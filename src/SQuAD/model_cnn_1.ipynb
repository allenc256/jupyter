{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achang/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_tf(sess = None, log_device_placement = False):\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(0)\n",
    "    return tf.InteractiveSession(config = tf.ConfigProto(log_device_placement = log_device_placement))\n",
    "\n",
    "def dump_statistics():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        print('parameters for \"%s\": %d' % (variable.name, variable_parameters))\n",
    "        total_parameters += variable_parameters\n",
    "    print('total parameters: %d' % total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(layer, epsilon=1e-6, name='ln', reuse=None):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        size = layer.shape[-1].value\n",
    "        scale = tf.get_variable(\n",
    "            'scale', [size], initializer = tf.ones_initializer())\n",
    "        bias = tf.get_variable(\n",
    "            'bias', [size], initializer = tf.zeros_initializer())\n",
    "        mean = tf.reduce_mean(\n",
    "            layer, axis = -1, keep_dims = True)\n",
    "        variance = tf.reduce_mean(\n",
    "            tf.square(layer - mean), axis = -1, keep_dims = True)\n",
    "        norm_layer = (layer - mean) * tf.rsqrt(variance + epsilon)\n",
    "        return norm_layer * scale + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(layer, dropout_rate=0.0, training=False, name='attn', reuse=None):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        # get size\n",
    "        size = layer.shape[-1].value\n",
    "        \n",
    "        # layer norm\n",
    "        layer = layer_norm(layer)\n",
    "\n",
    "        # dropout\n",
    "        l = tf.layers.dropout(layer, rate=dropout_rate, training=training)\n",
    "\n",
    "        # project\n",
    "        l = tf.layers.dense(layer, size, use_bias=False, name='proj')\n",
    "\n",
    "        # compute weights\n",
    "        l_T = tf.transpose(l, perm=[0, 2, 1])\n",
    "        w = tf.matmul(l, l_T)\n",
    "        w /= np.sqrt(size)\n",
    "        w = tf.nn.softmax(w)\n",
    "\n",
    "        # apply weights\n",
    "        return tf.matmul(w, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_attention(contexts, questions, dropout_rate=0.0, training=False, name='attn', reuse=None):\n",
    "    # grab size (static)\n",
    "    c = contexts\n",
    "    q = questions\n",
    "    size = c.shape[-1].value\n",
    "    assert q.shape[-1].value == size\n",
    "    \n",
    "    # grab lens (dynamic)\n",
    "    c_len = tf.shape(c)[1]\n",
    "    q_len = tf.shape(q)[1]\n",
    "    \n",
    "    # dropout\n",
    "    c = tf.layers.dropout(c, rate=dropout_rate, training=training)\n",
    "    q = tf.layers.dropout(q, rate=dropout_rate, training=training)\n",
    "\n",
    "    # compute input vectors\n",
    "    c = tf.expand_dims(c, axis=2)               # [batch, c_len, 1, size]\n",
    "    c = tf.tile(c, [1, 1, q_len, 1])            # [batch, c_len, q_len, size]\n",
    "    q = tf.expand_dims(q, axis=1)               # [batch, 1, q_len, size]\n",
    "    q = tf.tile(q, [1, c_len, 1, 1])            # [batch, c_len, q_len, size]\n",
    "    v = tf.concat([c, q, c*q], axis = -1)       # [batch, c_len, q_len, size*3]\n",
    "\n",
    "    # transform to weights\n",
    "    w = tf.layers.dense(v, 1, name='weight')    # [batch, c_len, q_len, 1]\n",
    "    w = tf.squeeze(w, axis=-1)                  # [batch, c_len, q_len]\n",
    "    w_c2q = w                                   # [batch, c_len, q_len]\n",
    "    w_q2c = tf.transpose(w, perm=[0,2,1])       # [batch, q_len, c_len]\n",
    "    \n",
    "    # softmax\n",
    "    w_c2q = tf.nn.softmax(w_c2q)\n",
    "    w_q2c = tf.nn.softmax(w_q2c)\n",
    "    \n",
    "    # apply weights\n",
    "    c2q = tf.matmul(w_c2q, questions)\n",
    "    q2c = tf.matmul(tf.matmul(w_c2q, w_q2c), contexts)\n",
    "    \n",
    "    return c2q, q2c    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(layer, hidden_size, dropout_rate=0.0, training=False, name='ff', reuse=None):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        # get size\n",
    "        size = layer.shape[-1].value\n",
    "        \n",
    "        # layer norm\n",
    "        l = layer_norm(layer)\n",
    "\n",
    "        # dropout\n",
    "        l = tf.layers.dropout(l, rate=dropout_rate, training=training)\n",
    "\n",
    "        # apply feed-forward\n",
    "        l = tf.layers.dense(l, hidden_size, activation=tf.nn.relu, name='ff0')\n",
    "        l = tf.layers.dense(l, size, name='ff1')\n",
    "        \n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(layer,\n",
    "            num_blocks,\n",
    "            num_convs,\n",
    "            kernel_size,\n",
    "            dropout_rate=0.0,\n",
    "            training=False,\n",
    "            name='enc',\n",
    "            reuse=None):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        # get size\n",
    "        size = layer.shape[-1].value\n",
    "\n",
    "        # encoder blocks\n",
    "        for b in range(num_blocks):\n",
    "            with tf.variable_scope('block_%d' % b):\n",
    "                # convolutions\n",
    "                for i in range(num_convs):\n",
    "                    with tf.variable_scope('conv_%d' % i):\n",
    "                        l = layer_norm(layer)\n",
    "                        l = tf.layers.dropout(l, rate=dropout_rate, training=training)\n",
    "                        l = tf.layers.conv1d(l, filters=size, kernel_size=kernel_size, padding='same')\n",
    "                        layer += l\n",
    "\n",
    "                # self-attention\n",
    "                layer += self_attention(layer, dropout_rate, training)\n",
    "\n",
    "                # ff\n",
    "                layer += feed_forward(layer, size*4, dropout_rate, training)\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_f1(a0, a1, a0_est, a1_est):\n",
    "    # make sure a1 is >= a0\n",
    "    a1_est = np.maximum(a0_est, a1_est)\n",
    "    \n",
    "    # offset endpoints by 1\n",
    "    a1 = a1 + 1\n",
    "    a1_est = a1_est + 1\n",
    "    \n",
    "    # compute interval lens\n",
    "    a_len = a1 - a0\n",
    "    e_len = a1_est - a0_est\n",
    "\n",
    "    # compute confusion matrix\n",
    "    tp = np.maximum(np.minimum(a1, a1_est) - np.maximum(a0, a0_est), 0)\n",
    "    fp = e_len - tp\n",
    "    fn = a_len - tp\n",
    "\n",
    "    # precision/recall/F1\n",
    "    pre = tp / (tp + fp + 1e-10)\n",
    "    rec = tp / (tp + fn + 1e-10)\n",
    "    F1 = 2 * (pre*rec) / (pre + rec + 1e-10)\n",
    "    \n",
    "    return np.mean(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example(example_proto, hp):\n",
    "    # parse proto\n",
    "    parsed = tf.parse_single_example(example_proto, features={\n",
    "        'context_wids': tf.VarLenFeature(tf.int64),\n",
    "        'context_cids': tf.VarLenFeature(tf.int64),\n",
    "        'question_wids': tf.VarLenFeature(tf.int64),\n",
    "        'question_cids': tf.VarLenFeature(tf.int64),\n",
    "        'answer_starts': tf.VarLenFeature(tf.int64),\n",
    "        'answer_ends': tf.VarLenFeature(tf.int64), })\n",
    "\n",
    "    # convert to dense tensors\n",
    "    c_wids = tf.sparse_tensor_to_dense(parsed['context_wids'])\n",
    "    c_cids = tf.sparse_tensor_to_dense(parsed['context_cids'])\n",
    "    q_wids = tf.sparse_tensor_to_dense(parsed['question_wids'])\n",
    "    q_cids = tf.sparse_tensor_to_dense(parsed['question_cids'])\n",
    "    a0 = tf.sparse_tensor_to_dense(parsed['answer_starts'])[0]\n",
    "    a1 = tf.sparse_tensor_to_dense(parsed['answer_ends'])[0]\n",
    "\n",
    "    # determine word lengths\n",
    "    c_wlen = tf.shape(c_wids)[0]\n",
    "    q_wlen = tf.shape(q_wids)[0]\n",
    "\n",
    "    # reshape char arrays\n",
    "    c_cids = tf.reshape(c_cids, [c_wlen, hp.max_word_len])\n",
    "    q_cids = tf.reshape(q_cids, [q_wlen, hp.max_word_len])\n",
    "\n",
    "    # pad to maximum length (necessary for batching tensors)\n",
    "    c_wids = tf.pad(c_wids, [[0, hp.max_context_len - c_wlen]])\n",
    "    c_cids = tf.pad(c_cids, [[0, hp.max_context_len - c_wlen], [0, 0]])\n",
    "    q_wids = tf.pad(q_wids, [[0, hp.max_question_len - q_wlen]])\n",
    "    q_cids = tf.pad(q_cids, [[0, hp.max_question_len - q_wlen], [0, 0]])\n",
    "    \n",
    "    # determine char lengths\n",
    "    c_clens = tf.reduce_sum(tf.cast(c_cids > 0, tf.int64), axis=-1)\n",
    "    q_clens = tf.reduce_sum(tf.cast(q_cids > 0, tf.int64), axis=-1)\n",
    "\n",
    "    return (c_wids, c_wlen, c_cids, c_clens, q_wids, q_wlen, q_cids, q_clens, a0, a1)\n",
    "\n",
    "def get_dataset(file, hp, limit=None, repeat=True):\n",
    "    def _parse(ex):\n",
    "        return parse_example(ex, hp)\n",
    "    d = tf.data.TFRecordDataset(file, compression_type = 'GZIP')\n",
    "    if limit:\n",
    "        d = d.take(limit)\n",
    "    d = d.map(_parse, num_parallel_calls=hp.data_num_parallel_calls)\n",
    "    d = d.shuffle(hp.data_shuffle_size)\n",
    "    if repeat:\n",
    "        d = d.repeat()\n",
    "    d = d.batch(hp.data_batch_size)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    dropout_rate = 0.2\n",
    "    \n",
    "    max_context_len = 850\n",
    "    max_question_len = 60\n",
    "    max_word_len = 16\n",
    "\n",
    "    data_batch_size = 16\n",
    "    data_num_parallel_calls = 2\n",
    "    data_prefetch_size = 256\n",
    "    data_shuffle_size = 512\n",
    "    \n",
    "    grad_clip_norm = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, hp, word_emb, data_it, handle):\n",
    "        # handle\n",
    "        self.handle = handle\n",
    "        \n",
    "        # training\n",
    "        self.training = tf.placeholder(tf.bool, name='training')\n",
    "\n",
    "        # read data (for speed)\n",
    "        (c_wids, c_wlens, c_cids, c_clens, \n",
    "         q_wids, q_wlens, q_cids, q_clens, \n",
    "         self.a0, self.a1) = data_it.get_next()\n",
    "\n",
    "        # trim data\n",
    "        c_max_wlen = tf.reduce_max(c_wlens)\n",
    "        q_max_wlen = tf.reduce_max(q_wlens)\n",
    "        c_wids = c_wids[:, :c_max_wlen]\n",
    "        c_cids = c_cids[:, :c_max_wlen, :]\n",
    "        q_wids = q_wids[:, :q_max_wlen]\n",
    "        q_cids = q_cids[:, :q_max_wlen, :]\n",
    "\n",
    "        # masks\n",
    "        c_wmask = tf.sequence_mask(c_wlens, c_max_wlen, dtype = tf.float32)\n",
    "        q_wmask = tf.sequence_mask(q_wlens, q_max_wlen, dtype = tf.float32)\n",
    "        \n",
    "        # embed\n",
    "        with tf.variable_scope('embed'):\n",
    "            word_emb = tf.get_variable(\n",
    "                'word', word_emb.shape,\n",
    "                initializer = tf.constant_initializer(word_emb),\n",
    "                trainable = False)\n",
    "            c_wemb = tf.nn.embedding_lookup(word_emb, c_wids)\n",
    "            q_wemb = tf.nn.embedding_lookup(word_emb, q_wids)\n",
    "            \n",
    "        # encode\n",
    "        with tf.variable_scope('encode'):\n",
    "            # dropout\n",
    "            c = tf.layers.dropout(c_wemb, hp.dropout_rate, self.training)\n",
    "            q = tf.layers.dropout(q_wemb, hp.dropout_rate, self.training)\n",
    "            # conv\n",
    "            c = tf.layers.conv1d(c, filters=128, kernel_size=7, padding='same')\n",
    "            q = tf.layers.conv1d(q, filters=128, kernel_size=7, padding='same')\n",
    "            # encode\n",
    "            c = encoder(\n",
    "                c, num_blocks=1, num_convs=4, kernel_size=7,\n",
    "                dropout_rate=hp.dropout_rate, training=self.training, name='enc')\n",
    "            q = encoder(\n",
    "                q, num_blocks=1, num_convs=4, kernel_size=7,\n",
    "                dropout_rate=hp.dropout_rate, training=self.training, name='enc', reuse=True)\n",
    "            \n",
    "        # cross attention\n",
    "        with tf.variable_scope('cross_attn'):\n",
    "            c *= tf.expand_dims(c_wmask, axis=-1)\n",
    "            q *= tf.expand_dims(q_wmask, axis=-1)\n",
    "            c2q, q2c = cross_attention(c, q, hp.dropout_rate, self.training)        \n",
    "            \n",
    "        # model\n",
    "        with tf.variable_scope('model'):\n",
    "            # concatenate\n",
    "            # TODO: add q2c\n",
    "            m = tf.concat([c, c2q, c*c2q], axis=-1)\n",
    "            # dropout\n",
    "            m = tf.layers.dropout(m, hp.dropout_rate, self.training)\n",
    "            # conv\n",
    "            m = tf.layers.conv1d(m, filters=128, kernel_size=5, padding='same')\n",
    "            # mask\n",
    "            m *= tf.expand_dims(c_wmask, axis=-1)\n",
    "            # encode\n",
    "            m0 = encoder(\n",
    "                m, num_blocks=5, num_convs=2, kernel_size=5,\n",
    "                dropout_rate=hp.dropout_rate, training=self.training)\n",
    "            m1 = encoder(\n",
    "                m0, num_blocks=5, num_convs=2, kernel_size=5,\n",
    "                dropout_rate=hp.dropout_rate, training=self.training, reuse=True)\n",
    "            m2 = encoder(\n",
    "                m1, num_blocks=5, num_convs=2, kernel_size=5,\n",
    "                dropout_rate=hp.dropout_rate, training=self.training, reuse=True)\n",
    "\n",
    "        # pointer\n",
    "        with tf.variable_scope('pointer'):\n",
    "            # dropout\n",
    "            m0 = tf.layers.dropout(m0, hp.dropout_rate, self.training)\n",
    "            m1 = tf.layers.dropout(m1, hp.dropout_rate, self.training)\n",
    "            m2 = tf.layers.dropout(m2, hp.dropout_rate, self.training)\n",
    "\n",
    "            # logits\n",
    "            l0 = tf.layers.dense(tf.concat([m0, m1], axis=-1), 1, use_bias=False, name='l0')\n",
    "            l1 = tf.layers.dense(tf.concat([m0, m2], axis=-1), 1, use_bias=False, name='l1')\n",
    "            l0 = tf.squeeze(l0, axis=-1)\n",
    "            l1 = tf.squeeze(l1, axis=-1)\n",
    "            \n",
    "            # mask\n",
    "            l0 *= c_wmask\n",
    "            l1 *= c_wmask\n",
    "            \n",
    "        # estimates\n",
    "        with tf.variable_scope('est'):\n",
    "            outer = tf.matmul(\n",
    "                tf.expand_dims(tf.nn.softmax(l0), axis=2),\n",
    "                tf.expand_dims(tf.nn.softmax(l1), axis=1))\n",
    "            outer = tf.matrix_band_part(outer, 0, 15)\n",
    "            self.a0_est = tf.argmax(tf.reduce_max(outer, axis=2), axis=1)\n",
    "            self.a1_est = tf.argmax(tf.reduce_max(outer, axis=1), axis=1)\n",
    "\n",
    "        # loss\n",
    "        losses0 = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=self.a0, logits=l0)\n",
    "        losses1 = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=self.a1, logits=l1)\n",
    "        self.mean_loss = tf.reduce_mean(losses0 + losses1)\n",
    "        \n",
    "        # global step\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        \n",
    "        # optimizer\n",
    "        opt = tf.train.AdamOptimizer(hp.learning_rate)\n",
    "        gs = opt.compute_gradients(self.mean_loss)\n",
    "        gs, vs = zip(*gs)\n",
    "        gs, _ = tf.clip_by_global_norm(gs, hp.grad_clip_norm)\n",
    "        self.train_op = opt.apply_gradients(zip(gs, vs), global_step=self.global_step)\n",
    "            \n",
    "    def eval(self, sess, steps, data_handle, tag='eval'):\n",
    "        em = 0\n",
    "        f1 = 0\n",
    "        n = 0\n",
    "        l = 0\n",
    "        for i in range(steps):\n",
    "            _l, a0, a0_est, a1, a1_est = sess.run(\n",
    "                [self.mean_loss, self.a0, self.a0_est, self.a1, self.a1_est],\n",
    "                feed_dict={ self.training: False, self.handle: data_handle })\n",
    "            em += np.sum((a0 == a0_est) * (a1 == a1_est))\n",
    "            f1 += mean_f1(a0, a1, a0_est, a1_est)\n",
    "            n += a0.size\n",
    "            l += _l\n",
    "        return l/steps, em/n, f1/steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../../data/SQuAD/data_3.words.embeddings.npy.gz', 'rb') as f:\n",
    "    word_emb = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for \"encode/conv1d/kernel:0\": 268800\n",
      "parameters for \"encode/conv1d/bias:0\": 128\n",
      "parameters for \"encode/conv1d_1/kernel:0\": 268800\n",
      "parameters for \"encode/conv1d_1/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_0/ln/scale:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_0/ln/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_0/conv1d/kernel:0\": 114688\n",
      "parameters for \"encode/enc/block_0/conv_0/conv1d/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_1/ln/scale:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_1/ln/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_1/conv1d/kernel:0\": 114688\n",
      "parameters for \"encode/enc/block_0/conv_1/conv1d/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_2/ln/scale:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_2/ln/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_2/conv1d/kernel:0\": 114688\n",
      "parameters for \"encode/enc/block_0/conv_2/conv1d/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_3/ln/scale:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_3/ln/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/conv_3/conv1d/kernel:0\": 114688\n",
      "parameters for \"encode/enc/block_0/conv_3/conv1d/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/attn/ln/scale:0\": 128\n",
      "parameters for \"encode/enc/block_0/attn/ln/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/attn/proj/kernel:0\": 16384\n",
      "parameters for \"encode/enc/block_0/ff/ln/scale:0\": 128\n",
      "parameters for \"encode/enc/block_0/ff/ln/bias:0\": 128\n",
      "parameters for \"encode/enc/block_0/ff/ff0/kernel:0\": 65536\n",
      "parameters for \"encode/enc/block_0/ff/ff0/bias:0\": 512\n",
      "parameters for \"encode/enc/block_0/ff/ff1/kernel:0\": 65536\n",
      "parameters for \"encode/enc/block_0/ff/ff1/bias:0\": 128\n",
      "parameters for \"cross_attn/weight/kernel:0\": 384\n",
      "parameters for \"cross_attn/weight/bias:0\": 1\n",
      "parameters for \"model/conv1d/kernel:0\": 245760\n",
      "parameters for \"model/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_0/conv_0/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_0/conv_0/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_0/conv_0/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_0/conv_0/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_0/conv_1/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_0/conv_1/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_0/conv_1/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_0/conv_1/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_0/attn/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_0/attn/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_0/attn/proj/kernel:0\": 16384\n",
      "parameters for \"model/enc/block_0/ff/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_0/ff/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_0/ff/ff0/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_0/ff/ff0/bias:0\": 512\n",
      "parameters for \"model/enc/block_0/ff/ff1/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_0/ff/ff1/bias:0\": 128\n",
      "parameters for \"model/enc/block_1/conv_0/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_1/conv_0/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_1/conv_0/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_1/conv_0/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_1/conv_1/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_1/conv_1/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_1/conv_1/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_1/conv_1/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_1/attn/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_1/attn/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_1/attn/proj/kernel:0\": 16384\n",
      "parameters for \"model/enc/block_1/ff/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_1/ff/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_1/ff/ff0/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_1/ff/ff0/bias:0\": 512\n",
      "parameters for \"model/enc/block_1/ff/ff1/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_1/ff/ff1/bias:0\": 128\n",
      "parameters for \"model/enc/block_2/conv_0/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_2/conv_0/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_2/conv_0/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_2/conv_0/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_2/conv_1/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_2/conv_1/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_2/conv_1/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_2/conv_1/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_2/attn/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_2/attn/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_2/attn/proj/kernel:0\": 16384\n",
      "parameters for \"model/enc/block_2/ff/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_2/ff/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_2/ff/ff0/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_2/ff/ff0/bias:0\": 512\n",
      "parameters for \"model/enc/block_2/ff/ff1/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_2/ff/ff1/bias:0\": 128\n",
      "parameters for \"model/enc/block_3/conv_0/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_3/conv_0/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_3/conv_0/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_3/conv_0/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_3/conv_1/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_3/conv_1/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_3/conv_1/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_3/conv_1/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_3/attn/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_3/attn/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_3/attn/proj/kernel:0\": 16384\n",
      "parameters for \"model/enc/block_3/ff/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_3/ff/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_3/ff/ff0/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_3/ff/ff0/bias:0\": 512\n",
      "parameters for \"model/enc/block_3/ff/ff1/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_3/ff/ff1/bias:0\": 128\n",
      "parameters for \"model/enc/block_4/conv_0/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_4/conv_0/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_4/conv_0/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_4/conv_0/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_4/conv_1/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_4/conv_1/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_4/conv_1/conv1d/kernel:0\": 81920\n",
      "parameters for \"model/enc/block_4/conv_1/conv1d/bias:0\": 128\n",
      "parameters for \"model/enc/block_4/attn/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_4/attn/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_4/attn/proj/kernel:0\": 16384\n",
      "parameters for \"model/enc/block_4/ff/ln/scale:0\": 128\n",
      "parameters for \"model/enc/block_4/ff/ln/bias:0\": 128\n",
      "parameters for \"model/enc/block_4/ff/ff0/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_4/ff/ff0/bias:0\": 512\n",
      "parameters for \"model/enc/block_4/ff/ff1/kernel:0\": 65536\n",
      "parameters for \"model/enc/block_4/ff/ff1/bias:0\": 128\n",
      "parameters for \"pointer/l0/kernel:0\": 256\n",
      "parameters for \"pointer/l1/kernel:0\": 256\n",
      "total parameters: 2959617\n"
     ]
    }
   ],
   "source": [
    "sess = reset_tf(sess)\n",
    "\n",
    "hp = HyperParameters()\n",
    "\n",
    "data_train = get_dataset('../../data/SQuAD/data_3.train.tfrecords.gz', hp)\n",
    "data_dev = get_dataset('../../data/SQuAD/data_3.dev.tfrecords.gz', hp)\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "handle_train = data_train.make_one_shot_iterator().string_handle().eval()\n",
    "handle_dev = data_dev.make_one_shot_iterator().string_handle().eval()\n",
    "\n",
    "data_it = tf.data.Iterator.from_string_handle(\n",
    "    handle, data_train.output_types, data_train.output_shapes)\n",
    "\n",
    "model = Model(hp, word_emb, data_it, handle)\n",
    "dump_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train_small = get_dataset('../../data/SQuAD/data_3.train.tfrecords.gz', hp, limit=1000)\n",
    "# handle_train_small = data_train_small.make_one_shot_iterator().string_handle().eval()\n",
    "# tr = tqdm_notebook(range(10000))\n",
    "# for i in tr:\n",
    "#     l, _, s = sess.run(\n",
    "#         [model.mean_loss, model.train_op, model.global_step],\n",
    "#         feed_dict={ model.training: True, model.handle: handle_train_small })\n",
    "#     tr.set_postfix(loss=l, step=s)\n",
    "#     if (i+1) % 500 == 0:\n",
    "#         print(model.eval(sess, 100, handle_train_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cc8333b6e2459e824a85c2a77f8364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.summary.FileWriter('../../logs/SQuAD/model_cnn_1') as sfw:\n",
    "    tr = tqdm_notebook(range(120000))\n",
    "    for i in tr:\n",
    "        l, _, s = sess.run(\n",
    "            [model.mean_loss, model.train_op, model.global_step],\n",
    "            feed_dict={ model.training: True, model.handle: handle_train })\n",
    "        tr.set_postfix(loss=l, step=s)\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            # evaluate\n",
    "            l_train, em_train, f1_train = model.eval(sess, 100, handle_train)\n",
    "            l_dev, em_dev, f1_dev = model.eval(sess, 100, handle_dev)\n",
    "\n",
    "            # summaries\n",
    "            sfw.add_summary(tf.Summary(value=[tf.Summary.Value(tag='train/loss', simple_value=l_train)]), s)\n",
    "            sfw.add_summary(tf.Summary(value=[tf.Summary.Value(tag='train/em', simple_value=em_train)]), s)\n",
    "            sfw.add_summary(tf.Summary(value=[tf.Summary.Value(tag='train/f1', simple_value=f1_train)]), s)\n",
    "            sfw.add_summary(tf.Summary(value=[tf.Summary.Value(tag='dev/loss', simple_value=l_dev)]), s)\n",
    "            sfw.add_summary(tf.Summary(value=[tf.Summary.Value(tag='dev/em', simple_value=em_dev)]), s)\n",
    "            sfw.add_summary(tf.Summary(value=[tf.Summary.Value(tag='dev/f1', simple_value=f1_dev)]), s)\n",
    "            sfw.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
