{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_tf(sess = None, log_device_placement = False):\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(0)\n",
    "    return tf.InteractiveSession(config = tf.ConfigProto(log_device_placement = log_device_placement))\n",
    "\n",
    "def dump_statistics():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        print('parameters for \"%s\": %d' % (variable.name, variable_parameters))\n",
    "        total_parameters += variable_parameters\n",
    "    print('total parameters: %d' % total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    dropout_rate = 0.2\n",
    "    \n",
    "    context_size = 850\n",
    "    question_size = 60\n",
    "    answers_size = 6\n",
    "    \n",
    "    d_hidden = 75\n",
    "    \n",
    "    num_rnn_layers_contexts = 1\n",
    "    num_rnn_layers_questions = 1\n",
    "\n",
    "    dataset_batch_size = 80\n",
    "    dataset_num_parallel_calls = 2\n",
    "    dataset_prefetch_size = 256\n",
    "    dataset_shuffle_size = 512\n",
    "    \n",
    "    gradient_clip_norm = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnModel:\n",
    "    def __init__(self, session, word_embeddings, hparams):\n",
    "        self._session = session\n",
    "        self._word_embeddings = word_embeddings\n",
    "        self._hparams = hparams\n",
    "        \n",
    "    def _parse_example(self, example_proto):\n",
    "        # parse proto\n",
    "        parsed = tf.parse_single_example(example_proto, features = {\n",
    "            'context': tf.VarLenFeature(tf.int64),\n",
    "            'question': tf.VarLenFeature(tf.int64),\n",
    "            'answer_starts': tf.VarLenFeature(tf.int64),\n",
    "            'answer_ends': tf.VarLenFeature(tf.int64), })\n",
    "        \n",
    "        # convert to dense tensors\n",
    "        context = tf.sparse_tensor_to_dense(parsed['context'])\n",
    "        question = tf.sparse_tensor_to_dense(parsed['question'])\n",
    "        answer_starts = tf.sparse_tensor_to_dense(parsed['answer_starts'])\n",
    "        answer_ends = tf.sparse_tensor_to_dense(parsed['answer_ends'])\n",
    "        \n",
    "        # pad tensors\n",
    "        context_len = tf.shape(context)[0]\n",
    "        question_len = tf.shape(question)[0]\n",
    "        answers_len = tf.shape(answer_starts)[0]\n",
    "        zero_vector = self._word_embeddings.shape[0] - 1\n",
    "        context = tf.pad(\n",
    "            context,\n",
    "            [[0, self._hparams.context_size - context_len]],\n",
    "            constant_values = 0)\n",
    "        question = tf.pad(\n",
    "            question,\n",
    "            [[0, self._hparams.question_size - question_len]],\n",
    "            constant_values = 0)\n",
    "        answer_starts = tf.pad(\n",
    "            answer_starts,\n",
    "            [[0, self._hparams.answers_size - answers_len]],\n",
    "            constant_values = -1)\n",
    "        answer_ends = tf.pad(\n",
    "            answer_ends,\n",
    "            [[0, self._hparams.answers_size - answers_len]],\n",
    "            constant_values = -1)\n",
    "        \n",
    "        return (context, context_len, question, question_len, answer_starts, answer_ends)\n",
    "    \n",
    "    def _build_dataset_pipeline(self):\n",
    "        with tf.variable_scope('dataset'):\n",
    "            # placeholders\n",
    "            self._dataset_filenames = tf.placeholder(\n",
    "                tf.string,\n",
    "                shape = [None],\n",
    "                name = 'dataset_filenames')\n",
    "            self._dataset_limit = tf.placeholder_with_default(\n",
    "                tf.constant(-1, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_limit')\n",
    "            self._dataset_shuffle_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_shuffle_size')\n",
    "            self._dataset_batch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_batch_size')\n",
    "            self._dataset_prefetch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_prefetch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_prefetch_size')\n",
    "\n",
    "            # build dataset\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                tf.random_shuffle(self._dataset_filenames),\n",
    "                compression_type='GZIP')\n",
    "            dataset = dataset.take(self._dataset_limit)\n",
    "            dataset = dataset.map(\n",
    "                self._parse_example,\n",
    "                num_parallel_calls = self._hparams.dataset_num_parallel_calls)\n",
    "            dataset = dataset.shuffle(self._dataset_shuffle_size)\n",
    "            dataset = dataset.prefetch(self._dataset_prefetch_size)\n",
    "            dataset = dataset.batch(self._dataset_batch_size)\n",
    "\n",
    "            # build iterator\n",
    "            self._dataset_iterator = dataset.make_initializable_iterator()\n",
    "            (contexts,\n",
    "             context_lens,\n",
    "             questions,\n",
    "             question_lens,\n",
    "             answer_starts,\n",
    "             answer_ends) = self._dataset_iterator.get_next()\n",
    "            \n",
    "            # trim contexts/questions\n",
    "            self._context_max_len = tf.reduce_max(context_lens)\n",
    "            self._question_max_len = tf.reduce_max(question_lens)\n",
    "            contexts = contexts[:, :self._context_max_len]\n",
    "            questions = questions[:, :self._question_max_len]\n",
    "            \n",
    "            # give key tensors names\n",
    "            self._contexts = tf.identity(contexts, 'contexts')\n",
    "            self._context_lens = tf.identity(context_lens, 'context_lens')\n",
    "            self._questions = tf.identity(questions, 'questions')\n",
    "            self._question_lens = tf.identity(question_lens, 'question_lens')\n",
    "            self._answer_starts = tf.identity(answer_starts, 'answer_starts')\n",
    "            self._answer_ends = tf.identity(answer_ends, 'answer_ends')\n",
    "\n",
    "            # minibatch size\n",
    "            self._minibatch_size = tf.shape(self._contexts)[0]\n",
    "            self._minibatch_size = tf.identity(self._minibatch_size, 'minibatch_size')\n",
    "            \n",
    "    def _rnn_uni_layer(self, seqs, num_layers, size):\n",
    "        # GRU\n",
    "        def build_gru(dropout):\n",
    "            return tf.contrib.cudnn_rnn.CudnnGRU(\n",
    "                num_layers = num_layers,\n",
    "                num_units = size,\n",
    "                input_size = seqs.shape[-1].value,\n",
    "                dropout = dropout,\n",
    "                direction = 'unidirectional')\n",
    "        gru_with_dropout = build_gru(self._hparams.dropout_rate)\n",
    "        gru_without_dropout = build_gru(0.0)\n",
    "\n",
    "        # variables\n",
    "        gru_params = tf.get_variable(\n",
    "            'gru_params',\n",
    "            [gru_with_dropout.params_size().eval(session = self._session)])\n",
    "\n",
    "        # make input hidden state\n",
    "        input_h = tf.zeros([num_layers, self._minibatch_size, size])\n",
    "\n",
    "        # make input data time-major\n",
    "        input_data = tf.transpose(seqs, perm = [1, 0, 2])\n",
    "        \n",
    "        # run GRU\n",
    "        outputs = tf.cond(\n",
    "            self._training,\n",
    "            lambda: gru_with_dropout(input_data, input_h, gru_params)[0],\n",
    "            lambda: gru_without_dropout(input_data, input_h, gru_params)[0])\n",
    "        \n",
    "        # undo time-major\n",
    "        outputs = tf.transpose(outputs, perm = [1, 0, 2])\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def _rnn_bidir_layer(self, seqs, seq_lens, num_layers, size):\n",
    "        # reverse input for backwards RNN\n",
    "        seqs_fw = seqs\n",
    "        seqs_bk = tf.reverse_sequence(seqs, seq_lens, seq_axis = 1)\n",
    "\n",
    "        # run RNNs\n",
    "        with tf.variable_scope('fw'):\n",
    "            out_fw = self._rnn_uni_layer(seqs_fw, num_layers, size)\n",
    "        with tf.variable_scope('bk'):\n",
    "            out_bk = self._rnn_uni_layer(seqs_bk, num_layers, size)\n",
    "\n",
    "        # unreverse output\n",
    "        out_bk = tf.reverse_sequence(out_bk, seq_lens, seq_axis = 1)\n",
    "        \n",
    "        # concat\n",
    "        return tf.concat([out_fw, out_bk], axis = -1)\n",
    "    \n",
    "    def _self_attention(self, layer, project = False):\n",
    "        l = layer\n",
    "        size = l.shape[-1].value\n",
    "        \n",
    "        if project:\n",
    "            l = tf.layers.dense(l, size, use_bias = False, name = 'proj')\n",
    "\n",
    "        # compute weights\n",
    "        l_T = tf.transpose(l, perm = [0, 2, 1])\n",
    "        w = tf.matmul(l, l_T)\n",
    "        w /= np.sqrt(size)\n",
    "        \n",
    "        # mask self-attention\n",
    "        mask = tf.diag(tf.fill([tf.shape(layer)[1]], -1e25))\n",
    "        mask = tf.expand_dims(mask, axis = 0)\n",
    "        w += mask\n",
    "        \n",
    "        # softmax\n",
    "        w = tf.nn.softmax(w, name = 'weights')\n",
    "\n",
    "        # dropout\n",
    "        w = tf.layers.dropout(\n",
    "            w,\n",
    "            rate = self._hparams.dropout_rate,\n",
    "            training = self._training)\n",
    "\n",
    "        # apply weights\n",
    "        return tf.matmul(w, layer)\n",
    "    \n",
    "    def _cross_attention(self, c, q):\n",
    "        size = c.shape[-1].value\n",
    "        assert q.shape[-1].value == size\n",
    "        \n",
    "        # project\n",
    "        cw = tf.layers.dense(c, size, use_bias = False, name = 'proj_cw')\n",
    "        qw = tf.layers.dense(q, size, use_bias = False, name = 'proj_qw')\n",
    "\n",
    "        # compute weights\n",
    "        qw_T = tf.transpose(qw, perm = [0, 2, 1])           # [batch, size, q_len]\n",
    "        w = tf.matmul(cw, qw_T)                             # [batch, c_len, q_len]\n",
    "        w /= np.sqrt(size)\n",
    "        \n",
    "        # c2q weights\n",
    "        w_c2q = tf.nn.softmax(w)\n",
    "        w_c2q = tf.layers.dropout(\n",
    "            w_c2q,\n",
    "            rate = self._hparams.dropout_rate,\n",
    "            training = self._training)\n",
    "\n",
    "        # q2c weights\n",
    "        w_q2c = tf.transpose(w, perm = [0, 2, 1])           # [batch, q_len, c_len]\n",
    "        w_q2c = tf.nn.softmax(w_q2c)\n",
    "        w_q2c = tf.layers.dropout(\n",
    "            w_q2c,\n",
    "            rate = self._hparams.dropout_rate,\n",
    "            training = self._training)\n",
    "\n",
    "        # apply weights\n",
    "        c2q = tf.matmul(w_c2q, q)\n",
    "        q2c = tf.matmul(w_q2c, c)\n",
    "        \n",
    "        return c2q, q2c\n",
    "                \n",
    "    def _layer_norm(self, layer, epsilon = 1e-6, name = 'ln'):\n",
    "        with tf.variable_scope(name):\n",
    "            size = layer.shape[-1].value\n",
    "            scale = tf.get_variable(\n",
    "                'scale',\n",
    "                [size],\n",
    "                initializer = tf.ones_initializer())\n",
    "            bias = tf.get_variable(\n",
    "                'bias',\n",
    "                [size],\n",
    "                initializer = tf.zeros_initializer())\n",
    "            mean = tf.reduce_mean(\n",
    "                layer,\n",
    "                axis = -1,\n",
    "                keep_dims = True)\n",
    "            variance = tf.reduce_mean(\n",
    "                tf.square(layer - mean),\n",
    "                axis = -1,\n",
    "                keep_dims = True)\n",
    "            norm_layer = (layer - mean) * tf.rsqrt(variance + epsilon)\n",
    "            return norm_layer * scale + bias\n",
    "        \n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('model'):\n",
    "            # placeholders\n",
    "            self._training = tf.placeholder(tf.bool, name = 'training')\n",
    "            \n",
    "            # init embedding\n",
    "            word_embeddings = tf.get_variable(\n",
    "                name = \"word_embeddings\",\n",
    "                shape = self._word_embeddings.shape,\n",
    "                initializer = tf.constant_initializer(self._word_embeddings),\n",
    "                trainable = False)\n",
    "            \n",
    "            # embed contexts/questions\n",
    "            contexts_embedded = tf.nn.embedding_lookup(\n",
    "                word_embeddings,\n",
    "                self._contexts)\n",
    "            questions_embedded = tf.nn.embedding_lookup(\n",
    "                word_embeddings,\n",
    "                self._questions)\n",
    "            \n",
    "            # RNN contexts/questions\n",
    "            with tf.variable_scope('encode_rnn'):\n",
    "                contexts_encoded = self._rnn_bidir_layer(\n",
    "                    contexts_embedded,\n",
    "                    self._context_lens,\n",
    "                    self._hparams.num_rnn_layers_contexts,\n",
    "                    self._hparams.d_hidden)\n",
    "            with tf.variable_scope('encode_rnn', reuse = True):\n",
    "                questions_encoded = self._rnn_bidir_layer(\n",
    "                    questions_embedded,\n",
    "                    self._question_lens,\n",
    "                    self._hparams.num_rnn_layers_questions,\n",
    "                    self._hparams.d_hidden)\n",
    "                    \n",
    "            # apply masks\n",
    "            contexts_mask = tf.sequence_mask(\n",
    "                self._context_lens,\n",
    "                maxlen = self._context_max_len,\n",
    "                dtype = tf.float32)\n",
    "            contexts_mask_exp = tf.expand_dims(contexts_mask, axis = -1)\n",
    "            contexts_encoded *= contexts_mask_exp\n",
    "            questions_mask = tf.sequence_mask(\n",
    "                self._question_lens,\n",
    "                maxlen = self._question_max_len,\n",
    "                dtype = tf.float32)\n",
    "            questions_mask_exp = tf.expand_dims(questions_mask, axis = -1)\n",
    "            questions_encoded *= questions_mask_exp\n",
    "\n",
    "            # summarize question\n",
    "            with tf.variable_scope('question_summary'):\n",
    "                q = self._layer_norm(questions_encoded)\n",
    "                q = tf.layers.dropout(\n",
    "                    q,\n",
    "                    rate = self._hparams.dropout_rate,\n",
    "                    training = self._training)\n",
    "                weights = tf.layers.dense(q, 1, use_bias = False)   # [batch_size, query_size, 1]\n",
    "                weights = tf.squeeze(weights, axis = -1)\n",
    "                weights = tf.nn.softmax(weights)\n",
    "                weights = tf.expand_dims(weights, axis = -1)\n",
    "                question_summary = questions_encoded * weights      # [batch_size, question_size, d_hidden]\n",
    "                question_summary = tf.reduce_sum(                   # [batch_size, d_hidden]\n",
    "                    question_summary,\n",
    "                    axis = 1)\n",
    "                \n",
    "            # joint attention layer\n",
    "            with tf.variable_scope('joint_attn'):\n",
    "                c2q, q2c = self._cross_attention(contexts_encoded, questions_encoded)\n",
    "                joint_encoded = tf.concat(\n",
    "                    [contexts_encoded, c2q],\n",
    "                    axis = -1)\n",
    "                \n",
    "            # joint self-attention layer\n",
    "            with tf.variable_scope('joint_self_attn'):\n",
    "                attn = self._self_attention(joint_encoded)\n",
    "                q = tf.expand_dims(question_summary, 1)\n",
    "                q = tf.tile(q, [1, self._context_max_len, 1])\n",
    "                joint_encoded = tf.concat(\n",
    "                    [joint_encoded, attn, q],\n",
    "                    axis = -1)\n",
    "                joint_encoded *= contexts_mask_exp\n",
    "            \n",
    "            # joint RNN layer\n",
    "            with tf.variable_scope('joint_rnn'):\n",
    "                joint_encoded = self._rnn_bidir_layer(\n",
    "                    joint_encoded,\n",
    "                    self._context_lens,\n",
    "                    1,\n",
    "                    self._hparams.d_hidden)\n",
    "                \n",
    "            # compute answer pointers\n",
    "            with tf.variable_scope('answer'):\n",
    "                q = self._layer_norm(question_summary, name = 'ln_q')\n",
    "                q = tf.layers.dropout(\n",
    "                    q,\n",
    "                    rate = self._hparams.dropout_rate,\n",
    "                    training = self._training)\n",
    "                q = tf.layers.dense(q, joint_encoded.shape[-1].value)\n",
    "                q = tf.expand_dims(q, axis = -1)                # [batch_size, d_hidden, 1]\n",
    "                l = tf.matmul(joint_encoded, q)                 # [batch_size, context_size, 1]\n",
    "                l = tf.squeeze(l, axis = -1)                    # [batch_size, context_size]\n",
    "                l *= contexts_mask\n",
    "                self._answer_start_logits = l\n",
    "\n",
    "#             self._answer_end_logits = tf.layers.dense(\n",
    "#                 joint_layer,\n",
    "#                 1,\n",
    "#                 use_bias = False,\n",
    "#                 name = 'answer_end_logits')\n",
    "#             self._answer_end_logits = tf.squeeze(      # [batch_size, context_size]\n",
    "#                 self._answer_end_logits,\n",
    "#                 axis = -1,\n",
    "#                 name = 'answer_end_logits')\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        with tf.variable_scope('optimize'):\n",
    "            # individual losses\n",
    "            # TODO: incorporate other answers into training\n",
    "            l0 = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = self._answer_starts[:, 0],\n",
    "                logits = self._answer_start_logits)\n",
    "#             l1 = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "#                 labels = self._answer_ends[:, 0],\n",
    "#                 logits = self._answer_end_logits)\n",
    "\n",
    "            # total loss\n",
    "            self._total_loss = tf.reduce_sum(l0) # + tf.reduce_sum(l1)\n",
    "            self._total_loss = tf.identity(self._total_loss, 'total_loss')\n",
    "            \n",
    "            # mean loss\n",
    "            self._mean_loss = self._total_loss / tf.cast(self._minibatch_size, tf.float32)\n",
    "            self._mean_loss = tf.identity(self._mean_loss, 'mean_loss')\n",
    "            \n",
    "            # start/end probabilities/estimates\n",
    "            self._answer_start_probs = tf.nn.softmax(\n",
    "                self._answer_start_logits,\n",
    "                name = 'answer_start_logits')\n",
    "            self._answer_start_estimates = tf.argmax(\n",
    "                self._answer_start_probs,\n",
    "                axis = -1,\n",
    "                name = 'answer_start_estimates')\n",
    "#             self._answer_end_probs = tf.nn.softmax(\n",
    "#                 self._answer_end_logits,\n",
    "#                 name = 'answer_end_logits')\n",
    "#             # N.B., mask impossible answers\n",
    "#             mask = 1.0 - tf.sequence_mask(\n",
    "#                 self._answer_start_estimates,\n",
    "#                 self._hparams.context_size,\n",
    "#                 dtype = tf.float32)\n",
    "#             self._answer_end_estimates = tf.argmax(\n",
    "#                 mask * self._answer_end_probs,\n",
    "#                 axis = -1,\n",
    "#                 name = 'answer_end_estimates')\n",
    "            \n",
    "            # exact match accuracy\n",
    "            answer_starts_eq = tf.equal(\n",
    "                self._answer_starts[:, 0],\n",
    "                self._answer_start_estimates)\n",
    "            self._total_exact_matches = tf.reduce_sum(\n",
    "                tf.cast(answer_starts_eq, tf.int64),\n",
    "                name = 'total_exact_matches')\n",
    "#             answer_ends_eq = tf.equal(\n",
    "#                 self._answer_ends[:, 0],\n",
    "#                 self._answer_end_estimates)\n",
    "#             answers_eq = tf.logical_and(\n",
    "#                 answer_starts_eq,\n",
    "#                 answer_ends_eq)\n",
    "#             self._total_exact_matches = tf.reduce_sum(\n",
    "#                 tf.cast(answers_eq, tf.int64),\n",
    "#                 name = 'total_exact_matches')\n",
    "            \n",
    "#             # F1\n",
    "#             a0 = self._answer_starts[:, 0]\n",
    "#             a1 = self._answer_ends[:, 0] + 1\n",
    "#             answer_lens = a1 - a0\n",
    "#             b0 = self._answer_start_estimates\n",
    "#             b1 = self._answer_end_estimates + 1\n",
    "#             answer_estimate_lens = b1 - b0\n",
    "#             tps = tf.maximum(\n",
    "#                 tf.cast(0, tf.int64),\n",
    "#                 tf.minimum(a1, b1) - tf.maximum(a0, b0))\n",
    "#             fps = answer_estimate_lens - tps\n",
    "#             fns = answer_lens - tps\n",
    "#             self._total_true_positives = tf.reduce_sum(\n",
    "#                 tps,\n",
    "#                 name = 'total_true_positives')\n",
    "#             self._total_false_positives = tf.reduce_sum(\n",
    "#                 fps,\n",
    "#                 name = 'total_false_positives')\n",
    "#             self._total_false_negatives = tf.reduce_sum(\n",
    "#                 fns,\n",
    "#                 name = 'total_false_negatives')\n",
    "            self._total_true_positives = tf.constant(0)\n",
    "            self._total_false_positives = tf.constant(0)\n",
    "            self._total_false_negatives = tf.constant(0)\n",
    "\n",
    "            # learning rate placeholder\n",
    "            self._learning_rate = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.learning_rate, tf.float32),\n",
    "                shape = [],\n",
    "                name = 'learning_rate')\n",
    "            \n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self._global_step = tf.Variable(0, name = 'global_step', trainable = False)\n",
    "                self._optimizer = tf.train.AdamOptimizer(learning_rate = self._learning_rate)\n",
    "                \n",
    "                # gradient clipping\n",
    "                gradients, variables = zip(*self._optimizer.compute_gradients(self._mean_loss))\n",
    "                gradients, _ = tf.clip_by_global_norm(\n",
    "                    gradients, \n",
    "                    self._hparams.gradient_clip_norm)\n",
    "                \n",
    "                self._train_op = self._optimizer.apply_gradients(\n",
    "                    zip(gradients, variables),\n",
    "                    global_step = self._global_step)\n",
    "\n",
    "    def process(self,\n",
    "                dataset_filenames,\n",
    "                dataset_limit = -1,\n",
    "                learning_rate = None,\n",
    "                header = 'results',\n",
    "                train = False,\n",
    "                log_file = None):\n",
    "        # initialize dataset to files\n",
    "        self._session.run(self._dataset_iterator.initializer, feed_dict={\n",
    "            self._dataset_filenames: dataset_filenames,\n",
    "            self._dataset_limit: dataset_limit })\n",
    "        \n",
    "        if learning_rate is None:\n",
    "            learning_rate = self._hparams.learning_rate\n",
    "\n",
    "        cum_loss = 0\n",
    "        cum_num_examples = 0\n",
    "        cum_exact_matches = 0\n",
    "        cum_tps = 0\n",
    "        cum_fps = 0\n",
    "        cum_fns = 0\n",
    "        \n",
    "        # start progress\n",
    "        start = datetime.datetime.now()\n",
    "        progress = tqdm_notebook(leave = False, desc = header)\n",
    "\n",
    "        while True:\n",
    "            # process a minibatch\n",
    "            try:\n",
    "                (_,\n",
    "                 curr_total_loss,\n",
    "                 curr_exact_matches,\n",
    "                 curr_tps,\n",
    "                 curr_fps,\n",
    "                 curr_fns,\n",
    "                 curr_minibatch_size) = self._session.run(\n",
    "                    (self._train_op if train else (),\n",
    "                     self._total_loss,\n",
    "                     self._total_exact_matches,\n",
    "                     self._total_true_positives,\n",
    "                     self._total_false_positives,\n",
    "                     self._total_false_negatives,\n",
    "                     self._minibatch_size),\n",
    "                    feed_dict = {\n",
    "                        self._training: train,\n",
    "                        self._learning_rate: learning_rate })\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "            # update loss stats\n",
    "            cum_loss += curr_total_loss\n",
    "            cum_exact_matches += curr_exact_matches\n",
    "            cum_tps += curr_tps\n",
    "            cum_fps += curr_fps\n",
    "            cum_fns += curr_fns\n",
    "            cum_num_examples += curr_minibatch_size\n",
    "            \n",
    "            # update progress\n",
    "            progress.update(curr_minibatch_size)\n",
    "            progress.set_postfix(loss = cum_loss / cum_num_examples)\n",
    "\n",
    "        # end progress\n",
    "        progress.close()\n",
    "        finish = datetime.datetime.now()\n",
    "        \n",
    "        # precision\n",
    "        precision = 0\n",
    "        if cum_tps + cum_fps > 0:\n",
    "            precision = cum_tps / (cum_tps + cum_fps)\n",
    "            \n",
    "        # recall\n",
    "        recall = 0\n",
    "        if cum_tps + cum_fns > 0:\n",
    "            recall = cum_tps / (cum_tps + cum_fns)\n",
    "            \n",
    "        # F1\n",
    "        F1 = 0\n",
    "        if precision + recall > 0:\n",
    "            F1 = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "        # print/log output\n",
    "        message = '%s: time=%s, step=%d, loss=%g, exact_match=%g, precision=%g, recall=%g, F1=%g' % (\n",
    "            header,\n",
    "            finish - start,\n",
    "            tf.train.global_step(sess, self._global_step),\n",
    "            cum_loss / cum_num_examples,\n",
    "            cum_exact_matches / cum_num_examples,\n",
    "            precision,\n",
    "            recall,\n",
    "            F1)\n",
    "        print(message)\n",
    "        if log_file:\n",
    "            print(message, file=log_file)\n",
    "            log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../../data/SQuAD/data_1.vocab.embeddings.npy.gz', 'rb') as f:\n",
    "    word_embeddings = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    return sorted([os.path.join(path, file) for file in os.listdir(path)])\n",
    "\n",
    "train_set = list_files('../../data/SQuAD/data_1.train')\n",
    "dev_set = list_files('../../data/SQuAD/data_1.dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for \"model/encode_rnn/fw/gru_params:0\": 84825\n",
      "parameters for \"model/encode_rnn/bk/gru_params:0\": 84825\n",
      "parameters for \"model/question_summary/ln/scale:0\": 150\n",
      "parameters for \"model/question_summary/ln/bias:0\": 150\n",
      "parameters for \"model/question_summary/dense/kernel:0\": 150\n",
      "parameters for \"model/joint_attn/proj_cw/kernel:0\": 22500\n",
      "parameters for \"model/joint_attn/proj_qw/kernel:0\": 22500\n",
      "parameters for \"model/joint_rnn/fw/gru_params:0\": 186075\n",
      "parameters for \"model/joint_rnn/bk/gru_params:0\": 186075\n",
      "parameters for \"model/answer/ln_q/scale:0\": 150\n",
      "parameters for \"model/answer/ln_q/bias:0\": 150\n",
      "parameters for \"model/answer/dense/kernel:0\": 22500\n",
      "parameters for \"model/answer/dense/bias:0\": 150\n",
      "total parameters: 610200\n"
     ]
    }
   ],
   "source": [
    "sess = reset_tf(sess)\n",
    "\n",
    "model = RnnModel(sess, word_embeddings, HyperParameters())\n",
    "model._build_dataset_pipeline()\n",
    "model._build_model()\n",
    "model._build_optimizer()\n",
    "dump_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50f5b2584f74ad1bc00c8a508d375fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_0', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_0: time=0:04:18.711854, step=1095, loss=3.2797, exact_match=0.207103, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b43ff3971b240c5b1a74cc78280f680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_0', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_0: time=0:00:13.470105, step=1095, loss=2.93637, exact_match=0.253075, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e599d0dd3984a5aa2f1c753b4fdfdaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_1', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_1: time=0:04:20.230364, step=2190, loss=2.65119, exact_match=0.312401, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a846c073b6d4a02a47e5c1eb23a1827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_1', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_1: time=0:00:13.288354, step=2190, loss=2.58648, exact_match=0.323841, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6db04b9c944aa5921cdecb79e4293c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_2', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_2: time=0:04:12.916900, step=3285, loss=2.33096, exact_match=0.380198, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d355f8df7c304b569a5e5d86075984a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_2', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_2: time=0:00:13.318368, step=3285, loss=2.42106, exact_match=0.367455, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef0ced18bf543d998be9ca9edb63bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_3', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_3: time=0:04:12.694991, step=4380, loss=2.09165, exact_match=0.433087, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab4af3cca1e4a5bb55993e8df2168d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_3', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_3: time=0:00:13.209056, step=4380, loss=2.28833, exact_match=0.394986, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88896acc26ad468283e08a3c84602ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_4', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_4: time=0:04:12.699345, step=5475, loss=1.89022, exact_match=0.47754, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7db3d52bad4fbeaf9b97fa5314875c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_4', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_4: time=0:00:13.195821, step=5475, loss=2.22604, exact_match=0.402365, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbed651c9544dcfb6eb53deb6248b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_5', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_5: time=0:04:11.995784, step=6570, loss=1.72137, exact_match=0.516844, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1687cf5a56d4b718936f1215a875a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_5', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_5: time=0:00:12.938025, step=6570, loss=2.21568, exact_match=0.414286, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26390244540d4ff6b3c1e95f25366dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_6', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_6: time=0:04:12.075426, step=7665, loss=1.57074, exact_match=0.549709, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3bf58f317141469d52d1e0f53b492b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_6', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_6: time=0:00:13.100132, step=7665, loss=2.24416, exact_match=0.423084, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9db446524dd4cb0b85a5f7f0f2207b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_7', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_7: time=0:04:12.490949, step=8760, loss=1.43671, exact_match=0.581182, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4dce618551443b0b7b7d272e2a95248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_7', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_7: time=0:00:13.139639, step=8760, loss=2.28878, exact_match=0.423746, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6b33b8e34a41a9bcd94385b37baffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_8', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train_8: time=0:04:10.542980, step=9855, loss=1.30654, exact_match=0.611286, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef5ae9cd9864d699690904fa3c5cbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev_8', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev_8: time=0:00:12.975790, step=9855, loss=2.3454, exact_match=0.41807, precision=0, recall=0, F1=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d96bdb70d6846b5bc9a9e4b93fc81a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_9', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('../../logs/SQuAD/model_rnn_4.2.log', 'wt') as f:\n",
    "    for i in range(50):\n",
    "        model.process(\n",
    "            train_set,\n",
    "            header = 'train_%d' % i,\n",
    "            train = True,\n",
    "            log_file = f)\n",
    "        model.process(\n",
    "            dev_set,\n",
    "            header = 'dev_%d' % i,\n",
    "            train = False,\n",
    "            log_file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(\n",
    "    model._dataset_iterator.initializer,\n",
    "    feed_dict = {\n",
    "        model._dataset_filenames: train_set[:1],\n",
    "        model._dataset_limit: 10 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, context_lens, questions, question_lens = sess.run(\n",
    "    [model._contexts,\n",
    "     model._context_lens,\n",
    "     model._questions,\n",
    "     model._question_lens],\n",
    "    feed_dict = { model._training: False })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([171,  70, 131, 102,  93, 190, 155, 129, 120, 162], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 29,   5,  78,  43,  34,  25, 124, 117,  55, 110])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65,   4,  78,  49,  80, 181, 123, 117,  52, 110])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_starts[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 67,   5,  78,  49,  80, 189, 124, 117,  55, 110])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_ends[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = reset_tf(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = tf.contrib.cudnn_rnn.CudnnGRU(\n",
    "    num_layers = 1,\n",
    "    num_units = 50,\n",
    "    input_size = 100,\n",
    "    direction = 'bidirectional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45600"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.params_size().eval(session = sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_params = tf.get_variable(\n",
    "    'gru_params',\n",
    "    [gru.params_size().eval()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_h = tf.cast(np.random.rand(2, 30, 50), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.cast(np.random.rand(20, 30, 100), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(20), Dimension(30), Dimension(100)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gru(input_data, input_h, gru_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'CudnnRNN_5:0' shape=(20, 30, 100) dtype=float32>,\n",
       " <tf.Tensor 'CudnnRNN_5:1' shape=(2, 30, 50) dtype=float32>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 30, 100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CudnnGRU in module tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops:\n",
      "\n",
      "class CudnnGRU(_CudnnRNNNoInputC)\n",
      " |  Cudnn implementation of the GRU model.\n",
      " |  Cudnn RNN has an opaque parameter buffer that can be used for inference and\n",
      " |  training. But it is possible that the layout of the parameter buffers\n",
      " |  changes between generations. So it is highly recommended to use\n",
      " |  CudnnOpaqueParamsSaveable to save and restore weights and biases in a\n",
      " |  canonical format.\n",
      " |  \n",
      " |  This is a typical use case:\n",
      " |  \n",
      " |    * The user creates a CudnnRNN model.\n",
      " |    * The user query that parameter buffer size.\n",
      " |    * The user creates a variable of that size that serves as the parameter\n",
      " |        buffers.\n",
      " |    * The user either initialize the parameter buffer, or load the canonical\n",
      " |        weights into the parameter buffer.\n",
      " |    * The user calls the model with the parameter buffer for inference, or\n",
      " |        training.\n",
      " |    * If training, the user creates a Saver object.\n",
      " |    * If training, the user creates a CudnnOpaqueParamsSaveable object from the\n",
      " |        parameter buffer for it to be later saved in the canonical format. When\n",
      " |        creating a CudnnOpaqueParamsSaveable object, a name could be provided,\n",
      " |        which is useful in distinguishing the names of multiple\n",
      " |        CudnnOpaqueParamsSaveable objects (e.g. for an encoder-decoder model).\n",
      " |    * Once a while, the user saves the parameter buffer into model checkpoints\n",
      " |        with Saver.save().\n",
      " |    * When restoring, the user creates a CudnnOpaqueParamsSaveable object and\n",
      " |      uses Saver.restore() to restore the parameter buffer from the canonical\n",
      " |      format to a user-defined format, as well as to restore other savable\n",
      " |      objects in the checkpoint file.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CudnnGRU\n",
      " |      _CudnnRNNNoInputC\n",
      " |      _CudnnRNN\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from _CudnnRNNNoInputC:\n",
      " |  \n",
      " |  __call__(self, input_data, input_h, params, is_training=True)\n",
      " |      Runs the forward step for the Cudnn LSTM model.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_data: the input sequence to the RNN model. A Tensor of shape [?,\n",
      " |          batch_size, input_size].\n",
      " |        input_h: the initial hidden state for h. A Tensor of shape [num_layers,\n",
      " |          batch_size, num_units].\n",
      " |        params: the parameter buffer created for this model.\n",
      " |        is_training: whether this operation will be used in training or inference.\n",
      " |      Returns:\n",
      " |        output: the output sequuence.\n",
      " |        output_h: the final state for h.\n",
      " |  \n",
      " |  __init__(self, num_layers, num_units, input_size, input_mode='linear_input', direction='unidirectional', dtype=tf.float32, dropout=0.0, seed=0)\n",
      " |      Creates a Cudnn RNN model from model without hidden-state C.\n",
      " |      \n",
      " |      Args:\n",
      " |        num_layers: the number of layers for the RNN model.\n",
      " |        num_units: the number of units within the RNN model.\n",
      " |        input_size: the size of the input, it could be different from the\n",
      " |            num_units.\n",
      " |        input_mode: indicate whether there is a linear projection between the\n",
      " |            input and The actual computation before the first layer. It could be\n",
      " |            'skip_input', 'linear_input' or 'auto_select'.\n",
      " |            'skip_input' is only allowed when input_size == num_units;\n",
      " |            'auto_select' implies 'skip_input' when input_size == num_units;\n",
      " |            otherwise, it implies 'linear_input'.\n",
      " |        direction: the direction model that the model operates. Could be either\n",
      " |            'unidirectional' or 'bidirectional'\n",
      " |        dtype: dtype of params, tf.float32 or tf.float64.\n",
      " |        dropout: whether to enable dropout. With it is 0, dropout is disabled.\n",
      " |        seed: the seed used for initializing dropout.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if direction is not 'unidirectional' or 'bidirectional'.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _CudnnRNN:\n",
      " |  \n",
      " |  canonical_to_params(self, weights, biases)\n",
      " |      Converts params from the canonical format to a specific format of cuDNN.\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a Tensor for weight parameters.\n",
      " |        biases: a Tensor for bias parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function for the canonical-to-params-to-specific conversion..\n",
      " |  \n",
      " |  params_size(self)\n",
      " |      Calculates the size of the opaque parameter buffer needed for this model.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The calculated parameter buffer size.\n",
      " |  \n",
      " |  params_to_canonical(self, params)\n",
      " |      Converts params from a specific format of cuDNN to the canonical format.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: a Variable for weight and bias parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function for the specific-to-canonical conversion.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _CudnnRNN:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  direction\n",
      " |  \n",
      " |  input_mode\n",
      " |  \n",
      " |  input_size\n",
      " |  \n",
      " |  num_layers\n",
      " |  \n",
      " |  num_units\n",
      " |  \n",
      " |  rnn_mode\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.contrib.cudnn_rnn.CudnnGRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [4, 5, 6, 7]], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(tf.reshape(tf.range(2*4), [2, 1, 4]), [1, 3, 1]).eval()[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims:0' shape=(2, 1, 4) dtype=int32>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf.reshape(tf.range(2*4), [2, 4]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(tf.range(2*4), [2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1],\n",
       "        [4, 5]], dtype=int32), array([[2, 3],\n",
       "        [6, 7]], dtype=int32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :2].eval(), x[:, 2:].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [4, 5, 6, 7]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x, y = 2*x):\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul:0' shape=(2, 4) dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = tf.contrib.cudnn_rnn.CudnnGRU(\n",
    "    num_layers = 1,\n",
    "    num_units = 10,\n",
    "    input_size = 10,\n",
    "    dropout = 0.5,\n",
    "    direction = 'bidirectional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.params_size().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
