{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achang/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_tf(sess = None, log_device_placement = False):\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(0)\n",
    "    return tf.InteractiveSession(config = tf.ConfigProto(log_device_placement = log_device_placement))\n",
    "\n",
    "def dump_statistics():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        print('parameters for \"%s\": %d' % (variable.name, variable_parameters))\n",
    "        total_parameters += variable_parameters\n",
    "    print('total parameters: %d' % total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    dropout_rate = 0.2\n",
    "    \n",
    "    encoding_num_ffn_layers = 2\n",
    "    encoding_num_rnn_layers = 2\n",
    "    memory_num_rnn_layers = 1\n",
    "    \n",
    "    context_max_len_sents = 30\n",
    "    context_max_len_words = 400\n",
    "    question_max_len = 60\n",
    "    answers_max_len = 6\n",
    "    \n",
    "    vocab_size = 88570\n",
    "    \n",
    "    d_hidden = 100\n",
    "\n",
    "    dataset_batch_size = 32\n",
    "    dataset_num_parallel_calls = 2\n",
    "    dataset_prefetch_size = 100\n",
    "    dataset_shuffle_size = 1000\n",
    "    \n",
    "    gradient_clip_norm = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnModel:\n",
    "    def __init__(self, session, word_embeddings_pretrained, hparams):\n",
    "        self._session = session\n",
    "        self._word_embeddings_pretrained = word_embeddings_pretrained\n",
    "        self._hparams = hparams\n",
    "        \n",
    "    def _parse_example(self, example_proto):\n",
    "        # parse proto\n",
    "        parsed = tf.parse_single_example(example_proto, features = {\n",
    "            'context_sizes': tf.VarLenFeature(tf.int64),\n",
    "            'context_word_ids': tf.VarLenFeature(tf.int64),\n",
    "            'question_word_ids': tf.VarLenFeature(tf.int64),\n",
    "            'answer_start_sents': tf.VarLenFeature(tf.int64),\n",
    "            'answer_start_idxs': tf.VarLenFeature(tf.int64),\n",
    "            'answer_end_sents': tf.VarLenFeature(tf.int64),\n",
    "            'answer_end_idxs': tf.VarLenFeature(tf.int64) })\n",
    "        \n",
    "        # convert to dense tensors\n",
    "        context_sizes = tf.sparse_tensor_to_dense(parsed['context_sizes'])\n",
    "        context = tf.sparse_tensor_to_dense(parsed['context_word_ids'])\n",
    "        question = tf.sparse_tensor_to_dense(parsed['question_word_ids'])\n",
    "        answer_start_sents = tf.sparse_tensor_to_dense(parsed['answer_start_sents'])\n",
    "        answer_start_words = tf.sparse_tensor_to_dense(parsed['answer_start_idxs'])\n",
    "        answer_end_sents = tf.sparse_tensor_to_dense(parsed['answer_end_sents'])\n",
    "        answer_end_words = tf.sparse_tensor_to_dense(parsed['answer_end_idxs'])\n",
    "        \n",
    "        # pad context\n",
    "        ns = tf.cast(tf.shape(context_sizes)[0], tf.int32)\n",
    "        nw = tf.cast(tf.reduce_max(context_sizes), tf.int32)\n",
    "        ps = self._hparams.context_max_len_sents - ns\n",
    "        pw = self._hparams.context_max_len_words - nw\n",
    "        context_len_sents = ns\n",
    "        context_len_words = tf.pad(context_sizes, [[0, ps]])\n",
    "        context = tf.reshape(context, [ns, nw])\n",
    "        context = tf.pad(context, [[0, ps], [0, pw]])\n",
    "\n",
    "        # pad questions\n",
    "        question_len = tf.shape(question)[0]\n",
    "        pad = [[0, self._hparams.question_max_len - question_len]]\n",
    "        question = tf.pad(question, pad, constant_values = 0)\n",
    "\n",
    "        # truncate answers (take 1st)\n",
    "        answer_start_sents = answer_start_sents[0]\n",
    "        answer_start_words = answer_start_words[0]\n",
    "        answer_end_sents = answer_end_sents[0]\n",
    "        answer_end_words = answer_end_words[0]\n",
    "\n",
    "        return (\n",
    "            context,\n",
    "            context_len_sents,\n",
    "            context_len_words,\n",
    "            question,\n",
    "            question_len,\n",
    "            answer_start_sents,\n",
    "            answer_start_words,\n",
    "            answer_end_sents,\n",
    "            answer_end_words)\n",
    "    \n",
    "    def _build_dataset_pipeline(self):\n",
    "        with tf.variable_scope('dataset'):\n",
    "            # placeholders\n",
    "            self._dataset_filenames = tf.placeholder(\n",
    "                tf.string,\n",
    "                shape = [None],\n",
    "                name = 'dataset_filenames')\n",
    "            self._dataset_limit = tf.placeholder_with_default(\n",
    "                tf.constant(-1, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_limit')\n",
    "            self._dataset_shuffle_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_shuffle_size')\n",
    "            self._dataset_batch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_batch_size')\n",
    "            self._dataset_prefetch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_prefetch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_prefetch_size')\n",
    "\n",
    "            # build dataset\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                tf.random_shuffle(self._dataset_filenames),\n",
    "                compression_type='GZIP')\n",
    "            dataset = dataset.take(self._dataset_limit)\n",
    "            dataset = dataset.map(\n",
    "                self._parse_example,\n",
    "                num_parallel_calls = self._hparams.dataset_num_parallel_calls)\n",
    "            dataset = dataset.shuffle(self._dataset_shuffle_size)\n",
    "            dataset = dataset.prefetch(self._dataset_prefetch_size)\n",
    "            dataset = dataset.batch(self._dataset_batch_size)\n",
    "\n",
    "            # build iterator\n",
    "            self._dataset_iterator = dataset.make_initializable_iterator()\n",
    "            (contexts,\n",
    "             context_len_sents,\n",
    "             context_len_words,\n",
    "             questions,\n",
    "             question_lens,\n",
    "             answer_start_sents,\n",
    "             answer_start_words,\n",
    "             answer_end_sents,\n",
    "             answer_end_words) = self._dataset_iterator.get_next()\n",
    "            \n",
    "            # get maximums for batch\n",
    "            self._context_max_sents = tf.cast(\n",
    "                tf.reduce_max(context_len_sents),\n",
    "                tf.int32,\n",
    "                name = 'context_max_sents')\n",
    "            self._context_max_words = tf.cast(\n",
    "                tf.reduce_max(context_len_words),\n",
    "                tf.int32,\n",
    "                name = 'context_max_words')\n",
    "            self._question_max_words = tf.cast(\n",
    "                tf.reduce_max(question_lens),\n",
    "                tf.int32,\n",
    "                name = 'question_max_words')\n",
    "\n",
    "            # trim tensors for efficiency\n",
    "            contexts = contexts[:, :self._context_max_sents, :self._context_max_words]\n",
    "            questions = questions[:, :self._question_max_words]\n",
    "            context_len_words = context_len_words[:, :self._context_max_sents]\n",
    "            \n",
    "            # give tensors names\n",
    "            self._contexts = tf.identity(contexts, 'contexts')\n",
    "            self._context_len_sents = tf.identity(context_len_sents, 'context_len_sents')\n",
    "            self._context_len_words = tf.identity(context_len_words, 'context_len_words')\n",
    "            self._questions = tf.identity(questions, 'questions')\n",
    "            self._question_lens = tf.identity(question_lens, 'question_lens')\n",
    "            self._answer_start_sents = tf.identity(answer_start_sents, 'answer_start_sents')\n",
    "            self._answer_start_words = tf.identity(answer_start_words, 'answer_start_words')\n",
    "            self._answer_end_sents = tf.identity(answer_end_sents, 'answer_end_sents')\n",
    "            self._answer_end_words = tf.identity(answer_end_words, 'answer_end_words')\n",
    "            \n",
    "            # masks\n",
    "            self._context_masks = tf.sequence_mask(\n",
    "                self._context_len_words,\n",
    "                maxlen = self._context_max_words,\n",
    "                dtype = tf.float32,\n",
    "                name = 'context_masks')\n",
    "            self._question_masks = tf.sequence_mask(\n",
    "                self._question_lens,\n",
    "                maxlen = self._question_max_words,\n",
    "                dtype = tf.float32,\n",
    "                name = 'question_masks')\n",
    "            \n",
    "            # count number of examples\n",
    "            self._num_examples = tf.shape(self._contexts)[0]\n",
    "            self._num_examples = tf.identity(self._num_examples, 'num_examples')\n",
    "        \n",
    "    def _build_model_embed(self, contexts, questions):\n",
    "        with tf.variable_scope('embed'):\n",
    "            # word embedding\n",
    "            word_embeddings_pretrained = tf.get_variable(\n",
    "                name = \"word_embeddings_pretrained\",\n",
    "                shape = self._word_embeddings_pretrained.shape,\n",
    "                initializer = tf.constant_initializer(self._word_embeddings_pretrained),\n",
    "                trainable = False)\n",
    "            s = self._word_embeddings_pretrained.shape\n",
    "            word_embeddings_new = tf.get_variable(\n",
    "                name = 'word_embeddings_new',\n",
    "                shape = [self._hparams.vocab_size - s[0], s[1]])\n",
    "            word_embeddings = tf.concat(\n",
    "                [word_embeddings_pretrained, word_embeddings_new],\n",
    "                axis = 0)\n",
    "\n",
    "            # embed questions/contexts\n",
    "            contexts_embedded = tf.nn.embedding_lookup(\n",
    "                word_embeddings,\n",
    "                contexts)\n",
    "            questions_embedded = tf.nn.embedding_lookup(\n",
    "                word_embeddings,\n",
    "                questions)\n",
    "\n",
    "            return contexts_embedded, questions_embedded\n",
    "    \n",
    "    def _rnn_layer(self, layer, num_rnn_layers = 1):\n",
    "        # get (static) layer size\n",
    "        size = layer.shape[-1].value\n",
    "\n",
    "        # LSTM\n",
    "        lstm = tf.contrib.cudnn_rnn.CudnnLSTM(\n",
    "            num_layers = num_rnn_layers,\n",
    "            num_units = size,\n",
    "            input_size = size,\n",
    "            # TODO: dropout\n",
    "            input_mode = 'skip_input',\n",
    "            direction = 'bidirectional')\n",
    "\n",
    "        # variables\n",
    "        lstm_params = tf.get_variable(\n",
    "            'lstm_params',\n",
    "            [lstm.params_size().eval(session = self._session)])\n",
    "        lstm_input_h = tf.get_variable(\n",
    "            'lstm_input_h',\n",
    "            [2 * num_rnn_layers, size])\n",
    "        lstm_input_c = tf.get_variable(\n",
    "            'lstm_input_c',\n",
    "            [2 * num_rnn_layers, size])\n",
    "\n",
    "        # make input data time-major\n",
    "        input_data = tf.transpose(layer, perm = [1, 0, 2])\n",
    "\n",
    "        # tile input hidden states\n",
    "        input_h = tf.expand_dims(lstm_input_h, 1)\n",
    "        input_h = tf.tile(input_h, [1, tf.shape(layer)[0], 1])\n",
    "        input_c = tf.expand_dims(lstm_input_c, 1)\n",
    "        input_c = tf.tile(input_c, [1, tf.shape(layer)[0], 1])\n",
    "\n",
    "        # run LSTM\n",
    "        outputs, _, _ = lstm(input_data, input_h, input_c, lstm_params)\n",
    "\n",
    "        # undo time-major\n",
    "        outputs = tf.transpose(outputs, perm = [1, 0, 2])\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def _ffn_layer(self, layer, hidden_size = None):\n",
    "        # design of FFN from: https://arxiv.org/abs/1603.05027\n",
    "        \n",
    "        # get hidden size\n",
    "        if hidden_size is None:\n",
    "            hidden_size = layer.shape[-1].value * 2\n",
    "        \n",
    "        # save original layer\n",
    "        orig_layer = layer\n",
    "            \n",
    "        # BN\n",
    "        layer = tf.layers.batch_normalization(\n",
    "            layer,\n",
    "            training = self._training)\n",
    "        \n",
    "        # relu\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "        # hidden\n",
    "        layer = tf.layers.dense(\n",
    "            layer,\n",
    "            hidden_size,\n",
    "            name = 'hidden')\n",
    "        \n",
    "        # BN\n",
    "        layer = tf.layers.batch_normalization(\n",
    "            layer,\n",
    "            training = self._training)\n",
    "\n",
    "        # weight\n",
    "        layer = tf.layers.dense(\n",
    "            layer,\n",
    "            orig_layer.shape[-1].value,\n",
    "            name = 'output')\n",
    "        \n",
    "        # add residual\n",
    "        return orig_layer + layer\n",
    "    \n",
    "    def _build_model_encode(self, contexts, questions):\n",
    "        with tf.variable_scope('encoding'):\n",
    "            c = contexts\n",
    "            q = questions\n",
    "\n",
    "            # apply FFN (w/ shared weights)\n",
    "            for i in range(self._hparams.encoding_num_ffn_layers):\n",
    "                with tf.variable_scope('fnn_%d' % i):\n",
    "                    c = self._ffn_layer(c)\n",
    "                with tf.variable_scope('fnn_%d' % i, reuse = True):\n",
    "                    q = self._ffn_layer(q)\n",
    "            \n",
    "            # apply RNN (w/ shared weights)\n",
    "            with tf.variable_scope('rnn'):\n",
    "                # flatten before applying RNN\n",
    "                c = tf.reshape(c, [\n",
    "                    self._num_examples * self._context_max_sents,\n",
    "                    self._context_max_words,\n",
    "                    c.shape[-1].value])\n",
    "                c = self._rnn_layer(c, self._hparams.encoding_num_rnn_layers)\n",
    "                # unflatten\n",
    "                c = tf.reshape(c, [\n",
    "                    self._num_examples,\n",
    "                    self._context_max_sents,\n",
    "                    self._context_max_words,\n",
    "                    c.shape[-1].value])\n",
    "            with tf.variable_scope('rnn', reuse = True):\n",
    "                q = self._rnn_layer(q, self._hparams.encoding_num_rnn_layers)\n",
    "\n",
    "            # apply masks\n",
    "            c *= tf.expand_dims(self._context_masks, axis = -1)\n",
    "            q *= tf.expand_dims(self._question_masks, axis = -1)\n",
    "\n",
    "            return c, q\n",
    "        \n",
    "    def _build_model_attn(self, contexts, questions):\n",
    "        with tf.variable_scope('attn'):\n",
    "            # grab layer size\n",
    "            size = contexts.shape[-1].value\n",
    "            assert questions.shape[-1].value == size\n",
    "\n",
    "            # project\n",
    "            c = tf.layers.dense(contexts, size, name = 'proj')\n",
    "            q = tf.layers.dense(questions, size, name = 'proj', reuse = True)\n",
    "            \n",
    "            # flatten contexts\n",
    "            c = tf.reshape(contexts, [                  # [batch, c_sents*c_words, size]\n",
    "                self._num_examples,\n",
    "                self._context_max_sents * self._context_max_words,\n",
    "                size])\n",
    "            \n",
    "            # compute weights\n",
    "            q_T = tf.transpose(q, perm = [0, 2, 1])     # [batch, size, q_words]\n",
    "            w = tf.matmul(c, q_T)                       # [batch, c_sents*c_words, q_words]\n",
    "            w /= np.sqrt(size)\n",
    "            \n",
    "            # context-to-query attention\n",
    "            c2q = tf.nn.softmax(w)\n",
    "            c2q_attn = tf.matmul(c2q, q)                # [batch, c_sents*c_words, q_words]\n",
    "            c2q_attn = tf.reshape(c2q_attn, [           # [batch, c_sents, c_words, size]\n",
    "                self._num_examples,\n",
    "                self._context_max_sents,\n",
    "                self._context_max_words,\n",
    "                size])\n",
    "            \n",
    "            # query-to-context attention\n",
    "            q2c = tf.transpose(w, perm = [0, 2, 1])     # [batch, q_words, c_sents*c_words]\n",
    "            q2c = tf.nn.softmax(q2c)\n",
    "            q2c_attn = tf.matmul(q2c, c)                # [batch, q_words, size]\n",
    "            \n",
    "            # apply masks\n",
    "            c2q_attn *= tf.expand_dims(self._context_masks, axis = -1)\n",
    "            q2c_attn *= tf.expand_dims(self._question_masks, axis = -1)\n",
    "            \n",
    "            return c2q_attn, q2c_attn\n",
    "        \n",
    "    def _build_model_memory(self, contexts, questions, c2q_attn, q2c_attn):\n",
    "        with tf.variable_scope('memory'):\n",
    "            # build summary of question\n",
    "            q = tf.concat([questions, q2c_attn], axis = -1)\n",
    "            w = tf.layers.dense(q, 1, name = 'proj')    # [batch, q_words, 1]\n",
    "            w = tf.nn.softmax(w, dim = 1)\n",
    "            q *= w\n",
    "            q = tf.reduce_sum(q, axis = 1)              # [batch, size]\n",
    "            \n",
    "            # tile question summary\n",
    "            q = tf.expand_dims(q, 1)\n",
    "            q = tf.expand_dims(q, 1)                    # [batch, 1, 1, size]\n",
    "            q = tf.tile(q, [                            # [batch, c_sents, c_words, size*2]\n",
    "                1,\n",
    "                self._context_max_sents,\n",
    "                self._context_max_words,\n",
    "                1])\n",
    "\n",
    "            # build final context input\n",
    "            c = tf.concat(                              # [batch, c_sents, c_words, size*4]\n",
    "                [contexts, c2q_attn, q],\n",
    "                axis = -1)\n",
    "            c = tf.reshape(c, [                         # [batch, c_sents*c_words, size*4]\n",
    "                self._num_examples,\n",
    "                self._context_max_sents * self._context_max_words,\n",
    "                c.shape[-1].value])\n",
    "\n",
    "            # fully connected layer\n",
    "            c = tf.layers.dense(\n",
    "                c,\n",
    "                200,\n",
    "                activation = tf.nn.relu, # ???\n",
    "                name = 'fc1')\n",
    "            \n",
    "            # apply RNN\n",
    "            with tf.variable_scope('rnn'):\n",
    "                m = self._rnn_layer(\n",
    "                    c,\n",
    "                    self._hparams.memory_num_rnn_layers)\n",
    "                \n",
    "            return m\n",
    "    \n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('model'):\n",
    "            # placeholders\n",
    "            self._training = tf.placeholder(tf.bool, name = 'training')\n",
    "\n",
    "            # embed contexts/questions\n",
    "            c_embedded, q_embedded = self._build_model_embed(self._contexts, self._questions)\n",
    "            \n",
    "            # encode contexts/questions\n",
    "            c_encoded, q_encoded = self._build_model_encode(c_embedded, q_embedded)\n",
    "\n",
    "            # compute c2q & q2c attention\n",
    "            c2q_attn, q2c_attn = self._build_model_attn(c_encoded, q_encoded)\n",
    "\n",
    "            # compute final memory\n",
    "            memory = self._build_model_memory(c_encoded, q_encoded, c2q_attn, q2c_attn)\n",
    "            \n",
    "            # answer logits\n",
    "            self._answer_start_logits = tf.layers.dense(memory, 1, use_bias = False)\n",
    "            self._answer_start_logits = tf.squeeze(\n",
    "                self._answer_start_logits,\n",
    "                axis = -1,\n",
    "                name = 'answer_start_logits')\n",
    "            \n",
    "    def _build_optimizer(self):\n",
    "        with tf.variable_scope('optimize'):\n",
    "            # compute answer starts\n",
    "            a_starts = (self._answer_start_sents\n",
    "                * tf.cast(self._context_max_words, tf.int64)\n",
    "                + self._answer_start_words)\n",
    "            self._a_starts = a_starts\n",
    "            \n",
    "            # individual losses\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = a_starts,\n",
    "                logits = self._answer_start_logits)\n",
    "\n",
    "            # total loss\n",
    "            self._total_loss = tf.reduce_sum(losses)\n",
    "            self._total_loss = tf.identity(self._total_loss, 'total_loss')\n",
    "            \n",
    "            # mean loss\n",
    "            self._mean_loss = self._total_loss / tf.cast(self._num_examples, tf.float32)\n",
    "            self._mean_loss = tf.identity(self._mean_loss, 'mean_loss')\n",
    "            \n",
    "            # start/end probabilities/estimates\n",
    "            self._answer_start_probs = tf.nn.softmax(\n",
    "                self._answer_start_logits,\n",
    "                name = 'answer_start_logits')\n",
    "            self._answer_start_estimates = tf.argmax(\n",
    "                self._answer_start_probs,\n",
    "                axis = -1,\n",
    "                name = 'answer_start_estimates')\n",
    "            \n",
    "            # exact match accuracy\n",
    "            answer_starts_eq = tf.equal(\n",
    "                a_starts,\n",
    "                self._answer_start_estimates)\n",
    "            self._total_exact_matches = tf.reduce_sum(\n",
    "                tf.cast(answer_starts_eq, tf.int64),\n",
    "                name = 'total_exact_matches')\n",
    "            \n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self._global_step = tf.Variable(0, name = 'global_step', trainable = False)\n",
    "                self._optimizer = tf.train.AdamOptimizer(learning_rate = self._hparams.learning_rate)\n",
    "                \n",
    "                # gradient clipping\n",
    "                gradients, variables = zip(*self._optimizer.compute_gradients(self._mean_loss))\n",
    "                gradients, _ = tf.clip_by_global_norm(\n",
    "                    gradients, \n",
    "                    self._hparams.gradient_clip_norm)\n",
    "                \n",
    "                self._train_op = self._optimizer.apply_gradients(\n",
    "                    zip(gradients, variables),\n",
    "                    global_step = self._global_step)\n",
    "                \n",
    "    def process(self,\n",
    "                dataset_filenames,\n",
    "                dataset_limit = -1,\n",
    "                header = 'results',\n",
    "                train = False,\n",
    "                log_file = None):\n",
    "        # initialize dataset to files\n",
    "        self._session.run(self._dataset_iterator.initializer, feed_dict={\n",
    "            self._dataset_filenames: dataset_filenames,\n",
    "            self._dataset_limit: dataset_limit })\n",
    "\n",
    "        cum_loss = 0\n",
    "        cum_num_examples = 0\n",
    "        cum_exact_matches = 0\n",
    "        \n",
    "        # start progress\n",
    "        start = datetime.datetime.now()\n",
    "        progress = tqdm_notebook(leave = False, desc = header)\n",
    "\n",
    "        while True:\n",
    "            # process a minibatch\n",
    "            try:\n",
    "                (_,\n",
    "                 curr_total_loss,\n",
    "                 curr_exact_matches,\n",
    "                 curr_num_examples) = self._session.run(\n",
    "                    (self._train_op if train else (),\n",
    "                     self._total_loss,\n",
    "                     self._total_exact_matches,\n",
    "                     self._num_examples),\n",
    "                    feed_dict = { self._training: train })\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "            # update loss stats\n",
    "            cum_loss += curr_total_loss\n",
    "            cum_exact_matches += curr_exact_matches\n",
    "            cum_num_examples += curr_num_examples\n",
    "            \n",
    "            # update progress\n",
    "            progress.update(curr_num_examples)\n",
    "            progress.set_postfix(loss = cum_loss / cum_num_examples)\n",
    "\n",
    "        # end progress\n",
    "        progress.close()\n",
    "        finish = datetime.datetime.now()\n",
    "        \n",
    "        # print/log output\n",
    "        message = '%s: time=%s, step=%d, loss=%g, exact_match=%g' % (\n",
    "            header,\n",
    "            finish - start,\n",
    "            tf.train.global_step(sess, self._global_step),\n",
    "            cum_loss / cum_num_examples,\n",
    "            cum_exact_matches / cum_num_examples)\n",
    "        print(message)\n",
    "        if log_file:\n",
    "            print(message, file=log_file)\n",
    "            log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../../data/SQuAD/data_2.vocab.embeddings.npy.gz', 'rb') as f:\n",
    "    word_embeddings = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    return sorted([os.path.join(path, file) for file in os.listdir(path)])\n",
    "\n",
    "train_set = list_files('../../data/SQuAD/data_2.train')\n",
    "dev_set = list_files('../../data/SQuAD/data_2.dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for \"model/embed/word_embeddings_new:0\": 1820500\n",
      "parameters for \"model/encoding/fnn_0/batch_normalization/gamma:0\": 100\n",
      "parameters for \"model/encoding/fnn_0/batch_normalization/beta:0\": 100\n",
      "parameters for \"model/encoding/fnn_0/hidden/kernel:0\": 20000\n",
      "parameters for \"model/encoding/fnn_0/hidden/bias:0\": 200\n",
      "parameters for \"model/encoding/fnn_0/batch_normalization_1/gamma:0\": 200\n",
      "parameters for \"model/encoding/fnn_0/batch_normalization_1/beta:0\": 200\n",
      "parameters for \"model/encoding/fnn_0/output/kernel:0\": 20000\n",
      "parameters for \"model/encoding/fnn_0/output/bias:0\": 100\n",
      "parameters for \"model/encoding/fnn_1/batch_normalization/gamma:0\": 100\n",
      "parameters for \"model/encoding/fnn_1/batch_normalization/beta:0\": 100\n",
      "parameters for \"model/encoding/fnn_1/hidden/kernel:0\": 20000\n",
      "parameters for \"model/encoding/fnn_1/hidden/bias:0\": 200\n",
      "parameters for \"model/encoding/fnn_1/batch_normalization_1/gamma:0\": 200\n",
      "parameters for \"model/encoding/fnn_1/batch_normalization_1/beta:0\": 200\n",
      "parameters for \"model/encoding/fnn_1/output/kernel:0\": 20000\n",
      "parameters for \"model/encoding/fnn_1/output/bias:0\": 100\n",
      "parameters for \"model/encoding/rnn/lstm_params:0\": 323200\n",
      "parameters for \"model/encoding/rnn/lstm_input_h:0\": 400\n",
      "parameters for \"model/encoding/rnn/lstm_input_c:0\": 400\n",
      "parameters for \"model/attn/proj/kernel:0\": 40000\n",
      "parameters for \"model/attn/proj/bias:0\": 200\n",
      "parameters for \"model/memory/proj/kernel:0\": 400\n",
      "parameters for \"model/memory/proj/bias:0\": 1\n",
      "parameters for \"model/memory/fc1/kernel:0\": 160000\n",
      "parameters for \"model/memory/fc1/bias:0\": 200\n",
      "parameters for \"model/memory/rnn/lstm_params:0\": 323200\n",
      "parameters for \"model/memory/rnn/lstm_input_h:0\": 400\n",
      "parameters for \"model/memory/rnn/lstm_input_c:0\": 400\n",
      "parameters for \"model/dense/kernel:0\": 400\n",
      "total parameters: 2751501\n"
     ]
    }
   ],
   "source": [
    "sess = reset_tf(sess)\n",
    "\n",
    "model = RnnModel(sess, word_embeddings, HyperParameters())\n",
    "model._build_dataset_pipeline()\n",
    "model._build_model()\n",
    "model._build_optimizer()\n",
    "dump_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feaa0f9aff0246809954d8920e79df78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_0', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to call ThenRnnBackward\n\t [[Node: optimize/gradients/model/memory/rnn/CudnnRNN_grad/CudnnRNNBackprop = CudnnRNNBackprop[T=DT_FLOAT, direction=\"bidirectional\", dropout=0, input_mode=\"skip_input\", rnn_mode=\"lstm\", seed=0, seed2=2147483647, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/memory/rnn/transpose, model/memory/rnn/Tile, model/memory/rnn/Tile_1, model/memory/rnn/lstm_params/read, model/memory/rnn/CudnnRNN, model/memory/rnn/CudnnRNN:1, model/memory/rnn/CudnnRNN:2, optimize/gradients/model/memory/rnn/transpose_1_grad/transpose, optimize/gradients/zeros_like_1, optimize/gradients/zeros_like_2, model/memory/rnn/CudnnRNN:3)]]\n\t [[Node: optimize/Adam/update/_622 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_13652_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'optimize/gradients/model/memory/rnn/CudnnRNN_grad/CudnnRNNBackprop', defined at:\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-bedad5fd0a7e>\", line 6, in <module>\n    model._build_optimizer()\n  File \"<ipython-input-4-4f3842a23db8>\", line 444, in _build_optimizer\n    gradients, variables = zip(*self._optimizer.compute_gradients(self._mean_loss))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1572, in _cudnn_rnn_backward\n    direction=op.get_attr(\"direction\"))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/ops/gen_cudnn_rnn_ops.py\", line 227, in cudnn_rnn_backprop\n    dropout=dropout, seed=seed, seed2=seed2, name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'model/memory/rnn/CudnnRNN', defined at:\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-bedad5fd0a7e>\", line 5, in <module>\n    model._build_model()\n  File \"<ipython-input-4-4f3842a23db8>\", line 391, in _build_model\n    memory = self._build_model_memory(c_encoded, q_encoded, c2q_attn, q2c_attn)\n  File \"<ipython-input-4-4f3842a23db8>\", line 372, in _build_model_memory\n    self._hparams.memory_num_rnn_layers)\n  File \"<ipython-input-4-4f3842a23db8>\", line 213, in _rnn_layer\n    outputs, _, _ = lstm(input_data, input_h, input_c, lstm_params)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1443, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1334, in __call__\n    seed=self._seed)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 823, in _cudnn_rnn\n    name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/ops/gen_cudnn_rnn_ops.py\", line 105, in cudnn_rnn\n    is_training=is_training, name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n\nInternalError (see above for traceback): Failed to call ThenRnnBackward\n\t [[Node: optimize/gradients/model/memory/rnn/CudnnRNN_grad/CudnnRNNBackprop = CudnnRNNBackprop[T=DT_FLOAT, direction=\"bidirectional\", dropout=0, input_mode=\"skip_input\", rnn_mode=\"lstm\", seed=0, seed2=2147483647, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/memory/rnn/transpose, model/memory/rnn/Tile, model/memory/rnn/Tile_1, model/memory/rnn/lstm_params/read, model/memory/rnn/CudnnRNN, model/memory/rnn/CudnnRNN:1, model/memory/rnn/CudnnRNN:2, optimize/gradients/model/memory/rnn/transpose_1_grad/transpose, optimize/gradients/zeros_like_1, optimize/gradients/zeros_like_2, model/memory/rnn/CudnnRNN:3)]]\n\t [[Node: optimize/Adam/update/_622 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_13652_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to call ThenRnnBackward\n\t [[Node: optimize/gradients/model/memory/rnn/CudnnRNN_grad/CudnnRNNBackprop = CudnnRNNBackprop[T=DT_FLOAT, direction=\"bidirectional\", dropout=0, input_mode=\"skip_input\", rnn_mode=\"lstm\", seed=0, seed2=2147483647, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/memory/rnn/transpose, model/memory/rnn/Tile, model/memory/rnn/Tile_1, model/memory/rnn/lstm_params/read, model/memory/rnn/CudnnRNN, model/memory/rnn/CudnnRNN:1, model/memory/rnn/CudnnRNN:2, optimize/gradients/model/memory/rnn/transpose_1_grad/transpose, optimize/gradients/zeros_like_1, optimize/gradients/zeros_like_2, model/memory/rnn/CudnnRNN:3)]]\n\t [[Node: optimize/Adam/update/_622 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_13652_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cd663bb23665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train_%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             log_file = f)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#         model.process(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#             dev_set,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4f3842a23db8>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, dataset_filenames, dataset_limit, header, train, log_file)\u001b[0m\n\u001b[1;32m    481\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_exact_matches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                      self._num_examples),\n\u001b[0;32m--> 483\u001b[0;31m                     feed_dict = { self._training: train })\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to call ThenRnnBackward\n\t [[Node: optimize/gradients/model/memory/rnn/CudnnRNN_grad/CudnnRNNBackprop = CudnnRNNBackprop[T=DT_FLOAT, direction=\"bidirectional\", dropout=0, input_mode=\"skip_input\", rnn_mode=\"lstm\", seed=0, seed2=2147483647, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/memory/rnn/transpose, model/memory/rnn/Tile, model/memory/rnn/Tile_1, model/memory/rnn/lstm_params/read, model/memory/rnn/CudnnRNN, model/memory/rnn/CudnnRNN:1, model/memory/rnn/CudnnRNN:2, optimize/gradients/model/memory/rnn/transpose_1_grad/transpose, optimize/gradients/zeros_like_1, optimize/gradients/zeros_like_2, model/memory/rnn/CudnnRNN:3)]]\n\t [[Node: optimize/Adam/update/_622 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_13652_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'optimize/gradients/model/memory/rnn/CudnnRNN_grad/CudnnRNNBackprop', defined at:\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-bedad5fd0a7e>\", line 6, in <module>\n    model._build_optimizer()\n  File \"<ipython-input-4-4f3842a23db8>\", line 444, in _build_optimizer\n    gradients, variables = zip(*self._optimizer.compute_gradients(self._mean_loss))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1572, in _cudnn_rnn_backward\n    direction=op.get_attr(\"direction\"))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/ops/gen_cudnn_rnn_ops.py\", line 227, in cudnn_rnn_backprop\n    dropout=dropout, seed=seed, seed2=seed2, name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'model/memory/rnn/CudnnRNN', defined at:\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-bedad5fd0a7e>\", line 5, in <module>\n    model._build_model()\n  File \"<ipython-input-4-4f3842a23db8>\", line 391, in _build_model\n    memory = self._build_model_memory(c_encoded, q_encoded, c2q_attn, q2c_attn)\n  File \"<ipython-input-4-4f3842a23db8>\", line 372, in _build_model_memory\n    self._hparams.memory_num_rnn_layers)\n  File \"<ipython-input-4-4f3842a23db8>\", line 213, in _rnn_layer\n    outputs, _, _ = lstm(input_data, input_h, input_c, lstm_params)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1443, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1334, in __call__\n    seed=self._seed)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 823, in _cudnn_rnn\n    name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/ops/gen_cudnn_rnn_ops.py\", line 105, in cudnn_rnn\n    is_training=is_training, name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n\nInternalError (see above for traceback): Failed to call ThenRnnBackward\n\t [[Node: optimize/gradients/model/memory/rnn/CudnnRNN_grad/CudnnRNNBackprop = CudnnRNNBackprop[T=DT_FLOAT, direction=\"bidirectional\", dropout=0, input_mode=\"skip_input\", rnn_mode=\"lstm\", seed=0, seed2=2147483647, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/memory/rnn/transpose, model/memory/rnn/Tile, model/memory/rnn/Tile_1, model/memory/rnn/lstm_params/read, model/memory/rnn/CudnnRNN, model/memory/rnn/CudnnRNN:1, model/memory/rnn/CudnnRNN:2, optimize/gradients/model/memory/rnn/transpose_1_grad/transpose, optimize/gradients/zeros_like_1, optimize/gradients/zeros_like_2, model/memory/rnn/CudnnRNN:3)]]\n\t [[Node: optimize/Adam/update/_622 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_13652_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with open('../../logs/SQuAD/model_rnn_3.1.log', 'wt') as f:\n",
    "    for i in range(20):\n",
    "        model.process(\n",
    "            train_set,\n",
    "            header = 'train_%d' % i,\n",
    "            train = True,\n",
    "            log_file = f)\n",
    "#         model.process(\n",
    "#             dev_set,\n",
    "#             header = 'dev_%d' % i,\n",
    "#             train = False,\n",
    "#             log_file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(\n",
    "    model._dataset_iterator.initializer,\n",
    "    feed_dict = {\n",
    "        model._dataset_filenames: train_set[:1],\n",
    "        model._dataset_limit: 10 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, context_lens, questions, question_lens, answer_starts, answer_ends, answer_start_estimates, answer_end_estimates = sess.run(\n",
    "    [model._contexts,\n",
    "     model._context_lens,\n",
    "     model._questions,\n",
    "     model._question_lens,\n",
    "     model._answer_starts,\n",
    "     model._answer_ends,\n",
    "     model._answer_start_estimates,\n",
    "     model._answer_end_estimates],\n",
    "    feed_dict = { model._training: False })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5,  571,    2, ...,    0,    0,    0],\n",
       "       [  36, 1448, 2230, ...,    0,    0,    0],\n",
       "       [   5, 3769,   87, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  69,   77,   37, ...,    0,    0,    0],\n",
       "       [   1, 9191, 2659, ...,    0,    0,    0],\n",
       "       [ 181,  832,  562, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 29,   5,  78,  43,  34,  25, 124, 117,  55, 110])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65,   4,  78,  49,  80, 181, 123, 117,  52, 110])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_starts[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 67,   5,  78,  49,  80, 189, 124, 117,  55, 110])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_ends[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = reset_tf(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = tf.contrib.cudnn_rnn.CudnnGRU(\n",
    "    num_layers = 1,\n",
    "    num_units = 50,\n",
    "    input_size = 100,\n",
    "    direction = 'bidirectional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45600"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.params_size().eval(session = sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_params = tf.get_variable(\n",
    "    'gru_params',\n",
    "    [gru.params_size().eval()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_h = tf.cast(np.random.rand(2, 30, 50), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.cast(np.random.rand(20, 30, 100), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(20), Dimension(30), Dimension(100)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gru(input_data, input_h, gru_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'CudnnRNN_5:0' shape=(20, 30, 100) dtype=float32>,\n",
       " <tf.Tensor 'CudnnRNN_5:1' shape=(2, 30, 50) dtype=float32>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 30, 100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CudnnGRU in module tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops:\n",
      "\n",
      "class CudnnGRU(_CudnnRNNNoInputC)\n",
      " |  Cudnn implementation of the GRU model.\n",
      " |  Cudnn RNN has an opaque parameter buffer that can be used for inference and\n",
      " |  training. But it is possible that the layout of the parameter buffers\n",
      " |  changes between generations. So it is highly recommended to use\n",
      " |  CudnnOpaqueParamsSaveable to save and restore weights and biases in a\n",
      " |  canonical format.\n",
      " |  \n",
      " |  This is a typical use case:\n",
      " |  \n",
      " |    * The user creates a CudnnRNN model.\n",
      " |    * The user query that parameter buffer size.\n",
      " |    * The user creates a variable of that size that serves as the parameter\n",
      " |        buffers.\n",
      " |    * The user either initialize the parameter buffer, or load the canonical\n",
      " |        weights into the parameter buffer.\n",
      " |    * The user calls the model with the parameter buffer for inference, or\n",
      " |        training.\n",
      " |    * If training, the user creates a Saver object.\n",
      " |    * If training, the user creates a CudnnOpaqueParamsSaveable object from the\n",
      " |        parameter buffer for it to be later saved in the canonical format. When\n",
      " |        creating a CudnnOpaqueParamsSaveable object, a name could be provided,\n",
      " |        which is useful in distinguishing the names of multiple\n",
      " |        CudnnOpaqueParamsSaveable objects (e.g. for an encoder-decoder model).\n",
      " |    * Once a while, the user saves the parameter buffer into model checkpoints\n",
      " |        with Saver.save().\n",
      " |    * When restoring, the user creates a CudnnOpaqueParamsSaveable object and\n",
      " |      uses Saver.restore() to restore the parameter buffer from the canonical\n",
      " |      format to a user-defined format, as well as to restore other savable\n",
      " |      objects in the checkpoint file.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CudnnGRU\n",
      " |      _CudnnRNNNoInputC\n",
      " |      _CudnnRNN\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from _CudnnRNNNoInputC:\n",
      " |  \n",
      " |  __call__(self, input_data, input_h, params, is_training=True)\n",
      " |      Runs the forward step for the Cudnn LSTM model.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_data: the input sequence to the RNN model. A Tensor of shape [?,\n",
      " |          batch_size, input_size].\n",
      " |        input_h: the initial hidden state for h. A Tensor of shape [num_layers,\n",
      " |          batch_size, num_units].\n",
      " |        params: the parameter buffer created for this model.\n",
      " |        is_training: whether this operation will be used in training or inference.\n",
      " |      Returns:\n",
      " |        output: the output sequuence.\n",
      " |        output_h: the final state for h.\n",
      " |  \n",
      " |  __init__(self, num_layers, num_units, input_size, input_mode='linear_input', direction='unidirectional', dtype=tf.float32, dropout=0.0, seed=0)\n",
      " |      Creates a Cudnn RNN model from model without hidden-state C.\n",
      " |      \n",
      " |      Args:\n",
      " |        num_layers: the number of layers for the RNN model.\n",
      " |        num_units: the number of units within the RNN model.\n",
      " |        input_size: the size of the input, it could be different from the\n",
      " |            num_units.\n",
      " |        input_mode: indicate whether there is a linear projection between the\n",
      " |            input and The actual computation before the first layer. It could be\n",
      " |            'skip_input', 'linear_input' or 'auto_select'.\n",
      " |            'skip_input' is only allowed when input_size == num_units;\n",
      " |            'auto_select' implies 'skip_input' when input_size == num_units;\n",
      " |            otherwise, it implies 'linear_input'.\n",
      " |        direction: the direction model that the model operates. Could be either\n",
      " |            'unidirectional' or 'bidirectional'\n",
      " |        dtype: dtype of params, tf.float32 or tf.float64.\n",
      " |        dropout: whether to enable dropout. With it is 0, dropout is disabled.\n",
      " |        seed: the seed used for initializing dropout.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if direction is not 'unidirectional' or 'bidirectional'.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _CudnnRNN:\n",
      " |  \n",
      " |  canonical_to_params(self, weights, biases)\n",
      " |      Converts params from the canonical format to a specific format of cuDNN.\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a Tensor for weight parameters.\n",
      " |        biases: a Tensor for bias parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function for the canonical-to-params-to-specific conversion..\n",
      " |  \n",
      " |  params_size(self)\n",
      " |      Calculates the size of the opaque parameter buffer needed for this model.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The calculated parameter buffer size.\n",
      " |  \n",
      " |  params_to_canonical(self, params)\n",
      " |      Converts params from a specific format of cuDNN to the canonical format.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: a Variable for weight and bias parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function for the specific-to-canonical conversion.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _CudnnRNN:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  direction\n",
      " |  \n",
      " |  input_mode\n",
      " |  \n",
      " |  input_size\n",
      " |  \n",
      " |  num_layers\n",
      " |  \n",
      " |  num_units\n",
      " |  \n",
      " |  rnn_mode\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.contrib.cudnn_rnn.CudnnGRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [4, 5, 6, 7]], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(tf.reshape(tf.range(2*4), [2, 1, 4]), [1, 3, 1]).eval()[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims:0' shape=(2, 1, 4) dtype=int32>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf.reshape(tf.range(2*4), [2, 4]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(tf.range(2*4), [2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1],\n",
       "        [4, 5]], dtype=int32), array([[2, 3],\n",
       "        [6, 7]], dtype=int32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :2].eval(), x[:, 2:].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [4, 5, 6, 7]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x, y = 2*x):\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul:0' shape=(2, 4) dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = tf.contrib.cudnn_rnn.CudnnGRU(\n",
    "    num_layers = 1,\n",
    "    num_units = 10,\n",
    "    input_size = 10,\n",
    "    dropout = 0.5,\n",
    "    direction = 'bidirectional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.params_size().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.cast(tf.reshape(tf.range(2*4), [2, 4]), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.expand_dims(x, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(4), Dimension(1)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0320586 ],\n",
       "        [0.08714432],\n",
       "        [0.23688284],\n",
       "        [0.6439143 ]],\n",
       "\n",
       "       [[0.0320586 ],\n",
       "        [0.08714432],\n",
       "        [0.23688284],\n",
       "        [0.6439143 ]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(y, 1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CudnnLSTM in module tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops:\n",
      "\n",
      "class CudnnLSTM(_CudnnRNN)\n",
      " |  Cudnn implementation of the LSTM model.\n",
      " |  Cudnn RNN has an opaque parameter buffer that can be used for inference and\n",
      " |  training. But it is possible that the layout of the parameter buffers\n",
      " |  changes between generations. So it is highly recommended to use\n",
      " |  CudnnOpaqueParamsSaveable to save and restore weights and biases in a\n",
      " |  canonical format.\n",
      " |  \n",
      " |  This is a typical use case:\n",
      " |  \n",
      " |    * The user creates a CudnnRNN model.\n",
      " |    * The user query that parameter buffer size.\n",
      " |    * The user creates a variable of that size that serves as the parameter\n",
      " |        buffers.\n",
      " |    * The user either initialize the parameter buffer, or load the canonical\n",
      " |        weights into the parameter buffer.\n",
      " |    * The user calls the model with the parameter buffer for inference, or\n",
      " |        training.\n",
      " |    * If training, the user creates a Saver object.\n",
      " |    * If training, the user creates a CudnnOpaqueParamsSaveable object from the\n",
      " |        parameter buffer for it to be later saved in the canonical format. When\n",
      " |        creating a CudnnOpaqueParamsSaveable object, a name could be provided,\n",
      " |        which is useful in distinguishing the names of multiple\n",
      " |        CudnnOpaqueParamsSaveable objects (e.g. for an encoder-decoder model).\n",
      " |    * Once a while, the user saves the parameter buffer into model checkpoints\n",
      " |        with Saver.save().\n",
      " |    * When restoring, the user creates a CudnnOpaqueParamsSaveable object and\n",
      " |      uses Saver.restore() to restore the parameter buffer from the canonical\n",
      " |      format to a user-defined format, as well as to restore other savable\n",
      " |      objects in the checkpoint file.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CudnnLSTM\n",
      " |      _CudnnRNN\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, input_data, input_h, input_c, params, is_training=True)\n",
      " |      Runs the forward step for the Cudnn LSTM model.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_data: the input sequence to the LSTM model. A Tensor of shape [?,\n",
      " |          batch_size, input_size].\n",
      " |        input_h: the initial hidden state for h. A Tensor of shape [num_layers,\n",
      " |          batch_size, num_units].\n",
      " |        input_c: the initial hidden state for c. A Tensor of the same shape as\n",
      " |          input_h.\n",
      " |        params: the parameter buffer created for this model.\n",
      " |        is_training: whether this operation will be used in training or inference.\n",
      " |      Returns:\n",
      " |        output: the output sequuence.\n",
      " |        output_h: the final state for h.\n",
      " |        output_c: the final state for c.\n",
      " |  \n",
      " |  __init__(self, num_layers, num_units, input_size, input_mode='linear_input', direction='unidirectional', dtype=tf.float32, dropout=0.0, seed=0)\n",
      " |      Creates a Cudnn LSTM model from model spec.\n",
      " |      \n",
      " |      Args:\n",
      " |        num_layers: the number of layers for the RNN model.\n",
      " |        num_units: the number of units within the RNN model.\n",
      " |        input_size: the size of the input, it could be different from the\n",
      " |            num_units.\n",
      " |        input_mode: indicate whether there is a linear projection between the\n",
      " |            input and The actual computation before the first layer. It could be\n",
      " |            'skip_input', 'linear_input' or 'auto_select'.\n",
      " |            'skip_input' is only allowed when input_size == num_units;\n",
      " |            'auto_select' implies 'skip_input' when input_size == num_units;\n",
      " |            otherwise, it implies 'linear_input'.\n",
      " |        direction: the direction model that the model operates. Could be either\n",
      " |            'unidirectional' or 'bidirectional'\n",
      " |        dtype: dtype of params, tf.float32 or tf.float64.\n",
      " |        dropout: whether to enable dropout. With it is 0, dropout is disabled.\n",
      " |        seed: the seed used for initializing dropout.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _CudnnRNN:\n",
      " |  \n",
      " |  canonical_to_params(self, weights, biases)\n",
      " |      Converts params from the canonical format to a specific format of cuDNN.\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a Tensor for weight parameters.\n",
      " |        biases: a Tensor for bias parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function for the canonical-to-params-to-specific conversion..\n",
      " |  \n",
      " |  params_size(self)\n",
      " |      Calculates the size of the opaque parameter buffer needed for this model.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The calculated parameter buffer size.\n",
      " |  \n",
      " |  params_to_canonical(self, params)\n",
      " |      Converts params from a specific format of cuDNN to the canonical format.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: a Variable for weight and bias parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function for the specific-to-canonical conversion.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _CudnnRNN:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  direction\n",
      " |  \n",
      " |  input_mode\n",
      " |  \n",
      " |  input_size\n",
      " |  \n",
      " |  num_layers\n",
      " |  \n",
      " |  num_units\n",
      " |  \n",
      " |  rnn_mode\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.contrib.cudnn_rnn.CudnnLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724800"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.contrib.cudnn_rnn.CudnnLSTM(\n",
    "    num_layers = 1,\n",
    "    num_units = 300,\n",
    "    input_size = 300,\n",
    "    # TODO: dropout\n",
    "    input_mode = 'skip_input',\n",
    "    direction = 'bidirectional').params_size().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
