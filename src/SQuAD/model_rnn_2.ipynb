{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achang/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_tf(sess = None, log_device_placement = False):\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(0)\n",
    "    return tf.InteractiveSession(config = tf.ConfigProto(log_device_placement = log_device_placement))\n",
    "\n",
    "def dump_statistics():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        print('parameters for \"%s\": %d' % (variable.name, variable_parameters))\n",
    "        total_parameters += variable_parameters\n",
    "    print('total parameters: %d' % total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    dropout_rate = 0.2\n",
    "    \n",
    "    context_max_len = 850\n",
    "    question_max_len = 60\n",
    "    \n",
    "    d_embedding = 100\n",
    "    \n",
    "    num_encoding_ffn_layers = 2\n",
    "    num_encoding_rnn_layers = 2\n",
    "\n",
    "    dataset_batch_size = 128\n",
    "    dataset_num_parallel_calls = 2\n",
    "    dataset_prefetch_size = dataset_batch_size\n",
    "    dataset_shuffle_size = 256\n",
    "    \n",
    "    gradient_clip_norm = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnModel:\n",
    "    def __init__(self, session, word_embeddings, hparams):\n",
    "        self._session = session\n",
    "        self._word_embeddings = word_embeddings\n",
    "        self._hparams = hparams\n",
    "        \n",
    "    def _parse_example(self, example_proto):\n",
    "        # parse proto\n",
    "        parsed = tf.parse_single_example(example_proto, features = {\n",
    "            'context': tf.VarLenFeature(tf.int64),\n",
    "            'question': tf.VarLenFeature(tf.int64),\n",
    "            'answer_starts': tf.VarLenFeature(tf.int64),\n",
    "            'answer_ends': tf.VarLenFeature(tf.int64), })\n",
    "        \n",
    "        # convert to dense tensors\n",
    "        context = tf.sparse_tensor_to_dense(parsed['context'])\n",
    "        question = tf.sparse_tensor_to_dense(parsed['question'])\n",
    "        answer_starts = tf.sparse_tensor_to_dense(parsed['answer_starts'])\n",
    "        answer_ends = tf.sparse_tensor_to_dense(parsed['answer_ends'])\n",
    "        \n",
    "        # pad tensors\n",
    "        context_len = tf.shape(context)[0]\n",
    "        question_len = tf.shape(question)[0]\n",
    "        context = tf.pad(context, [[0, self._hparams.context_max_len - context_len]])\n",
    "        question = tf.pad(question, [[0, self._hparams.question_max_len - question_len]])\n",
    "        \n",
    "        return (context, context_len, question, question_len, answer_starts[0], answer_ends[0])\n",
    "    \n",
    "    def _build_dataset_pipeline(self):\n",
    "        with tf.variable_scope('dataset'):\n",
    "            # placeholders\n",
    "            self._dataset_filenames = tf.placeholder(\n",
    "                tf.string,\n",
    "                shape = [None],\n",
    "                name = 'dataset_filenames')\n",
    "            self._dataset_limit = tf.placeholder_with_default(\n",
    "                tf.constant(-1, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_limit')\n",
    "            self._dataset_shuffle_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_shuffle_size')\n",
    "            self._dataset_batch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_batch_size')\n",
    "            self._dataset_prefetch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_prefetch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_prefetch_size')\n",
    "\n",
    "            # build dataset\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                tf.random_shuffle(self._dataset_filenames),\n",
    "                compression_type='GZIP')\n",
    "            dataset = dataset.take(self._dataset_limit)\n",
    "            dataset = dataset.map(\n",
    "                self._parse_example,\n",
    "                num_parallel_calls = self._hparams.dataset_num_parallel_calls)\n",
    "            dataset = dataset.shuffle(self._dataset_shuffle_size)\n",
    "            dataset = dataset.prefetch(self._dataset_prefetch_size)\n",
    "            dataset = dataset.batch(self._dataset_batch_size)\n",
    "\n",
    "            # build iterator\n",
    "            self._dataset_iterator = dataset.make_initializable_iterator()\n",
    "            (contexts,\n",
    "             context_lens,\n",
    "             questions,\n",
    "             question_lens,\n",
    "             answer_starts,\n",
    "             answer_ends) = self._dataset_iterator.get_next()\n",
    "            \n",
    "            # trim tensors for efficiency\n",
    "            c_size = tf.reduce_max(context_lens)\n",
    "            q_size = tf.reduce_max(question_lens)\n",
    "            contexts = contexts[:, :c_size]\n",
    "            questions = questions[:, :q_size]\n",
    "            \n",
    "            # give key tensors names\n",
    "            self._contexts = tf.identity(contexts, 'contexts')\n",
    "            self._context_lens = tf.identity(context_lens, 'context_lens')\n",
    "            self._questions = tf.identity(questions, 'questions')\n",
    "            self._question_lens = tf.identity(question_lens, 'question_lens')\n",
    "            self._answer_starts = tf.identity(answer_starts, 'answer_starts')\n",
    "            self._answer_ends = tf.identity(answer_ends, 'answer_ends')\n",
    "            \n",
    "            # sequence masks\n",
    "            self._context_masks = tf.sequence_mask(\n",
    "                self._context_lens,\n",
    "                maxlen = c_size,\n",
    "                dtype = tf.float32,\n",
    "                name = 'context_masks')\n",
    "            self._question_masks = tf.sequence_mask(\n",
    "                self._question_lens,\n",
    "                maxlen = q_size,\n",
    "                name = 'question_masks',\n",
    "                dtype = tf.float32)\n",
    "\n",
    "            # minibatch size\n",
    "            self._minibatch_size = tf.shape(self._contexts)[0]\n",
    "            self._minibatch_size = tf.identity(self._minibatch_size, 'minibatch_size')\n",
    "            \n",
    "    def _rnn_unidir_layer(self, layer, num_layers):\n",
    "        # get size\n",
    "        size = layer.shape[-1].value\n",
    "        assert size is not None\n",
    "        \n",
    "        # GRU\n",
    "        def make_gru(dropout):\n",
    "            return tf.contrib.cudnn_rnn.CudnnGRU(\n",
    "                num_layers = num_layers,\n",
    "                num_units = layer.shape[-1].value,\n",
    "                input_size = layer.shape[-1].value,\n",
    "                input_mode = 'skip_input',\n",
    "                dropout = dropout,\n",
    "                direction = 'unidirectional')\n",
    "        gru_trn = make_gru(self._hparams.dropout_rate)\n",
    "        gru_inf = make_gru(0.0)\n",
    "\n",
    "        # variables\n",
    "        gru_params = tf.get_variable(\n",
    "            'gru_params',\n",
    "            [gru_trn.params_size().eval(session = self._session)])\n",
    "\n",
    "        # make input hidden state\n",
    "        input_h = tf.zeros([num_layers, self._minibatch_size, size])\n",
    "\n",
    "        # make input data time-major\n",
    "        input_data = tf.transpose(layer, perm = [1, 0, 2])\n",
    "        \n",
    "        # run GRU\n",
    "        outputs, _ = tf.cond(\n",
    "            self._training,\n",
    "            lambda: gru_trn(input_data, input_h, gru_params),\n",
    "            lambda: gru_inf(input_data, input_h, gru_params))\n",
    "        \n",
    "        # undo time-major\n",
    "        outputs = tf.transpose(outputs, perm = [1, 0, 2])\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def _rnn_bidir_layer(self, layer, seq_lens, num_layers):\n",
    "        # reverse for backwards RNN\n",
    "        layer_bk = tf.reverse_sequence(\n",
    "            layer,\n",
    "            seq_lens,\n",
    "            seq_axis = 1)\n",
    "        \n",
    "        with tf.variable_scope('fw'):\n",
    "            outputs_fw = self._rnn_unidir_layer(layer, num_layers)\n",
    "        with tf.variable_scope('bk'):\n",
    "            outputs_bk = self._rnn_unidir_layer(layer_bk, num_layers)\n",
    "            \n",
    "        # undo sequence reversal\n",
    "        outputs_bk = tf.reverse_sequence(\n",
    "            outputs_bk,\n",
    "            seq_lens,\n",
    "            seq_axis = 1)\n",
    "        \n",
    "        return outputs_fw, outputs_bk\n",
    "    \n",
    "    def _attention_bidir_layer(self, contexts, questions):\n",
    "        # extract size (must be statically known)\n",
    "        size = contexts.shape[-1].value\n",
    "        assert questions.shape[-1].value == size\n",
    "\n",
    "        # project contexts/questions\n",
    "        c = tf.layers.dense(contexts, size, name = 'proj_c')\n",
    "        c *= tf.expand_dims(self._context_masks, axis = -1)\n",
    "        q = tf.layers.dense(questions, size, name = 'proj_q')\n",
    "        q *= tf.expand_dims(self._question_masks, axis = -1)\n",
    "        \n",
    "        # compute weights\n",
    "        q_T = tf.transpose(q, perm = [0, 2, 1])         # [batch, size, q_width]\n",
    "        w = tf.matmul(c, q_T)                           # [batch, c_width, q_width]\n",
    "        w /= np.sqrt(size)\n",
    "\n",
    "        # context-to-query attention\n",
    "        c2q = tf.nn.softmax(w, name = 'weights_c2q')    # [batch, c_width, q_width]\n",
    "        c2q = tf.layers.dropout(\n",
    "            c2q,\n",
    "            rate = self._hparams.dropout_rate,\n",
    "            training = self._training)\n",
    "        c2q_attn = tf.matmul(c2q, questions)            # [batch, c_width, size]\n",
    "\n",
    "        # query-to-context attention\n",
    "        q2c = tf.transpose(w, perm = [0, 2, 1])         # [batch, q_width, size]\n",
    "        q2c = tf.nn.softmax(q2c, name = 'weights_q2c')\n",
    "        q2c = tf.layers.dropout(\n",
    "            q2c,\n",
    "            rate = self._hparams.dropout_rate,\n",
    "            training = self._training)\n",
    "        q2c_attn = tf.matmul(q2c, contexts)             # [batch, q_width, size]\n",
    "\n",
    "        return c2q_attn, q2c_attn\n",
    "    \n",
    "#     def _layer_norm(self, layer, epsilon = 1e-6, name = 'ln'):\n",
    "#         with tf.variable_scope(name):\n",
    "#             size = layer.shape[-1].value\n",
    "#             scale = tf.get_variable(\n",
    "#                 'scale',\n",
    "#                 [size],\n",
    "#                 initializer = tf.ones_initializer())\n",
    "#             bias = tf.get_variable(\n",
    "#                 'bias',\n",
    "#                 [size],\n",
    "#                 initializer = tf.zeros_initializer())\n",
    "#             mean = tf.reduce_mean(\n",
    "#                 layer,\n",
    "#                 axis = -1,\n",
    "#                 keep_dims = True)\n",
    "#             variance = tf.reduce_mean(\n",
    "#                 tf.square(layer - mean),\n",
    "#                 axis = -1,\n",
    "#                 keep_dims = True)\n",
    "#             norm_layer = (layer - mean) * tf.rsqrt(variance + epsilon)\n",
    "#             return norm_layer * scale + bias\n",
    "\n",
    "    def _embedding_layer(self, c, q):\n",
    "        # init embedding\n",
    "        word_embeddings = tf.get_variable(\n",
    "            name = \"embeddings\",\n",
    "            shape = self._word_embeddings.shape,\n",
    "            initializer = tf.constant_initializer(self._word_embeddings),\n",
    "            trainable = False)\n",
    "\n",
    "        # embed contexts/questions\n",
    "        c_embedded = tf.nn.embedding_lookup(\n",
    "            word_embeddings,\n",
    "            c)\n",
    "        q_embedded = tf.nn.embedding_lookup(\n",
    "            word_embeddings,\n",
    "            q)\n",
    "\n",
    "        return c_embedded, q_embedded\n",
    "    \n",
    "    def _ffn_layer(self, layer, hidden_size = None):\n",
    "        # design of FFN from: https://arxiv.org/abs/1603.05027\n",
    "        \n",
    "        # get hidden size\n",
    "        if hidden_size is None:\n",
    "            hidden_size = layer.shape[-1].value * 2\n",
    "        \n",
    "        # save original layer\n",
    "        orig_layer = layer\n",
    "\n",
    "        # dropout\n",
    "        layer = tf.layers.dropout(\n",
    "            layer,\n",
    "            rate = self._hparams.dropout_rate,\n",
    "            training = self._training)\n",
    "            \n",
    "        # BN\n",
    "        layer = tf.layers.batch_normalization(\n",
    "            layer,\n",
    "            training = self._training)\n",
    "        \n",
    "        # relu\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "        # hidden\n",
    "        layer = tf.layers.dense(\n",
    "            layer,\n",
    "            hidden_size,\n",
    "            name = 'hidden')\n",
    "        \n",
    "        # BN\n",
    "        layer = tf.layers.batch_normalization(\n",
    "            layer,\n",
    "            training = self._training)\n",
    "\n",
    "        # weight\n",
    "        layer = tf.layers.dense(\n",
    "            layer,\n",
    "            orig_layer.shape[-1].value,\n",
    "            name = 'output')\n",
    "        \n",
    "        # add residual\n",
    "        return orig_layer + layer\n",
    "    \n",
    "    def _encoding_layer(self, c, q, c_lens, q_lens):\n",
    "        # embedding\n",
    "        with tf.variable_scope('embed'):\n",
    "            c, q = self._embedding_layer(\n",
    "                self._contexts,\n",
    "                self._questions)\n",
    "\n",
    "            # project\n",
    "            c = tf.layers.dropout(\n",
    "                c,\n",
    "                rate = self._hparams.dropout_rate,\n",
    "                training = self._training)\n",
    "            c = tf.layers.dense(\n",
    "                c,\n",
    "                self._hparams.d_embedding,\n",
    "                name = 'proj')\n",
    "            q = tf.layers.dropout(\n",
    "                q,\n",
    "                rate = self._hparams.dropout_rate,\n",
    "                training = self._training)\n",
    "            q = tf.layers.dense(\n",
    "                q,\n",
    "                self._hparams.d_embedding,\n",
    "                name = 'proj',\n",
    "                reuse = True)\n",
    "        \n",
    "        # position-wise FFN\n",
    "        for i in range(self._hparams.num_encoding_ffn_layers):\n",
    "            with tf.variable_scope('ffn_%d' % i):\n",
    "                c = self._ffn_layer(c)\n",
    "        for i in range(self._hparams.num_encoding_ffn_layers):\n",
    "            with tf.variable_scope('ffn_%d' % i, reuse = True):\n",
    "                q = self._ffn_layer(q)\n",
    "\n",
    "        # RNN\n",
    "        with tf.variable_scope('rnn'):\n",
    "            c_fw, c_bk = self._rnn_bidir_layer(\n",
    "                c,\n",
    "                c_lens,\n",
    "                self._hparams.num_encoding_rnn_layers)\n",
    "        with tf.variable_scope('rnn', reuse = True):\n",
    "            q_fw, q_bk = self._rnn_bidir_layer(\n",
    "                q,\n",
    "                q_lens,\n",
    "                self._hparams.num_encoding_rnn_layers)\n",
    "\n",
    "        # concat RNN states\n",
    "        c = tf.concat([c_fw, c_bk], axis = -1)\n",
    "        q = tf.concat([q_fw, q_bk], axis = -1)\n",
    "        \n",
    "        return c, q\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('model'):\n",
    "            # placeholders\n",
    "            self._training = tf.placeholder(tf.bool, name = 'training')\n",
    "            \n",
    "            # encode\n",
    "            with tf.variable_scope('encode'):\n",
    "                c_encoded, q_encoded = self._encoding_layer(\n",
    "                    self._contexts,\n",
    "                    self._questions,\n",
    "                    self._context_lens,\n",
    "                    self._question_lens)\n",
    "\n",
    "            # attention (bidirectional)\n",
    "            with tf.variable_scope('attn_bidir'):\n",
    "                c2q_attn, q2c_attn = self._attention_bidir_layer(\n",
    "                    c_encoded,\n",
    "                    q_encoded)\n",
    "\n",
    "            # summarize q\n",
    "            q = tf.concat([q_encoded, q2c_attn], axis = -1)\n",
    "            w = tf.layers.dense(q, 1)\n",
    "            w = tf.nn.softmax(w, dim = 1)\n",
    "            q *= w\n",
    "            q = tf.reduce_sum(q, axis = 1)\n",
    "            \n",
    "            q = tf.expand_dims(q, axis = 1)\n",
    "            q = tf.tile(q, [1, tf.shape(c_encoded)[1], 1])\n",
    "            \n",
    "            m = tf.concat([c_encoded, c2q_attn, q], axis = -1)\n",
    "            \n",
    "            m = tf.layers.dropout(\n",
    "                m,\n",
    "                rate = self._hparams.dropout_rate,\n",
    "                training = self._training)\n",
    "            m = tf.layers.dense(\n",
    "                m,\n",
    "                200)\n",
    "            m *= tf.expand_dims(self._context_masks, axis = -1)\n",
    "            m_fw, m_bk = self._rnn_bidir_layer(m, self._context_lens, 2)\n",
    "            m = tf.concat([m_fw, m_bk], axis = -1)\n",
    "            \n",
    "            a = tf.layers.dense(m, 1, name = 'ans')\n",
    "            a = tf.squeeze(a, axis = -1)\n",
    "            a *= self._context_masks\n",
    "            self._answer_start_logits = a\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        with tf.variable_scope('optimize'):\n",
    "            # individual losses\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = self._answer_starts,\n",
    "                logits = self._answer_start_logits)\n",
    "\n",
    "            # total loss\n",
    "            self._total_loss = tf.reduce_sum(losses)\n",
    "            self._total_loss = tf.identity(self._total_loss, 'total_loss')\n",
    "            \n",
    "            # mean loss\n",
    "            self._mean_loss = self._total_loss / tf.cast(self._minibatch_size, tf.float32)\n",
    "            self._mean_loss = tf.identity(self._mean_loss, 'mean_loss')\n",
    "            \n",
    "            # start/end probabilities/estimates\n",
    "            self._answer_start_probs = tf.nn.softmax(\n",
    "                self._answer_start_logits,\n",
    "                name = 'answer_start_logits')\n",
    "            self._answer_start_estimates = tf.argmax(\n",
    "                self._answer_start_probs,\n",
    "                axis = -1,\n",
    "                name = 'answer_start_estimates')\n",
    "            \n",
    "            # exact match accuracy\n",
    "            answer_starts_eq = tf.equal(\n",
    "                self._answer_starts,\n",
    "                self._answer_start_estimates)\n",
    "            self._total_exact_matches = tf.reduce_sum(\n",
    "                tf.cast(answer_starts_eq, tf.int64),\n",
    "                name = 'total_exact_matches')\n",
    "            \n",
    "#             # F1\n",
    "#             a0 = self._answer_starts[:, 0]\n",
    "#             a1 = self._answer_ends[:, 0] + 1\n",
    "#             answer_lens = a1 - a0\n",
    "#             b0 = self._answer_start_estimates\n",
    "#             b1 = self._answer_end_estimates + 1\n",
    "#             answer_estimate_lens = b1 - b0\n",
    "#             tps = tf.maximum(\n",
    "#                 tf.cast(0, tf.int64),\n",
    "#                 tf.minimum(a1, b1) - tf.maximum(a0, b0))\n",
    "#             fps = answer_estimate_lens - tps\n",
    "#             fns = answer_lens - tps\n",
    "#             self._total_true_positives = tf.reduce_sum(\n",
    "#                 tps,\n",
    "#                 name = 'total_true_positives')\n",
    "#             self._total_false_positives = tf.reduce_sum(\n",
    "#                 fps,\n",
    "#                 name = 'total_false_positives')\n",
    "#             self._total_false_negatives = tf.reduce_sum(\n",
    "#                 fns,\n",
    "#                 name = 'total_false_negatives')\n",
    "\n",
    "            # learning rate\n",
    "            self._learning_rate = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.learning_rate, tf.float32),\n",
    "                shape = [],\n",
    "                name = 'learning_rate')\n",
    "            \n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self._global_step = tf.Variable(0, name = 'global_step', trainable = False)\n",
    "                self._optimizer = tf.train.AdamOptimizer(learning_rate = self._learning_rate)\n",
    "                \n",
    "                # gradient clipping\n",
    "                gradients, variables = zip(*self._optimizer.compute_gradients(self._mean_loss))\n",
    "                gradients, _ = tf.clip_by_global_norm(\n",
    "                    gradients, \n",
    "                    self._hparams.gradient_clip_norm)\n",
    "                \n",
    "                self._train_op = self._optimizer.apply_gradients(\n",
    "                    zip(gradients, variables),\n",
    "                    global_step = self._global_step)\n",
    "\n",
    "    def process(self,\n",
    "                dataset_filenames,\n",
    "                dataset_limit = -1,\n",
    "                learning_rate = None,\n",
    "                header = 'results',\n",
    "                train = False,\n",
    "                log_file = None):\n",
    "        # initialize dataset to files\n",
    "        self._session.run(self._dataset_iterator.initializer, feed_dict={\n",
    "            self._dataset_filenames: dataset_filenames,\n",
    "            self._dataset_limit: dataset_limit })\n",
    "\n",
    "        cum_loss = 0\n",
    "        cum_num_examples = 0\n",
    "        cum_exact_matches = 0\n",
    "        \n",
    "        # start progress\n",
    "        start = datetime.datetime.now()\n",
    "        progress = tqdm_notebook(leave = False, desc = header)\n",
    "        \n",
    "        if learning_rate is None:\n",
    "            learning_rate = self._hparams.learning_rate\n",
    "\n",
    "        while True:\n",
    "            # process a minibatch\n",
    "            try:\n",
    "                (_,\n",
    "                 curr_total_loss,\n",
    "                 curr_exact_matches,\n",
    "                 curr_minibatch_size) = self._session.run(\n",
    "                    (self._train_op if train else (),\n",
    "                     self._total_loss,\n",
    "                     self._total_exact_matches,\n",
    "                     self._minibatch_size),\n",
    "                    feed_dict = {\n",
    "                        self._training: train,\n",
    "                        self._learning_rate: learning_rate })\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "            # update loss stats\n",
    "            cum_loss += curr_total_loss\n",
    "            cum_exact_matches += curr_exact_matches\n",
    "            cum_num_examples += curr_minibatch_size\n",
    "            \n",
    "            # update progress\n",
    "            progress.update(curr_minibatch_size)\n",
    "            progress.set_postfix(loss = cum_loss / cum_num_examples)\n",
    "\n",
    "        # end progress\n",
    "        progress.close()\n",
    "        finish = datetime.datetime.now()\n",
    "        \n",
    "        # print/log output\n",
    "        message = '%s: time=%s, step=%d, loss=%g, exact_match=%g' % (\n",
    "            header,\n",
    "            finish - start,\n",
    "            tf.train.global_step(sess, self._global_step),\n",
    "            cum_loss / cum_num_examples,\n",
    "            cum_exact_matches / cum_num_examples)\n",
    "        print(message)\n",
    "        if log_file:\n",
    "            print(message, file=log_file)\n",
    "            log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../../data/SQuAD/data_1.vocab.embeddings.npy.gz', 'rb') as f:\n",
    "    word_embeddings = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    return sorted([os.path.join(path, file) for file in os.listdir(path)])\n",
    "\n",
    "train_set = list_files('../../data/SQuAD/data_1.train')\n",
    "dev_set = list_files('../../data/SQuAD/data_1.dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for \"model/encode/embed/proj/kernel:0\": 30000\n",
      "parameters for \"model/encode/embed/proj/bias:0\": 100\n",
      "parameters for \"model/encode/ffn_0/batch_normalization/gamma:0\": 100\n",
      "parameters for \"model/encode/ffn_0/batch_normalization/beta:0\": 100\n",
      "parameters for \"model/encode/ffn_0/hidden/kernel:0\": 20000\n",
      "parameters for \"model/encode/ffn_0/hidden/bias:0\": 200\n",
      "parameters for \"model/encode/ffn_0/batch_normalization_1/gamma:0\": 200\n",
      "parameters for \"model/encode/ffn_0/batch_normalization_1/beta:0\": 200\n",
      "parameters for \"model/encode/ffn_0/output/kernel:0\": 20000\n",
      "parameters for \"model/encode/ffn_0/output/bias:0\": 100\n",
      "parameters for \"model/encode/ffn_1/batch_normalization/gamma:0\": 100\n",
      "parameters for \"model/encode/ffn_1/batch_normalization/beta:0\": 100\n",
      "parameters for \"model/encode/ffn_1/hidden/kernel:0\": 20000\n",
      "parameters for \"model/encode/ffn_1/hidden/bias:0\": 200\n",
      "parameters for \"model/encode/ffn_1/batch_normalization_1/gamma:0\": 200\n",
      "parameters for \"model/encode/ffn_1/batch_normalization_1/beta:0\": 200\n",
      "parameters for \"model/encode/ffn_1/output/kernel:0\": 20000\n",
      "parameters for \"model/encode/ffn_1/output/bias:0\": 100\n",
      "parameters for \"model/encode/rnn/fw/gru_params:0\": 91200\n",
      "parameters for \"model/encode/rnn/bk/gru_params:0\": 91200\n",
      "parameters for \"model/attn_bidir/proj_c/kernel:0\": 40000\n",
      "parameters for \"model/attn_bidir/proj_c/bias:0\": 200\n",
      "parameters for \"model/attn_bidir/proj_q/kernel:0\": 40000\n",
      "parameters for \"model/attn_bidir/proj_q/bias:0\": 200\n",
      "parameters for \"model/dense/kernel:0\": 400\n",
      "parameters for \"model/dense/bias:0\": 1\n",
      "parameters for \"model/dense_1/kernel:0\": 160000\n",
      "parameters for \"model/dense_1/bias:0\": 200\n",
      "parameters for \"model/fw/gru_params:0\": 362400\n",
      "parameters for \"model/bk/gru_params:0\": 362400\n",
      "parameters for \"model/ans/kernel:0\": 400\n",
      "parameters for \"model/ans/bias:0\": 1\n",
      "total parameters: 1260502\n"
     ]
    }
   ],
   "source": [
    "sess = reset_tf(sess)\n",
    "\n",
    "model = RnnModel(sess, word_embeddings, HyperParameters())\n",
    "model._build_dataset_pipeline()\n",
    "model._build_model()\n",
    "model._build_optimizer()\n",
    "dump_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06aab9f04344ee4b678398e3ed57617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train_0', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[676,128,200]\n\t [[Node: optimize/gradients/zeros_4 = Fill[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](optimize/gradients/Shape_5, optimize/gradients/zeros_4/Const)]]\n\t [[Node: optimize/Adam/update/_820 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_19966_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'optimize/gradients/zeros_4', defined at:\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-bedad5fd0a7e>\", line 6, in <module>\n    model._build_optimizer()\n  File \"<ipython-input-4-f26f716ca48b>\", line 447, in _build_optimizer\n    gradients, variables = zip(*self._optimizer.compute_gradients(self._mean_loss))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 572, in gradients\n    out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1345, in ZerosLikeOutsideLoop\n    return array_ops.zeros(zeros_shape, dtype=val.dtype)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1442, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1771, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[676,128,200]\n\t [[Node: optimize/gradients/zeros_4 = Fill[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](optimize/gradients/Shape_5, optimize/gradients/zeros_4/Const)]]\n\t [[Node: optimize/Adam/update/_820 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_19966_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[676,128,200]\n\t [[Node: optimize/gradients/zeros_4 = Fill[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](optimize/gradients/Shape_5, optimize/gradients/zeros_4/Const)]]\n\t [[Node: optimize/Adam/update/_820 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_19966_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9a0cfcef8a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             log_file = f)\n\u001b[0m\u001b[1;32m      9\u001b[0m         model.process(\n\u001b[1;32m     10\u001b[0m             \u001b[0mdev_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f26f716ca48b>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, dataset_filenames, dataset_limit, learning_rate, header, train, log_file)\u001b[0m\n\u001b[1;32m    490\u001b[0m                     feed_dict = {\n\u001b[1;32m    491\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                         self._learning_rate: learning_rate })\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[676,128,200]\n\t [[Node: optimize/gradients/zeros_4 = Fill[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](optimize/gradients/Shape_5, optimize/gradients/zeros_4/Const)]]\n\t [[Node: optimize/Adam/update/_820 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_19966_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'optimize/gradients/zeros_4', defined at:\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/achang/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-bedad5fd0a7e>\", line 6, in <module>\n    model._build_optimizer()\n  File \"<ipython-input-4-f26f716ca48b>\", line 447, in _build_optimizer\n    gradients, variables = zip(*self._optimizer.compute_gradients(self._mean_loss))\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 572, in gradients\n    out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1345, in ZerosLikeOutsideLoop\n    return array_ops.zeros(zeros_shape, dtype=val.dtype)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1442, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1771, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/achang/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[676,128,200]\n\t [[Node: optimize/gradients/zeros_4 = Fill[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](optimize/gradients/Shape_5, optimize/gradients/zeros_4/Const)]]\n\t [[Node: optimize/Adam/update/_820 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_19966_optimize/Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with open('../../logs/SQuAD/model_rnn_2.4.log', 'at') as f:\n",
    "    for i in range(50):\n",
    "        model.process(\n",
    "            train_set,\n",
    "            header = 'train_%d' % i,\n",
    "            train = True,\n",
    "            learning_rate = 3e-3,\n",
    "            log_file = f)\n",
    "        model.process(\n",
    "            dev_set,\n",
    "            header = 'dev_%d' % i,\n",
    "            train = False,\n",
    "            log_file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1924800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.contrib.cudnn_rnn.CudnnGRU(\n",
    "    num_layers = 1,\n",
    "    num_units = 800,\n",
    "    input_size = 800,\n",
    "    input_mode = 'skip_input',\n",
    "    dropout = 0,\n",
    "    direction = 'unidirectional').params_size().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fill([1], 1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
