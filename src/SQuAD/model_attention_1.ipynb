{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_tf(sess = None, log_device_placement = False):\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(0)\n",
    "    return tf.InteractiveSession(config = tf.ConfigProto(log_device_placement = log_device_placement))\n",
    "\n",
    "def dump_statistics():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        print('parameters for \"%s\": %d' % (variable.name, variable_parameters))\n",
    "        total_parameters += variable_parameters\n",
    "    print('total parameters: %d' % total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    dropout_rate = 0.1\n",
    "    \n",
    "    context_size = 850\n",
    "    question_size = 60\n",
    "    answers_size = 6\n",
    "    \n",
    "    d_hidden = 128\n",
    "\n",
    "    dataset_batch_size = 64\n",
    "    dataset_num_parallel_calls = 4\n",
    "    dataset_prefetch_size = 1000\n",
    "    dataset_shuffle_size = 1000\n",
    "    \n",
    "    max_distance_bias = 10\n",
    "    \n",
    "    gradient_clip_norm = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel:\n",
    "    def __init__(self, session, word_embeddings, hparams):\n",
    "        self._session = session\n",
    "        self._word_embeddings = word_embeddings\n",
    "        self._hparams = hparams\n",
    "        \n",
    "    def _parse_example(self, example_proto):\n",
    "        # parse proto\n",
    "        parsed = tf.parse_single_example(example_proto, features = {\n",
    "            'context': tf.VarLenFeature(tf.int64),\n",
    "            'question': tf.VarLenFeature(tf.int64),\n",
    "            'answer_starts': tf.VarLenFeature(tf.int64),\n",
    "            'answer_ends': tf.VarLenFeature(tf.int64), })\n",
    "        \n",
    "        # convert to dense tensors\n",
    "        context = tf.sparse_tensor_to_dense(parsed['context'])\n",
    "        question = tf.sparse_tensor_to_dense(parsed['question'])\n",
    "        answer_starts = tf.sparse_tensor_to_dense(parsed['answer_starts'])\n",
    "        answer_ends = tf.sparse_tensor_to_dense(parsed['answer_ends'])\n",
    "        \n",
    "        # pad tensors\n",
    "        context_len = tf.shape(context)[0]\n",
    "        question_len = tf.shape(question)[0]\n",
    "        answers_len = tf.shape(answer_starts)[0]\n",
    "        zero_vector = self._word_embeddings.shape[0] - 1\n",
    "        context = tf.pad(\n",
    "            context,\n",
    "            [[0, self._hparams.context_size - context_len]],\n",
    "            constant_values = 0)\n",
    "        question = tf.pad(\n",
    "            question,\n",
    "            [[0, self._hparams.question_size - question_len]],\n",
    "            constant_values = 0)\n",
    "        answer_starts = tf.pad(\n",
    "            answer_starts,\n",
    "            [[0, self._hparams.answers_size - answers_len]],\n",
    "            constant_values = -1)\n",
    "        answer_ends = tf.pad(\n",
    "            answer_ends,\n",
    "            [[0, self._hparams.answers_size - answers_len]],\n",
    "            constant_values = -1)\n",
    "        \n",
    "        return (context, question, answer_starts, answer_ends)\n",
    "    \n",
    "    def _build_dataset_pipeline(self):\n",
    "        with tf.variable_scope('dataset'):\n",
    "            # placeholders\n",
    "            self._dataset_filenames = tf.placeholder(\n",
    "                tf.string,\n",
    "                shape = [None],\n",
    "                name = 'dataset_filenames')\n",
    "            self._dataset_limit = tf.placeholder_with_default(\n",
    "                tf.constant(-1, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_limit')\n",
    "            self._dataset_shuffle_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_shuffle_size')\n",
    "            self._dataset_batch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_batch_size')\n",
    "            self._dataset_prefetch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hparams.dataset_prefetch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_prefetch_size')\n",
    "\n",
    "            # build dataset\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                tf.random_shuffle(self._dataset_filenames),\n",
    "                compression_type='GZIP')\n",
    "            dataset = dataset.take(self._dataset_limit)\n",
    "            dataset = dataset.map(\n",
    "                self._parse_example,\n",
    "                num_parallel_calls = self._hparams.dataset_num_parallel_calls)\n",
    "            dataset = dataset.shuffle(self._dataset_shuffle_size)\n",
    "            dataset = dataset.prefetch(self._dataset_prefetch_size)\n",
    "            dataset = dataset.batch(self._dataset_batch_size)\n",
    "\n",
    "            # build iterator\n",
    "            self._dataset_iterator = dataset.make_initializable_iterator()\n",
    "            (contexts, questions, answer_starts, answer_ends) = self._dataset_iterator.get_next()\n",
    "            \n",
    "            # give key tensors names\n",
    "            self._contexts = tf.identity(contexts, 'contexts')\n",
    "            self._questions = tf.identity(questions, 'questions')\n",
    "            self._answer_starts = tf.identity(answer_starts, 'answer_starts')\n",
    "            self._answer_ends = tf.identity(answer_ends, 'answer_ends')\n",
    "\n",
    "            # minibatch size\n",
    "            self._minibatch_size = tf.shape(self._contexts)[0]\n",
    "            self._minibatch_size = tf.identity(self._minibatch_size, 'minibatch_size')\n",
    "    \n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('model'):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../../data/SQuAD/data_1.vocab.embeddings.npy.gz', 'rb') as f:\n",
    "    word_embeddings = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    return sorted([os.path.join(path, file) for file in os.listdir(path)])\n",
    "\n",
    "train_set = list_files('../../data/SQuAD/data_1.train')\n",
    "dev_set = list_files('../../data/SQuAD/data_1.dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 0\n"
     ]
    }
   ],
   "source": [
    "sess = reset_tf(sess)\n",
    "\n",
    "model = AttentionModel(sess, word_embeddings, HyperParameters())\n",
    "model._build_dataset_pipeline()\n",
    "dump_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(\n",
    "    model._dataset_iterator.initializer,\n",
    "    feed_dict = {\n",
    "        model._dataset_filenames: train_set })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[   8, 6796,    1, ...,    0,    0,    0],\n",
       "        [  73, 2634,    7, ...,    0,    0,    0],\n",
       "        [ 495, 1647,    1, ...,    0,    0,    0],\n",
       "        ..., \n",
       "        [   1, 1114,    3, ...,    0,    0,    0],\n",
       "        [   1, 1955, 1169, ...,    0,    0,    0],\n",
       "        [1818,   45, 2378, ...,    0,    0,    0]]),\n",
       " array([[  10,   23,    1, ...,    0,    0,    0],\n",
       "        [  73, 2634,    7, ...,    0,    0,    0],\n",
       "        [  33,   23, 1334, ...,    0,    0,    0],\n",
       "        ..., \n",
       "        [  28,   12,    1, ...,    0,    0,    0],\n",
       "        [  26,  118,   23, ...,    0,    0,    0],\n",
       "        [  10,  824,   56, ...,    0,    0,    0]]),\n",
       " array([[ 26,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 11,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 29,  -1,  -1,  -1,  -1,  -1],\n",
       "        [135,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 30,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 61,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 46,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 51,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 13,  -1,  -1,  -1,  -1,  -1],\n",
       "        [107,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 11,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  0,  -1,  -1,  -1,  -1,  -1],\n",
       "        [109,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  8,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 58,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 26,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 54,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  0,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 79,  -1,  -1,  -1,  -1,  -1],\n",
       "        [268,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 49,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 63,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 55,  -1,  -1,  -1,  -1,  -1],\n",
       "        [110,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 96,  -1,  -1,  -1,  -1,  -1],\n",
       "        [117,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 85,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 83,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  5,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  0,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  3,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  0,  -1,  -1,  -1,  -1,  -1],\n",
       "        [211,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 37,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 12,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 76,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  5,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  0,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 32,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 92,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  2,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 11,  -1,  -1,  -1,  -1,  -1],\n",
       "        [166,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 23,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 72,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 90,  -1,  -1,  -1,  -1,  -1],\n",
       "        [114,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 18,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 76,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  3,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  5,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 30,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 22,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 58,  -1,  -1,  -1,  -1,  -1],\n",
       "        [150,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 73,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  2,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 21,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 14,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 46,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 31,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 62,  -1,  -1,  -1,  -1,  -1]]),\n",
       " array([[ 43,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 15,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 31,  -1,  -1,  -1,  -1,  -1],\n",
       "        [135,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 32,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 65,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 47,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 51,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 13,  -1,  -1,  -1,  -1,  -1],\n",
       "        [109,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 11,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  4,  -1,  -1,  -1,  -1,  -1],\n",
       "        [109,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 10,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 60,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 26,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 57,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  2,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 81,  -1,  -1,  -1,  -1,  -1],\n",
       "        [271,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 50,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 64,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 55,  -1,  -1,  -1,  -1,  -1],\n",
       "        [113,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 98,  -1,  -1,  -1,  -1,  -1],\n",
       "        [118,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 86,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 85,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  5,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  5,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [216,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 39,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 12,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 76,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  5,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  2,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 32,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 93,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  2,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 14,  -1,  -1,  -1,  -1,  -1],\n",
       "        [167,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 23,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 72,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  3,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 90,  -1,  -1,  -1,  -1,  -1],\n",
       "        [132,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 19,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 83,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 10,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  5,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 30,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 24,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 58,  -1,  -1,  -1,  -1,  -1],\n",
       "        [152,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 73,  -1,  -1,  -1,  -1,  -1],\n",
       "        [  3,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 21,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 20,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 47,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 33,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 63,  -1,  -1,  -1,  -1,  -1]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([model._contexts, model._questions, model._answer_starts, model._answer_ends])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
