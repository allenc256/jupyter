{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    Z = Z - np.max(Z, axis = 0, keepdims = True)\n",
    "    e = np.exp(Z)\n",
    "    d = np.sum(e, axis = 0, keepdims = True)\n",
    "    return e / d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y, a):\n",
    "    return -np.sum(y * np.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss_many(Y, A):\n",
    "    m = Y.shape[1]\n",
    "    J = -np.sum(Y * np.log(np.maximum(A, 1e-10)), axis = 0, keepdims = True)\n",
    "    return np.sum(J) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numeric_jacobian(x, f, epsilon=1e-4):\n",
    "    x = np.copy(x)\n",
    "    a = f(x)\n",
    "    a_shape = () if np.isscalar(a) else a.shape\n",
    "    result = np.zeros(a_shape + x.shape)\n",
    "    for index, y in np.ndenumerate(x):\n",
    "        y_prev = y - epsilon\n",
    "        y_next = y + epsilon\n",
    "        x[index] = y_prev\n",
    "        f_prev = f(x)\n",
    "        x[index] = y_next\n",
    "        f_next = f(x)\n",
    "        x[index] = y\n",
    "        f_grad = (f_next - f_prev) / (2 * epsilon)\n",
    "        result[(...,) + index] = f_grad\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numeric_jacobian_test(x, f, expected, epsilon=1e-4):\n",
    "    j = numeric_jacobian(x, f, epsilon)\n",
    "    print('analytic:')\n",
    "    print(expected)\n",
    "    print()\n",
    "    print('numeric:')\n",
    "    print(j)\n",
    "    print()\n",
    "    print('error norm:', np.linalg.norm(expected - j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytic:\n",
      "[[ 0.19661193  0.          0.        ]\n",
      " [ 0.          0.10499359  0.        ]\n",
      " [ 0.          0.          0.04517666]]\n",
      "\n",
      "numeric:\n",
      "[[ 0.19661193  0.          0.        ]\n",
      " [ 0.          0.10499359  0.        ]\n",
      " [ 0.          0.          0.04517666]]\n",
      "\n",
      "error norm: 1.03863334212e-10\n"
     ]
    }
   ],
   "source": [
    "z = np.array([1.,2.,3.])\n",
    "f = sigmoid\n",
    "a = f(z)\n",
    "dz = np.diag(a * (1 - a))\n",
    "\n",
    "numeric_jacobian_test(z, f, dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytic:\n",
      "[[ 0.41997434  0.          0.        ]\n",
      " [ 0.          0.07065082  0.        ]\n",
      " [ 0.          0.          0.00986604]]\n",
      "\n",
      "numeric:\n",
      "[[ 0.41997434  0.          0.        ]\n",
      " [ 0.          0.07065083  0.        ]\n",
      " [ 0.          0.          0.00986604]]\n",
      "\n",
      "error norm: 1.12035346308e-09\n"
     ]
    }
   ],
   "source": [
    "z = np.array([1.,2.,3.])\n",
    "f = np.tanh\n",
    "a = f(z)\n",
    "dz = np.diag(1 - np.power(a, 2))\n",
    "\n",
    "numeric_jacobian_test(z, f, dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytic:\n",
      "[[ 0.08192507 -0.02203304 -0.05989202]\n",
      " [-0.02203304  0.18483645 -0.1628034 ]\n",
      " [-0.05989202 -0.1628034   0.22269543]]\n",
      "\n",
      "numeric:\n",
      "[[ 0.08192507 -0.02203304 -0.05989202]\n",
      " [-0.02203304  0.18483645 -0.1628034 ]\n",
      " [-0.05989202 -0.1628034   0.22269543]]\n",
      "\n",
      "error norm: 1.86126090163e-10\n"
     ]
    }
   ],
   "source": [
    "z = np.array([1.,2.,3.])\n",
    "f = softmax\n",
    "a = f(z)\n",
    "dz = np.diag(a) - np.outer(a, a)\n",
    "\n",
    "numeric_jacobian_test(z, f, dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytic:\n",
      "[-2.         -0.         -1.33333333]\n",
      "\n",
      "numeric:\n",
      "[-2.00000067  0.         -1.33333335]\n",
      "\n",
      "error norm: 6.66781910961e-07\n"
     ]
    }
   ],
   "source": [
    "y = np.array([0.2, 0.0, 0.8])\n",
    "a = np.array([0.1, 0.3, 0.6])\n",
    "f = lambda a: cross_entropy_loss(y, a)\n",
    "da = - y / a\n",
    "\n",
    "numeric_jacobian_test(a, f, da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytic:\n",
      "[-0.10996943  0.24472847 -0.13475904]\n",
      "\n",
      "numeric:\n",
      "[-0.10996943  0.24472847 -0.13475904]\n",
      "\n",
      "error norm: 2.29340228256e-10\n"
     ]
    }
   ],
   "source": [
    "y = np.array([0.2, 0.0, 0.8])\n",
    "z = np.array([1., 2., 3.])\n",
    "a = softmax(z)\n",
    "f = lambda z: cross_entropy_loss(y, softmax(z))\n",
    "dz = a - y\n",
    "\n",
    "numeric_jacobian_test(z, f, dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dJ/dW\n",
      "=====\n",
      "\n",
      "analytic:\n",
      "[[ 0.05835788  0.23767355  0.15065267  0.07192808]\n",
      " [ 0.06459683  0.26308287  0.16675872  0.07961781]\n",
      " [-0.12295471 -0.50075643 -0.31741138 -0.15154589]]\n",
      "\n",
      "numeric:\n",
      "[[ 0.05835788  0.23767355  0.15065267  0.07192808]\n",
      " [ 0.06459683  0.26308287  0.16675872  0.07961781]\n",
      " [-0.12295471 -0.50075643 -0.31741138 -0.15154589]]\n",
      "\n",
      "error norm: 1.89989372869e-10\n",
      "\n",
      "dJ/dx\n",
      "=====\n",
      "\n",
      "analytic:\n",
      "[[ 0.15249132  0.37423959 -0.09565523 -0.20249029]]\n",
      "\n",
      "numeric:\n",
      "[ 0.15249132  0.37423959 -0.09565523 -0.20249029]\n",
      "\n",
      "error norm: 4.76952760471e-11\n",
      "\n",
      "dJ/db\n",
      "=====\n",
      "\n",
      "analytic:\n",
      "[ 0.25024567  0.27699905 -0.52724472]\n",
      "\n",
      "numeric:\n",
      "[ 0.25024567  0.27699905 -0.52724472]\n",
      "\n",
      "error norm: 2.15040108902e-10\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(3, 4)\n",
    "b = np.random.rand(3)\n",
    "x = np.random.rand(4)\n",
    "z = np.matmul(W, x) + b\n",
    "a = softmax(z)\n",
    "y = np.array([0.2, 0.0, 0.8])\n",
    "\n",
    "print('dJ/dW')\n",
    "print('=====')\n",
    "print()\n",
    "\n",
    "f = lambda W: cross_entropy_loss(y, softmax(np.matmul(W, x) + b))\n",
    "dz = a - y\n",
    "dW = np.outer(a - y, x)\n",
    "numeric_jacobian_test(W, f, dW)\n",
    "\n",
    "print()\n",
    "print('dJ/dx')\n",
    "print('=====')\n",
    "print()\n",
    "\n",
    "f = lambda x: cross_entropy_loss(y, softmax(np.matmul(W, x) + b))\n",
    "dz = a - y\n",
    "dx = np.matmul(dz.reshape(1, dz.size), W)\n",
    "numeric_jacobian_test(x, f, dx)\n",
    "\n",
    "print()\n",
    "print('dJ/db')\n",
    "print('=====')\n",
    "print()\n",
    "\n",
    "f = lambda b: cross_entropy_loss(y, softmax(np.matmul(W, x) + b))\n",
    "dz = a - y\n",
    "db = dz\n",
    "numeric_jacobian_test(b, f, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dJ/dW\n",
      "=====\n",
      "\n",
      "analytic:\n",
      "[[-0.04022874 -0.0159691  -0.07395404 -0.06597514]\n",
      " [-0.10300245 -0.05765084 -0.15381043 -0.11379874]\n",
      " [ 0.1432312   0.07361994  0.22776446  0.17977388]]\n",
      "\n",
      "numeric:\n",
      "[[-0.04022874 -0.0159691  -0.07395404 -0.06597514]\n",
      " [-0.10300245 -0.05765084 -0.15381043 -0.11379874]\n",
      " [ 0.1432312   0.07361994  0.22776446  0.17977388]]\n",
      "\n",
      "error norm: 2.08093198502e-10\n",
      "\n",
      "dJ/dX\n",
      "=====\n",
      "\n",
      "analytic:\n",
      "[[-0.00299724  0.01108631]\n",
      " [-0.00973512 -0.06479612]\n",
      " [ 0.03534242  0.15264563]\n",
      " [ 0.00425963  0.05495008]]\n",
      "\n",
      "numeric:\n",
      "[[-0.00299724  0.01108631]\n",
      " [-0.00973512 -0.06479612]\n",
      " [ 0.03534242  0.15264563]\n",
      " [ 0.00425963  0.05495008]]\n",
      "\n",
      "error norm: 3.69815593006e-11\n",
      "\n",
      "dJ/db\n",
      "=====\n",
      "\n",
      "analytic:\n",
      "[[-0.08386111]\n",
      " [-0.17826072]\n",
      " [ 0.26212183]]\n",
      "\n",
      "numeric:\n",
      "[[-0.08386111]\n",
      " [-0.17826072]\n",
      " [ 0.26212183]]\n",
      "\n",
      "error norm: 2.23671954153e-10\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(3, 4)\n",
    "b = np.random.rand(3, 1)\n",
    "X = np.random.rand(4, 2)\n",
    "Z = np.matmul(W, X) + b\n",
    "A = softmax(Z)\n",
    "Y = softmax(np.random.rand(3, 2))\n",
    "\n",
    "print('dJ/dW')\n",
    "print('=====')\n",
    "print()\n",
    "\n",
    "f = lambda W: cross_entropy_loss_many(Y, softmax(np.matmul(W, X) + b))\n",
    "dZ = (A - Y) / Y.shape[1]\n",
    "dW = np.matmul(dZ, X.T)\n",
    "numeric_jacobian_test(W, f, dW)\n",
    "\n",
    "print()\n",
    "print('dJ/dX')\n",
    "print('=====')\n",
    "print()\n",
    "\n",
    "f = lambda X: cross_entropy_loss_many(Y, softmax(np.matmul(W, X) + b))\n",
    "dZ = (A - Y) / Y.shape[1]\n",
    "dX = np.matmul(W.T, dZ)\n",
    "numeric_jacobian_test(X, f, dX)\n",
    "\n",
    "print()\n",
    "print('dJ/db')\n",
    "print('=====')\n",
    "print()\n",
    "\n",
    "f = lambda b: cross_entropy_loss_many(Y, softmax(np.matmul(W, X) + b))\n",
    "dZ = (A - Y) / Y.shape[1]\n",
    "db = np.matmul(dZ, np.ones((2, 1)))\n",
    "numeric_jacobian_test(b, f, db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
