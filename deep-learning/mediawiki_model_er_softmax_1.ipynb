{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_tf(sess = None, log_device_placement = False):\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(0)\n",
    "    return tf.InteractiveSession(config = tf.ConfigProto(log_device_placement = log_device_placement))\n",
    "\n",
    "def dump_statistics():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        print('parameters for \"%s\": %d' % (variable.name, variable_parameters))\n",
    "        total_parameters += variable_parameters\n",
    "    print('total parameters: %d' % total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    vocab_size = 30000\n",
    "    num_targets = 2000\n",
    "    \n",
    "    dropout_rate = 0.1\n",
    "    \n",
    "    context_size = 81\n",
    "    \n",
    "    d_embedding_position = 32\n",
    "    d_embedding_word = 128\n",
    "    \n",
    "    d_attention = 128\n",
    "    d_attention_ff = 512\n",
    "    \n",
    "    attention_num_layers = 4\n",
    "\n",
    "    dataset_context_size = 121\n",
    "    dataset_batch_size = 512\n",
    "    dataset_num_parallel_calls = 4\n",
    "    dataset_prefetch_size = 4096\n",
    "    dataset_shuffle_size = 4096\n",
    "    \n",
    "    gradient_clip_norm = 5.0\n",
    "    \n",
    "    link_loss_pos_weight = 3.0\n",
    "    link_loss_scale = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityRecognitionModel:\n",
    "    def __init__(self, session, hp):\n",
    "        self._session = session\n",
    "        self._hp = hp\n",
    "        \n",
    "    def _parse_example(self, example_proto):\n",
    "        parsed = tf.parse_single_example(example_proto, features = {\n",
    "            'page': tf.FixedLenFeature([1], tf.int64),\n",
    "            'context': tf.FixedLenFeature([self._hp.dataset_context_size], tf.int64),\n",
    "            'targets': tf.FixedLenFeature([self._hp.dataset_context_size], tf.int64),\n",
    "            'targets_left': tf.FixedLenFeature([self._hp.dataset_context_size], tf.int64),\n",
    "            'targets_right': tf.FixedLenFeature([self._hp.dataset_context_size], tf.int64) })\n",
    "        \n",
    "        # apply random crop\n",
    "        offset = (self._dataset_random_seed + parsed['page'][0]) % (\n",
    "            (self._hp.dataset_context_size - self._hp.context_size) // 2)\n",
    "#         offset = tf.random_uniform(\n",
    "#             [],\n",
    "#             maxval = self._hp.dataset_context_size - self._hp.context_size,\n",
    "#             seed = seed,\n",
    "#             dtype = tf.int32)\n",
    "\n",
    "        # apply croppings\n",
    "        context = parsed['context']\n",
    "        context = context[offset:offset + self._hp.context_size]\n",
    "        targets = parsed['targets']\n",
    "        targets = targets[offset:offset + self._hp.context_size]\n",
    "        targets_left = parsed['targets_left']\n",
    "        targets_left = targets_left[offset:offset + self._hp.context_size]\n",
    "        targets_right = parsed['targets_right']\n",
    "        targets_right = targets_right[offset:offset + self._hp.context_size]\n",
    "        \n",
    "        return (context, targets, targets_left, targets_right)\n",
    "\n",
    "    def _build_data_pipeline(self):\n",
    "        with tf.variable_scope('dataset'):\n",
    "            # placeholders\n",
    "            self._dataset_filenames = tf.placeholder(\n",
    "                tf.string,\n",
    "                shape = [None],\n",
    "                name = 'dataset_filenames')\n",
    "            self._dataset_limit = tf.placeholder_with_default(\n",
    "                tf.constant(-1, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_limit')\n",
    "            self._dataset_shuffle_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hp.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_shuffle_size')\n",
    "            self._dataset_batch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hp.dataset_batch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_batch_size')\n",
    "            self._dataset_prefetch_size = tf.placeholder_with_default(\n",
    "                tf.constant(self._hp.dataset_prefetch_size, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_prefetch_size')\n",
    "            self._dataset_random_seed = tf.placeholder_with_default(\n",
    "                tf.constant(0, tf.int64),\n",
    "                shape = [],\n",
    "                name = 'dataset_random_seed')\n",
    "\n",
    "            # build dataset\n",
    "            dataset = tf.data.TFRecordDataset(\n",
    "                tf.random_shuffle(self._dataset_filenames),\n",
    "                compression_type='GZIP')\n",
    "            dataset = dataset.take(self._dataset_limit)\n",
    "            dataset = dataset.map(\n",
    "                self._parse_example,\n",
    "                num_parallel_calls = self._hp.dataset_num_parallel_calls)\n",
    "            dataset = dataset.shuffle(self._dataset_shuffle_size)\n",
    "            dataset = dataset.prefetch(self._dataset_prefetch_size)\n",
    "            dataset = dataset.batch(self._dataset_batch_size)\n",
    "            \n",
    "            # build iterator\n",
    "            self._dataset_iterator = dataset.make_initializable_iterator()\n",
    "            (context, targets, targets_left, targets_right) = self._dataset_iterator.get_next()\n",
    "\n",
    "            # give key tensors names\n",
    "            self._context = tf.identity(context, 'context')\n",
    "            self._targets = tf.identity(targets, 'targets')\n",
    "            self._targets_left = tf.identity(targets_left, 'targets_left')\n",
    "            self._targets_right = tf.identity(targets_right, 'targets_right')\n",
    "\n",
    "            # minibatch size\n",
    "            self._minibatch_size = tf.shape(self._context)[0]\n",
    "            self._minibatch_size = tf.identity(self._minibatch_size, 'minibatch_size')\n",
    "            \n",
    "            # positions\n",
    "            p = tf.range(self._hp.context_size, dtype = tf.int64)\n",
    "            p = tf.tile(p, [self._minibatch_size])\n",
    "            p = tf.reshape(\n",
    "                p,\n",
    "                [self._minibatch_size, self._hp.context_size],\n",
    "                name = 'context_positions')\n",
    "            self._context_positions = p\n",
    "            \n",
    "    def _attention_self(self, layer):\n",
    "        with tf.variable_scope('self'):\n",
    "            # variables\n",
    "            kernels = tf.get_variable(\n",
    "                'kernels',\n",
    "                [2, self._hp.d_attention, self._hp.d_attention])\n",
    "            \n",
    "            # compute weights\n",
    "            k0 = tf.tensordot(layer, kernels[0], axes = 1) # [batch_size, context_size, d_attention]\n",
    "            k0.set_shape([None, self._hp.context_size, self._hp.d_attention])\n",
    "            k1 = tf.tensordot(layer, kernels[1], axes = 1) # [batch_size, context_size, d_attention]\n",
    "            k1.set_shape([None, self._hp.context_size, self._hp.d_attention])\n",
    "            k1 = tf.transpose(k1, perm = [0, 2, 1])        # [batch_size, d_attention, context_size]\n",
    "            w = tf.matmul(k0, k1)                          # [batch_size, context_size, context_size]\n",
    "            mask = tf.diag([-1e20] * self._hp.context_size)\n",
    "            mask = tf.expand_dims(mask, axis = 0)          # [1, context_size, context_size]\n",
    "            w += mask\n",
    "            w /= np.sqrt(self._hp.d_attention)\n",
    "            w = tf.nn.softmax(w)\n",
    "            \n",
    "            # apply weights\n",
    "            layer += tf.matmul(w, layer)\n",
    "            \n",
    "            # batch norm\n",
    "            layer = tf.layers.batch_normalization(\n",
    "                layer,\n",
    "                training = self._training)\n",
    "\n",
    "            # dropout\n",
    "            layer = tf.layers.dropout(\n",
    "                layer,\n",
    "                rate = self._hp.dropout_rate,\n",
    "                training = self._training)\n",
    "            \n",
    "            return layer\n",
    "\n",
    "    def _attention_feed_forward(self, layer):\n",
    "        with tf.variable_scope('ff'):\n",
    "            # hidden layer\n",
    "            layer = tf.layers.dense(\n",
    "                layer,\n",
    "                self._hp.d_attention_ff,\n",
    "                activation = tf.nn.relu,\n",
    "                name = 'fc1')\n",
    "            \n",
    "            # output\n",
    "            layer = tf.layers.dense(\n",
    "                layer,\n",
    "                self._hp.d_attention,\n",
    "                name = 'fc2')\n",
    "            \n",
    "            # batch norm\n",
    "            layer = tf.layers.batch_normalization(\n",
    "                layer,\n",
    "                training = self._training)\n",
    "            \n",
    "            # dropout\n",
    "            layer = tf.layers.dropout(\n",
    "                layer, \n",
    "                rate = self._hp.dropout_rate, \n",
    "                training = self._training)\n",
    "        \n",
    "            return layer\n",
    "            \n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('model'):\n",
    "            # placeholder: training flag\n",
    "            self._training = tf.placeholder(tf.bool, name = 'training')\n",
    "            \n",
    "            # embed context words\n",
    "            word_embeddings = tf.get_variable(\n",
    "                'word_embeddings', \n",
    "                [self._hp.vocab_size, self._hp.d_embedding_word])\n",
    "            context_embedded = tf.nn.embedding_lookup(\n",
    "                word_embeddings,\n",
    "                self._context)\n",
    "\n",
    "            # embed context positions\n",
    "            position_embeddings = tf.get_variable(\n",
    "                'position_embeddings',\n",
    "                [self._hp.context_size, self._hp.d_embedding_position],\n",
    "                dtype=tf.float32)\n",
    "            context_positions_embedded = tf.nn.embedding_lookup(\n",
    "                position_embeddings,\n",
    "                self._context_positions)\n",
    "\n",
    "            # build full context vector (concat embeddings)\n",
    "            context_full = tf.concat(\n",
    "                [context_embedded, context_positions_embedded], \n",
    "                axis = -1)\n",
    "            \n",
    "            # build attention layers\n",
    "            with tf.variable_scope('attention'):\n",
    "                # build input vector\n",
    "                context_attention = tf.layers.dense(\n",
    "                    context_full,\n",
    "                    self._hp.d_attention,\n",
    "                    activation = tf.nn.relu,\n",
    "                    name = 'input')\n",
    "                context_attention = tf.layers.batch_normalization(\n",
    "                    context_attention,\n",
    "                    training = self._training,\n",
    "                    name = 'input')\n",
    "                context_attention = tf.layers.dropout(\n",
    "                    context_attention,\n",
    "                    rate = self._hp.dropout_rate,\n",
    "                    training = self._training)\n",
    "                \n",
    "                layer = context_attention\n",
    "                for i in range(self._hp.attention_num_layers):\n",
    "                    with tf.variable_scope('layer_%d' % i):\n",
    "                        layer = self._attention_self(layer)\n",
    "                        layer = self._attention_feed_forward(layer)\n",
    "            \n",
    "            # link detection\n",
    "            self._output_link_logits = tf.layers.dense(layer, 1)\n",
    "            self._output_link_logits = tf.squeeze(\n",
    "                self._output_link_logits,\n",
    "                axis = -1,\n",
    "                name = 'output_link_logits')\n",
    "\n",
    "            # class identification\n",
    "            self._output_class_logits = tf.layers.dense(\n",
    "                layer,\n",
    "                self._hp.num_targets,\n",
    "                name = 'output_class_logits')\n",
    "\n",
    "    def _build_training_model(self):\n",
    "        with tf.variable_scope('train'):\n",
    "            # link detection losses\n",
    "            target_links = tf.cast(tf.logical_not(tf.less(self._targets, 0)), tf.int64)\n",
    "            link_losses = tf.nn.weighted_cross_entropy_with_logits(\n",
    "                targets = tf.cast(target_links, tf.float32),\n",
    "                logits = self._output_link_logits,\n",
    "                pos_weight = self._hp.link_loss_pos_weight)\n",
    "            link_losses *= self._hp.link_loss_scale\n",
    "            \n",
    "            # DEBUG: remove me\n",
    "            self._link_losses = link_losses\n",
    "\n",
    "            # class identification losses\n",
    "            targets = tf.maximum(self._targets, 0) # prevent NaNs\n",
    "            class_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = targets,\n",
    "                logits = self._output_class_logits)\n",
    "            # (mask off losses for non-links)\n",
    "            class_losses *= tf.cast(target_links, tf.float32)\n",
    "\n",
    "            # DEBUG: remove me\n",
    "            self._class_losses = class_losses\n",
    "            \n",
    "            # total loss\n",
    "            self._total_link_loss = tf.reduce_sum(link_losses, name = 'total_link_loss')\n",
    "            self._total_class_loss = tf.reduce_sum(class_losses, name = 'total_class_loss')\n",
    "            self._total_loss = self._total_link_loss + self._total_class_loss\n",
    "            self._total_loss = tf.identity(self._total_loss, name = 'total_loss')\n",
    "\n",
    "            # mean loss\n",
    "            self._mean_loss = self._total_loss / tf.cast(self._minibatch_size, tf.float32)\n",
    "            self._mean_loss = tf.identity(self._mean_loss, name = 'mean_loss')\n",
    "            \n",
    "            # precision/recall\n",
    "            # N.B., tf.nn.softmax here is unnecessary?\n",
    "            output_link_probs = tf.sigmoid(self._output_link_logits)\n",
    "            self._output_links = output_link_probs > 0.5\n",
    "            self._output_links = tf.cast(\n",
    "                self._output_links,\n",
    "                tf.int64,\n",
    "                name = 'output_links')\n",
    "            self._true_positives = tf.reduce_sum(\n",
    "                self._output_links * target_links,\n",
    "                name = 'true_positives')\n",
    "            self._false_positives = tf.reduce_sum(\n",
    "                self._output_links * (1 - target_links),\n",
    "                name = 'false_positives')\n",
    "            self._false_negatives = tf.reduce_sum(\n",
    "                (1 - self._output_links) * target_links,\n",
    "                name = 'false_negatives')\n",
    "            \n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self._global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "                self._optimizer = tf.train.AdamOptimizer(learning_rate=self._hp.learning_rate)\n",
    "                \n",
    "                # gradient clipping\n",
    "                gradients, variables = zip(*self._optimizer.compute_gradients(self._mean_loss))\n",
    "                gradients, _ = tf.clip_by_global_norm(\n",
    "                    gradients, \n",
    "                    self._hp.gradient_clip_norm)\n",
    "                \n",
    "                self._train_op = self._optimizer.apply_gradients(\n",
    "                    zip(gradients, variables),\n",
    "                    global_step = self._global_step)\n",
    "    \n",
    "    def build_model(self):\n",
    "        self._build_data_pipeline()\n",
    "        self._build_model()\n",
    "        self._build_training_model()\n",
    "\n",
    "    def process(self,\n",
    "                dataset_filenames,\n",
    "                dataset_limit = -1,\n",
    "                header = 'results',\n",
    "                train = False,\n",
    "                log_file = None):\n",
    "        # initialize dataset to files\n",
    "        self._session.run(self._dataset_iterator.initializer, feed_dict={\n",
    "            self._dataset_filenames: dataset_filenames,\n",
    "            self._dataset_limit: dataset_limit })\n",
    "\n",
    "        cum_loss = 0\n",
    "        cum_link_loss = 0\n",
    "        cum_class_loss = 0\n",
    "        cum_num_examples = 0\n",
    "        cum_true_positives = 0\n",
    "        cum_false_positives = 0\n",
    "        cum_false_negatives = 0\n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        progress = tqdm_notebook(leave = False, desc = header)\n",
    "\n",
    "        while True:\n",
    "            # process a minibatch\n",
    "            try:\n",
    "                (_,\n",
    "                 curr_total_loss, \n",
    "                 curr_total_link_loss,\n",
    "                 curr_total_class_loss,\n",
    "                 curr_minibatch_size,\n",
    "                 curr_true_positives,\n",
    "                 curr_false_positives,\n",
    "                 curr_false_negatives) = self._session.run(\n",
    "                    (self._train_op if train else (),\n",
    "                     self._total_loss,\n",
    "                     self._total_link_loss,\n",
    "                     self._total_class_loss,\n",
    "                     self._minibatch_size,\n",
    "                     self._true_positives,\n",
    "                     self._false_positives,\n",
    "                     self._false_negatives),\n",
    "                    feed_dict = { self._training: train })\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "            # update stats/progress\n",
    "            cum_loss += curr_total_loss\n",
    "            cum_link_loss += curr_total_link_loss\n",
    "            cum_class_loss += curr_total_class_loss\n",
    "            cum_num_examples += curr_minibatch_size\n",
    "            cum_true_positives += curr_true_positives\n",
    "            cum_false_positives += curr_false_positives\n",
    "            cum_false_negatives += curr_false_negatives\n",
    "            progress.update(curr_minibatch_size)\n",
    "\n",
    "        progress.close()\n",
    "        finish = datetime.datetime.now()\n",
    "        \n",
    "        # precision\n",
    "        precision = 0\n",
    "        if cum_true_positives + cum_false_positives > 0:\n",
    "            precision = cum_true_positives / (cum_true_positives + cum_false_positives)\n",
    "            \n",
    "        # recall\n",
    "        recall = 0\n",
    "        if cum_true_positives + cum_false_negatives > 0:\n",
    "            recall = cum_true_positives / (cum_true_positives + cum_false_negatives)\n",
    "            \n",
    "        # F1\n",
    "        F1 = 0\n",
    "        if precision + recall > 0:\n",
    "            F1 = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "        # print/log output\n",
    "        message = '%s: time=%s, step=%d, loss=%g (%g + %g), precision=%g, recall=%g, F=%g' % (\n",
    "            header,\n",
    "            finish - start,\n",
    "            tf.train.global_step(sess, self._global_step),\n",
    "            cum_loss / cum_num_examples,\n",
    "            cum_link_loss / cum_num_examples,\n",
    "            cum_class_loss / cum_num_examples,\n",
    "            precision,\n",
    "            recall,\n",
    "            F1)\n",
    "        print(message)\n",
    "        if log_file:\n",
    "            print(message, file=log_file)\n",
    "            log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for \"model/word_embeddings:0\": 3840000\n",
      "parameters for \"model/position_embeddings:0\": 2592\n",
      "parameters for \"model/attention/input/kernel:0\": 20480\n",
      "parameters for \"model/attention/input/bias:0\": 128\n",
      "parameters for \"model/attention/input/gamma:0\": 128\n",
      "parameters for \"model/attention/input/beta:0\": 128\n",
      "parameters for \"model/attention/layer_0/self/kernels:0\": 32768\n",
      "parameters for \"model/attention/layer_0/self/batch_normalization/gamma:0\": 128\n",
      "parameters for \"model/attention/layer_0/self/batch_normalization/beta:0\": 128\n",
      "parameters for \"model/attention/layer_0/ff/fc1/kernel:0\": 65536\n",
      "parameters for \"model/attention/layer_0/ff/fc1/bias:0\": 512\n",
      "parameters for \"model/attention/layer_0/ff/fc2/kernel:0\": 65536\n",
      "parameters for \"model/attention/layer_0/ff/fc2/bias:0\": 128\n",
      "parameters for \"model/attention/layer_0/ff/batch_normalization/gamma:0\": 128\n",
      "parameters for \"model/attention/layer_0/ff/batch_normalization/beta:0\": 128\n",
      "parameters for \"model/attention/layer_1/self/kernels:0\": 32768\n",
      "parameters for \"model/attention/layer_1/self/batch_normalization/gamma:0\": 128\n",
      "parameters for \"model/attention/layer_1/self/batch_normalization/beta:0\": 128\n",
      "parameters for \"model/attention/layer_1/ff/fc1/kernel:0\": 65536\n",
      "parameters for \"model/attention/layer_1/ff/fc1/bias:0\": 512\n",
      "parameters for \"model/attention/layer_1/ff/fc2/kernel:0\": 65536\n",
      "parameters for \"model/attention/layer_1/ff/fc2/bias:0\": 128\n",
      "parameters for \"model/attention/layer_1/ff/batch_normalization/gamma:0\": 128\n",
      "parameters for \"model/attention/layer_1/ff/batch_normalization/beta:0\": 128\n",
      "parameters for \"model/attention/layer_2/self/kernels:0\": 32768\n",
      "parameters for \"model/attention/layer_2/self/batch_normalization/gamma:0\": 128\n",
      "parameters for \"model/attention/layer_2/self/batch_normalization/beta:0\": 128\n",
      "parameters for \"model/attention/layer_2/ff/fc1/kernel:0\": 65536\n",
      "parameters for \"model/attention/layer_2/ff/fc1/bias:0\": 512\n",
      "parameters for \"model/attention/layer_2/ff/fc2/kernel:0\": 65536\n",
      "parameters for \"model/attention/layer_2/ff/fc2/bias:0\": 128\n",
      "parameters for \"model/attention/layer_2/ff/batch_normalization/gamma:0\": 128\n",
      "parameters for \"model/attention/layer_2/ff/batch_normalization/beta:0\": 128\n",
      "parameters for \"model/attention/layer_3/self/kernels:0\": 32768\n",
      "parameters for \"model/attention/layer_3/self/batch_normalization/gamma:0\": 128\n",
      "parameters for \"model/attention/layer_3/self/batch_normalization/beta:0\": 128\n",
      "parameters for \"model/attention/layer_3/ff/fc1/kernel:0\": 65536\n",
      "parameters for \"model/attention/layer_3/ff/fc1/bias:0\": 512\n",
      "parameters for \"model/attention/layer_3/ff/fc2/kernel:0\": 65536\n",
      "parameters for \"model/attention/layer_3/ff/fc2/bias:0\": 128\n",
      "parameters for \"model/attention/layer_3/ff/batch_normalization/gamma:0\": 128\n",
      "parameters for \"model/attention/layer_3/ff/batch_normalization/beta:0\": 128\n",
      "parameters for \"model/dense/kernel:0\": 128\n",
      "parameters for \"model/dense/bias:0\": 1\n",
      "parameters for \"model/output_class_logits/kernel:0\": 256000\n",
      "parameters for \"model/output_class_logits/bias:0\": 2000\n",
      "total parameters: 4781553\n"
     ]
    }
   ],
   "source": [
    "sess = reset_tf(sess)\n",
    "\n",
    "model = EntityRecognitionModel(sess, HyperParameters())\n",
    "model.build_model()\n",
    "dump_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    return sorted([os.path.join(path, file) for file in os.listdir(path)])\n",
    "\n",
    "train_set = list_files('../data/simplewiki/simplewiki-20171103.er_softmax_1.train')\n",
    "dev_set = list_files('../data/simplewiki/simplewiki-20171103.er_softmax_1.dev')\n",
    "test_set = list_files('../data/simplewiki/simplewiki-20171103.er_softmax_1.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46268cfea23846719ee25103b3ed425e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 0', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 0: time=0:02:37.470138, step=965, loss=65.4464 (37.968 + 27.4784), precision=0.47381, recall=0.838531, F=0.60549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd1d6379c8a4cd3bf6c5acea1fc7fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 0', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 0: time=0:00:02.724285, step=965, loss=48.4185 (28.1573 + 20.2612), precision=0.628549, recall=0.807609, F=0.706916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547245ff44ba46efa988a55c79788d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 1', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 1: time=0:02:31.684070, step=1930, loss=39.186 (25.4332 + 13.7529), precision=0.582439, recall=0.885379, F=0.702647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eb2479be424fff9a276188276efb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 1', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 1: time=0:00:02.583615, step=1930, loss=35.4048 (27.0248 + 8.37996), precision=0.697273, recall=0.794058, F=0.742525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d84d27ad454c678a0d8427f2a1303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 2', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 2: time=0:02:31.740054, step=2895, loss=30.2211 (22.8888 + 7.33223), precision=0.609793, recall=0.899694, F=0.726905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc37434562047189e8b74f523bbd1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 2', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 2: time=0:00:02.863238, step=2895, loss=30.1805 (25.3604 + 4.82009), precision=0.675182, recall=0.834407, F=0.746397\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b0740500ec449cb29665be575171ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 3', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 3: time=0:02:31.846296, step=3860, loss=26.204 (21.2687 + 4.93531), precision=0.626585, recall=0.910028, F=0.742165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9c1953cb4c4a10ad6f039ad118f9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 3', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 3: time=0:00:02.764185, step=3860, loss=29.5703 (25.9616 + 3.60876), precision=0.687163, recall=0.825932, F=0.750184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa07c85cdce4dcebf6ee87a239f905f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 4', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 4: time=0:02:31.361258, step=4825, loss=23.8213 (20.0425 + 3.77876), precision=0.639974, recall=0.917596, F=0.754043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b81785552644da92f925fc2e489f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 4', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 4: time=0:00:02.580893, step=4825, loss=29.5177 (26.4454 + 3.07229), precision=0.701552, recall=0.815494, F=0.754244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a273899c5f304e7981abc3e99dbb5e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 5', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 5: time=0:02:30.281095, step=5790, loss=22.0925 (18.9738 + 3.11869), precision=0.651895, recall=0.924087, F=0.764486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9c8458c26e46f9acb85baf64cf60f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 5', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 5: time=0:00:02.501831, step=5790, loss=30.3996 (27.4935 + 2.90616), precision=0.683314, recall=0.826705, F=0.748201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60702e66f295429bbb203d57aa2adaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 6', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 6: time=0:02:30.066458, step=6755, loss=20.8424 (18.0979 + 2.74453), precision=0.663152, recall=0.929201, F=0.773951\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a0b83ed24b40e798671599951eed5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 6', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 6: time=0:00:02.533136, step=6755, loss=32.2327 (29.4718 + 2.76092), precision=0.693908, recall=0.820275, F=0.751818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcfce6214824ce39c8ec29967934a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 7', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 7: time=0:02:30.128509, step=7720, loss=19.7351 (17.228 + 2.50703), precision=0.674574, recall=0.934345, F=0.783489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32021263217046e49aaa2322063cea4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 7', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 7: time=0:00:02.539677, step=7720, loss=32.778 (30.1147 + 2.66338), precision=0.695872, recall=0.816867, F=0.751531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f66b76af024eb3a61430241e3c7099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 8', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 8: time=0:02:30.189422, step=8685, loss=18.8475 (16.5267 + 2.3208), precision=0.684392, recall=0.938229, F=0.791456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d5079186b04c78a5f056d5decf7435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 8', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 8: time=0:00:02.491868, step=8685, loss=37.5906 (34.9572 + 2.63339), precision=0.722391, recall=0.785104, F=0.752443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9257b1692ce844abb80458b77fb67168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train 9', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "train 9: time=0:02:30.140851, step=9650, loss=18.0086 (15.8238 + 2.18481), precision=0.694021, recall=0.9422, F=0.799289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef366a6434946b5b01e8977885ef114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='dev 9', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev 9: time=0:00:02.545961, step=9650, loss=33.1947 (30.8207 + 2.37397), precision=0.680458, recall=0.824642, F=0.745644\n"
     ]
    }
   ],
   "source": [
    "with open('../logs/simplewiki/mediawiki_er_softmax_1.log', 'wt') as f:\n",
    "    for i in range(10):\n",
    "        model.process(\n",
    "            train_set,\n",
    "            header = 'train %d' % i,\n",
    "            train = True,\n",
    "            log_file = f)\n",
    "        model.process(\n",
    "            dev_set,\n",
    "            header = 'dev %d' % i,\n",
    "            train = False,\n",
    "            log_file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._output_link_probs = tf.sigmoid(model._output_link_logits)\n",
    "model._output_class_probs = tf.nn.softmax(model._output_class_logits)\n",
    "model._output_classes = tf.argmax(model._output_class_probs, axis = -1, name = 'output_class_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/simplewiki/simplewiki-20171103.er_softmax_1.vocab.txt', 'rt') as f:\n",
    "    id_to_word = [w.strip() for w in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/simplewiki/simplewiki-20171103.er_softmax_1.targets.txt', 'rt') as f:\n",
    "    id_to_target = [t.strip() for t in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_negative_examples(filenames, limit = None):\n",
    "    # initialize dataset iterator\n",
    "    sess.run(model._dataset_iterator.initializer, feed_dict = {\n",
    "        model._dataset_filenames: filenames,\n",
    "        model._training: False })\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    while True:\n",
    "        # compute minibatch\n",
    "        try:\n",
    "            (context,\n",
    "             targets,\n",
    "             output_links,\n",
    "             output_link_probs,\n",
    "             output_classes,\n",
    "             output_class_probs) = sess.run(\n",
    "                (model._context, \n",
    "                 model._targets, \n",
    "                 model._output_links, \n",
    "                 model._output_link_probs,\n",
    "                 model._output_classes,\n",
    "                 model._output_class_probs),\n",
    "                feed_dict = { model._training: False })\n",
    "        except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "        # loop through examples\n",
    "        for cs, ts, ols, olps, ocs, ocps in zip(context, targets, output_links, output_link_probs, output_classes, output_class_probs):\n",
    "            # stop if limit reached\n",
    "            if limit and len(examples) >= limit:\n",
    "                break\n",
    "            \n",
    "            # decode context\n",
    "            decoded_context = [id_to_word[wid] for wid in cs]\n",
    "            decoded_targets = [id_to_target[tid] if tid >= 0 else None for tid in ts]\n",
    "            decoded_output_classes = [id_to_target[ocs[i]] if ols[i] else None for i in range(len(ols))]\n",
    "            decoded_class_probs = [ocps[i, ocs[i]] if ols[i] else 0.0 for i in range(len(ols))]\n",
    "\n",
    "            # decode example\n",
    "            examples.append([\n",
    "                decoded_context,\n",
    "                decoded_targets,\n",
    "                decoded_output_classes,\n",
    "                olps,\n",
    "                decoded_class_probs])\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = compute_negative_examples(dev_set[:1], limit = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(e):\n",
    "    context, targets, outputs, link_probs, class_probs = e\n",
    "    for word, target, output, link_prob, class_prob in zip(context, targets, outputs, link_probs, class_probs):\n",
    "        class_prob = ' %0.3f' % class_prob if class_prob else ''\n",
    "        print('%20.20s %20.20s %20.20s  %0.3f %s' % (word, target, output, link_prob, class_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "               <OOB>                 None                 None  0.000 \n",
      "          jacqueline                 None                 None  0.000 \n",
      "                jill                 None                 None  0.000 \n",
      "                   \"                 None                 None  0.000 \n",
      "               <UNK>                 None                 None  0.000 \n",
      "                   \"                 None                 None  0.001 \n",
      "               smith                 None                 None  0.000 \n",
      "                   (                 None                 None  0.000 \n",
      "                born                 None                 None  0.001 \n",
      "                   3                 None                 None  0.000 \n",
      "            november                 None                 None  0.000 \n",
      "                1962                 None                 None  0.012 \n",
      "                   )                 None                 None  0.000 \n",
      "                  is                 None                 None  0.000 \n",
      "                  an                 None                 None  0.000 \n",
      "             english       ENGLISH PEOPLE       ENGLISH PEOPLE  0.979  0.803\n",
      "          politician           POLITICIAN           POLITICIAN  0.902  0.996\n",
      "                   .                 None                 None  0.000 \n",
      "                 she                 None                 None  0.000 \n",
      "                 was                 None                 None  0.000 \n",
      "                 the                 None                 None  0.000 \n",
      "               first                 None                 None  0.001 \n",
      "              female                 None                 None  0.003 \n",
      "                home                 None                 None  0.002 \n",
      "           secretary                 None                 None  0.001 \n",
      "                  of                 None                 None  0.000 \n",
      "                 the                 None                 None  0.004 \n",
      "              united       UNITED KINGDOM                 None  0.479 \n",
      "             kingdom       UNITED KINGDOM       UNITED KINGDOM  0.960  0.914\n",
      "                   .                 None                 None  0.000 \n",
      "                 she                 None                 None  0.000 \n",
      "                 was                 None                 None  0.000 \n",
      "                born                 None                 None  0.000 \n",
      "                  in                 None                 None  0.000 \n",
      "             malvern                 None                 None  0.000 \n",
      "                   ,                 None                 None  0.000 \n",
      "      worcestershire                 None                 None  0.000 \n",
      "                   .                 None                 None  0.000 \n",
      "                 she                 None                 None  0.000 \n",
      "                 was                 None                 None  0.000 \n",
      "                 the                 None                 None  0.000 \n",
      "              member                 None                 None  0.002 \n",
      "                  of                 None                 None  0.014 \n",
      "          parliament                 None                 None  0.490 \n"
     ]
    }
   ],
   "source": [
    "print_example(examples[53])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
