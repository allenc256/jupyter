{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_tf():\n",
    "    global sess\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_tf()\n",
    "\n",
    "seq_length = 50\n",
    "batch_size = 64\n",
    "embedding_size = 64\n",
    "hidden_size = 64\n",
    "vocab_size = 256\n",
    "num_layers = 2\n",
    "\n",
    "input_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "input_lengths = tf.placeholder(tf.int32, [batch_size])\n",
    "target_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "\n",
    "rnn_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(hidden_size) for i in range(num_layers)])\n",
    "\n",
    "initial_states = rnn_cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# embedded_inputs = tf.one_hot(input_data, vocab_size)\n",
    "\n",
    "embedding = tf.get_variable('embedding', [vocab_size, embedding_size])\n",
    "embedded_inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [hidden_size, vocab_size])\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "\n",
    "outputs, final_states = tf.nn.dynamic_rnn(rnn_cell,\n",
    "                                          embedded_inputs, \n",
    "                                          initial_state=initial_states, \n",
    "                                          sequence_length=input_lengths)\n",
    "\n",
    "flat_outputs = tf.reshape(outputs, [-1, hidden_size])\n",
    "flat_targets = tf.reshape(target_data, [-1])\n",
    "\n",
    "flat_output_logits = tf.matmul(flat_outputs, softmax_w) + softmax_b\n",
    "flat_output_probs = tf.nn.softmax(flat_output_logits)\n",
    "\n",
    "flat_loss_mask = tf.sign(tf.to_float(flat_targets))\n",
    "flat_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=flat_output_logits, labels=flat_targets) * flat_loss_mask\n",
    "# flat_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=flat_output_logits, labels=flat_targets)\n",
    "\n",
    "mean_loss = tf.reduce_mean(flat_losses)\n",
    "total_loss = tf.reduce_sum(flat_losses)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "gradients, variables = zip(*optimizer.compute_gradients(mean_loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "# train_op = tf.train.AdamOptimizer(0.01).minimize(mean_loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(initial_data, count):\n",
    "    curr_initial_states  = sess.run(initial_states)\n",
    "    curr_input_data = np.zeros(input_data.shape)\n",
    "    curr_input_lengths = [1] + [0] * (batch_size - 1)\n",
    "    \n",
    "    result = [initial_data]\n",
    "    \n",
    "    for i in range(count):\n",
    "        curr_input_data[0,0] = result[-1]\n",
    "        ps, curr_initial_states = sess.run((flat_output_probs, final_states), feed_dict = {\n",
    "            input_data: curr_input_data,\n",
    "            input_lengths: curr_input_lengths,\n",
    "            initial_states: curr_initial_states\n",
    "        })\n",
    "        result.append(np.random.choice(len(ps[0]), p = ps[0]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batches(array, batch_size, seq_length):\n",
    "    num_seqs = (len(array) + seq_length - 1) // seq_length\n",
    "    num_seqs_per_batch = (num_seqs + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(num_seqs_per_batch):\n",
    "        seqs = []\n",
    "        seq_lens = []\n",
    "        \n",
    "        for j in range(batch_size):\n",
    "            offset = (j*num_seqs_per_batch + i)*seq_length\n",
    "            \n",
    "            seq = array[offset:offset+seq_length]\n",
    "            seq_len = len(seq)\n",
    "            seq = np.pad(seq, (0,seq_length-len(seq)), 'constant', constant_values=0)\n",
    "            \n",
    "            seqs.append(seq)\n",
    "            seq_lens.append(seq_len)\n",
    "            \n",
    "        yield np.stack(seqs), seq_lens\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = None\n",
    "with urllib.request.urlopen('http://textfiles.com/stories/13chil.txt') as response:\n",
    "    train_text = response.read().decode(\"utf-8\")\n",
    "train_text = ' '.join(train_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss=0.01862826055409957\n",
      "epoch 10: loss=0.01844330904435138\n",
      "epoch 20: loss=0.01826385040672458\n",
      "epoch 30: loss=0.018088892284704713\n",
      "epoch 40: loss=0.017918856776490504\n",
      "epoch 50: loss=0.017750957547401896\n",
      "epoch 60: loss=0.017587185879142916\n",
      "epoch 70: loss=0.017432176823518716\n",
      "epoch 80: loss=0.017279222060223014\n",
      "epoch 90: loss=0.017116361004965646\n",
      "epoch 100: loss=0.017043660854806707\n",
      "epoch 110: loss=0.016874300460426175\n",
      "epoch 120: loss=0.7329377777722417\n",
      "epoch 130: loss=0.26116881078603316\n",
      "epoch 140: loss=0.06868012097417092\n",
      "epoch 150: loss=0.035748796073757874\n",
      "epoch 160: loss=0.029626026932074098\n",
      "epoch 170: loss=0.02669382581905443\n",
      "epoch 180: loss=0.024921293161353286\n",
      "epoch 190: loss=0.023587300339523627\n",
      "epoch 200: loss=0.022551416864200514\n",
      "epoch 210: loss=0.02170572718795465\n",
      "epoch 220: loss=0.021019407194487902\n",
      "epoch 230: loss=0.02043881270350242\n",
      "epoch 240: loss=0.019937464412377804\n",
      "epoch 250: loss=0.019499532543883032\n",
      "epoch 260: loss=0.01911404205828297\n",
      "epoch 270: loss=0.01877201527965312\n",
      "epoch 280: loss=0.0184654029048219\n",
      "epoch 290: loss=0.018187048970436562\n",
      "epoch 300: loss=0.017931849615914482\n",
      "epoch 310: loss=0.01769599744251796\n",
      "epoch 320: loss=0.01747642049984056\n",
      "epoch 330: loss=0.017270535595562995\n",
      "epoch 340: loss=0.017076313982204515\n",
      "epoch 350: loss=0.016892213480813163\n",
      "epoch 360: loss=0.01671704443133607\n",
      "epoch 370: loss=0.016549763630847543\n",
      "epoch 380: loss=0.01638947579325462\n",
      "epoch 390: loss=0.016235578546718674\n",
      "epoch 400: loss=0.016089853948476365\n",
      "epoch 410: loss=0.01594494118982432\n",
      "epoch 420: loss=0.015811914813761808\n",
      "epoch 430: loss=0.015674246817219014\n",
      "epoch 440: loss=0.015544870678259402\n",
      "epoch 450: loss=0.015420390635120625\n",
      "epoch 460: loss=0.015296158012078733\n",
      "epoch 470: loss=0.01518338797043781\n",
      "epoch 480: loss=0.015062882219042097\n",
      "epoch 490: loss=0.014948549805855265\n"
     ]
    }
   ],
   "source": [
    "train_array = np.array([ord(ch) for ch in train_text])\n",
    "\n",
    "# train_array = np.array(list(range(30)))\n",
    "\n",
    "for i in range(500):\n",
    "    epoch_loss = 0.0\n",
    "    curr_initial_states = sess.run(initial_states)\n",
    "    train_input_batches = generate_batches(train_array[:-1], batch_size, seq_length)\n",
    "    train_target_batches = generate_batches(train_array[1:], batch_size, seq_length)\n",
    "    \n",
    "    for (curr_input_data, curr_input_lens), (curr_target_data, _) in zip(train_input_batches, train_target_batches):\n",
    "        feed_dict = {\n",
    "            input_data: curr_input_data, \n",
    "            input_lengths: curr_input_lens,\n",
    "            target_data: curr_target_data,\n",
    "            initial_states: curr_initial_states }\n",
    "        _, curr_loss, curr_initial_states = sess.run((train_op, total_loss, final_states), feed_dict = feed_dict)\n",
    "        epoch_loss += curr_loss\n",
    "        \n",
    "    epoch_loss /= len(train_array) - 1\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f'epoch {i}: loss={epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAeng sgabt,\" he andos, surninter cruin an endead fon we wath if to ear tro! Why fon ther his own hom'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([chr(ch) for ch in sample(ord('R'), 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(32)])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
