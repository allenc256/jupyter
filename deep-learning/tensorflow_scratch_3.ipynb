{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_tf():\n",
    "    global sess\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_tf()\n",
    "\n",
    "seq_length = 50\n",
    "batch_size = 64\n",
    "embedding_size = 64\n",
    "hidden_size = 100\n",
    "vocab_size = 256\n",
    "num_layers = 2\n",
    "\n",
    "input_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "input_lengths = tf.placeholder(tf.int32, [batch_size])\n",
    "target_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(hidden_size)\n",
    "# rnn_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(hidden_size)] * num_layers)\n",
    "\n",
    "initial_states = rnn_cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# embedded_inputs = tf.one_hot(input_data, vocab_size)\n",
    "\n",
    "embedding = tf.get_variable('embedding', [vocab_size, embedding_size])\n",
    "embedded_inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [hidden_size, vocab_size])\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "\n",
    "outputs, final_states = tf.nn.dynamic_rnn(rnn_cell,\n",
    "                                          embedded_inputs, \n",
    "                                          initial_state=initial_states, \n",
    "                                          sequence_length=input_lengths)\n",
    "\n",
    "flat_outputs = tf.reshape(outputs, [-1, hidden_size])\n",
    "flat_targets = tf.reshape(target_data, [-1])\n",
    "\n",
    "flat_output_logits = tf.matmul(flat_outputs, softmax_w) + softmax_b\n",
    "flat_output_probs = tf.nn.softmax(flat_output_logits)\n",
    "\n",
    "flat_loss_mask = tf.sign(tf.to_float(flat_targets))\n",
    "flat_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=flat_output_logits, labels=flat_targets) * flat_loss_mask\n",
    "# flat_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=flat_output_logits, labels=flat_targets)\n",
    "\n",
    "mean_loss = tf.reduce_mean(flat_losses)\n",
    "total_loss = tf.reduce_sum(flat_losses)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "gradients, variables = zip(*optimizer.compute_gradients(mean_loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "# train_op = tf.train.AdamOptimizer(0.01).minimize(mean_loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(initial_data, count):\n",
    "    curr_initial_states  = np.zeros(initial_states.shape)\n",
    "    curr_input_data = np.zeros(input_data.shape)\n",
    "    curr_input_lengths = [1] + [0] * (batch_size - 1)\n",
    "    \n",
    "    result = [initial_data]\n",
    "    \n",
    "    for i in range(count):\n",
    "        curr_input_data[0,0] = result[-1]\n",
    "        ps, curr_initial_states = sess.run((flat_output_probs, final_states), feed_dict = {\n",
    "            input_data: curr_input_data,\n",
    "            input_lengths: curr_input_lengths,\n",
    "            initial_states: curr_initial_states\n",
    "        })\n",
    "        result.append(np.random.choice(len(ps[0]), p = ps[0]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batches(array, batch_size, seq_length):\n",
    "    num_seqs = (len(array) + seq_length - 1) // seq_length\n",
    "    num_seqs_per_batch = (num_seqs + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(num_seqs_per_batch):\n",
    "        seqs = []\n",
    "        seq_lens = []\n",
    "        \n",
    "        for j in range(batch_size):\n",
    "            offset = (j*num_seqs_per_batch + i)*seq_length\n",
    "            \n",
    "            seq = array[offset:offset+seq_length]\n",
    "            seq_len = len(seq)\n",
    "            seq = np.pad(seq, (0,seq_length-len(seq)), 'constant', constant_values=0)\n",
    "            \n",
    "            seqs.append(seq)\n",
    "            seq_lens.append(seq_len)\n",
    "            \n",
    "        yield np.stack(seqs), seq_lens\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = None\n",
    "with urllib.request.urlopen('http://textfiles.com/stories/13chil.txt') as response:\n",
    "    train_text = response.read().decode(\"utf-8\")\n",
    "train_text = ' '.join(train_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss=0.24252834709323182\n",
      "epoch 10: loss=0.12895266474509726\n",
      "epoch 20: loss=0.0946833357519033\n",
      "epoch 30: loss=0.08441579390545281\n",
      "epoch 40: loss=0.07864886497964664\n",
      "epoch 50: loss=0.07478695305026307\n",
      "epoch 60: loss=0.07171535686570771\n",
      "epoch 70: loss=0.06939767915375379\n",
      "epoch 80: loss=0.06701291726560009\n",
      "epoch 90: loss=0.06783491640674824\n",
      "epoch 100: loss=0.07884371037385901\n",
      "epoch 110: loss=0.4817079038036113\n",
      "epoch 120: loss=0.18474281077482263\n",
      "epoch 130: loss=0.1124166761125837\n",
      "epoch 140: loss=0.09135466205830477\n",
      "epoch 150: loss=0.08045643203112544\n",
      "epoch 160: loss=0.07393209690950354\n",
      "epoch 170: loss=0.0693089485168457\n",
      "epoch 180: loss=0.065573415950853\n",
      "epoch 190: loss=0.062494316879583865\n"
     ]
    }
   ],
   "source": [
    "train_array = np.array([ord(ch) for ch in train_text])\n",
    "\n",
    "# train_array = np.array(list(range(30)))\n",
    "\n",
    "for i in range(200):\n",
    "    epoch_loss = 0.0\n",
    "    curr_initial_states = np.zeros(initial_states.shape)\n",
    "    train_input_batches = generate_batches(train_array[:-1], batch_size, seq_length)\n",
    "    train_target_batches = generate_batches(train_array[1:], batch_size, seq_length)\n",
    "    \n",
    "    for (curr_input_data, curr_input_lens), (curr_target_data, _) in zip(train_input_batches, train_target_batches):\n",
    "        feed_dict = {\n",
    "            input_data: curr_input_data, \n",
    "            input_lengths: curr_input_lens,\n",
    "            target_data: curr_target_data,\n",
    "            initial_states: curr_initial_states }\n",
    "        _, curr_loss, curr_initial_states = sess.run((train_op, total_loss, final_states), feed_dict = feed_dict)\n",
    "        epoch_loss += curr_loss\n",
    "        \n",
    "    epoch_loss /= len(train_array) - 1\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f'epoch {i}: loss={epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RÂ¦abbe wals st and at wered over his splaws an then he looked over his spersend hor lon in eirey. But'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([chr(ch) for ch in sample(ord('R'), 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
