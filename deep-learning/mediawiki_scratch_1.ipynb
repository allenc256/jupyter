{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: handle disambiguation pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import lxml.html\n",
    "import wikitextparser as wtp\n",
    "import nltk.data\n",
    "import re\n",
    "import json\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/simplewiki/simplewiki-20171103-pages-meta-current.xml.gz', 'rt', 'utf-8') as f:\n",
    "    tree = etree.parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespaces = {\n",
    "    'mediawiki': 'http://www.mediawiki.org/xml/export-0.10/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Shell (weapons)',\n",
       " '0',\n",
       " [<Element {http://www.mediawiki.org/xml/export-0.10/}redirect at 0x7f97bdab8a08>])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 200000\n",
    "page = tree.xpath('mediawiki:page[%d]' % index, namespaces = namespaces)[0]\n",
    "redirect = tree.xpath('mediawiki:page[%d]/mediawiki:redirect' % index, namespaces = namespaces)\n",
    "ns = tree.xpath('mediawiki:page[%d]/mediawiki:ns' % index, namespaces = namespaces)\n",
    "title = tree.xpath('mediawiki:page[%d]/mediawiki:title' % index, namespaces = namespaces)[0].text\n",
    "text = tree.xpath('mediawiki:page[%d]/mediawiki:revision/mediawiki:text' % index, namespaces = namespaces)[0].text\n",
    "title, ns[0].text, redirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(title, raw_text):\n",
    "    keep_tags = {'i','p','u','b','tt'}\n",
    "    wiki_text = wtp.parse(raw_text)\n",
    "    regions = []\n",
    "    strs = []\n",
    "    links = {}\n",
    "    offset = 0\n",
    "    \n",
    "    for l in wiki_text.wikilinks:\n",
    "        span = l.span\n",
    "        discard = re.match(r'^[^:]+:', l.target) and not l.target.startswith('wikt:')\n",
    "        target = l.target if not discard and not l.target.startswith('wikt:') else None\n",
    "        text = l.text or l.target\n",
    "        regions.append((span, discard, target, text))\n",
    "        \n",
    "    for l in wiki_text.external_links:\n",
    "        span = l.span\n",
    "        discard = False\n",
    "        target = None\n",
    "        text = l.text or l.url\n",
    "        regions.append((span, discard, target, text))\n",
    "        \n",
    "    for t in wiki_text.templates:\n",
    "        span = t.span\n",
    "        discard = True\n",
    "        target = None\n",
    "        text = None\n",
    "        regions.append((span, discard, target, text))\n",
    "    \n",
    "    for t in wiki_text.tags():\n",
    "        span = t.span\n",
    "        target = None\n",
    "        if (span[1] <= span[0]) or (span[1] - span[0] > 100):\n",
    "            discard = True\n",
    "            text = None\n",
    "        else:\n",
    "            try:\n",
    "                discard = t.name not in keep_tags\n",
    "                text = t.contents\n",
    "            except (TypeError, AttributeError) as e:\n",
    "                discard = True\n",
    "                text = None\n",
    "        regions.append((span, discard, target, text))\n",
    "    \n",
    "    for t in wiki_text.tables:\n",
    "        span = t.span\n",
    "        discard = True\n",
    "        target = None\n",
    "        text = None\n",
    "        regions.append((span, discard, target, text))\n",
    "    \n",
    "    for l in wiki_text.lists():\n",
    "        span = l.span\n",
    "        discard = True\n",
    "        target = None\n",
    "        text = None\n",
    "        regions.append((span, discard, target, text))\n",
    "        \n",
    "    for pf in wiki_text.parser_functions:\n",
    "        span = pf.span\n",
    "        discard = True\n",
    "        target = None\n",
    "        text = None\n",
    "        regions.append((span, discard, target, text))\n",
    "        \n",
    "    for c in wiki_text.comments:\n",
    "        span = c.span\n",
    "        discard = True\n",
    "        target = None\n",
    "        text = None\n",
    "        regions.append((span, discard, target, text))\n",
    "        \n",
    "    regions.sort()\n",
    "    \n",
    "    for (span, discard, target, text) in regions:\n",
    "        if span[0] < offset:\n",
    "            continue\n",
    "        strs.append(wiki_text.string[offset:span[0]])\n",
    "        if not discard:\n",
    "            if target:\n",
    "                token = '{{%d}}' % len(links)\n",
    "                strs.append(token)\n",
    "                links[token] = {'text': text, 'target': target.upper()}\n",
    "            else:\n",
    "                strs.append(text)\n",
    "        offset = span[1]\n",
    "    \n",
    "    strs.append(wiki_text.string[offset:])\n",
    "    \n",
    "    text = ''.join(strs)\n",
    "    \n",
    "    text = re.sub(r\"''+\", '', text)\n",
    "    text = re.sub(r\"==+[^=\\n]+==+\", '', text)\n",
    "    text = re.sub('&nbsp;', ' ', text)\n",
    "    text = re.sub('\\n\\n+', '\\n\\n', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return {\n",
    "        'title': title.upper(),\n",
    "        'text': text,\n",
    "        'links': links\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page_xml(page_xml):\n",
    "    redirects = page_xml.xpath('mediawiki:redirect', namespaces = namespaces)\n",
    "    ns = page_xml.xpath('mediawiki:ns', namespaces = namespaces)\n",
    "    titles = page_xml.xpath('mediawiki:title', namespaces = namespaces)\n",
    "    texts = page_xml.xpath('mediawiki:revision/mediawiki:text', namespaces = namespaces)\n",
    "    \n",
    "    if len(redirects) > 1:\n",
    "        raise Exception('found multiple redirects')\n",
    "    if len(ns) > 1:\n",
    "        raise Exception('found multiple namespaces')\n",
    "    if len(titles) > 1:\n",
    "        raise Exception('found multiple titles')\n",
    "    if len(texts) > 1:\n",
    "        raise Exception('found multiple texts')\n",
    "    \n",
    "    if ns[0].text != '0':\n",
    "        return None\n",
    "    if not texts[0].text or not titles[0].text:\n",
    "        return None\n",
    "    \n",
    "    if len(redirects) > 0:\n",
    "        target = redirects[0].attrib['title']\n",
    "        if target:\n",
    "            return {'title': titles[0].text.upper(), 'redirect': target.upper()}\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    return parse(titles[0].text.upper(), texts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_dump_xml(dump_xml, limit = None):\n",
    "    path = 'mediawiki:page'\n",
    "    if limit:\n",
    "        path += '[position() < %d]' % limit\n",
    "    page_xmls = dump_xml.xpath(path, namespaces = namespaces)\n",
    "    \n",
    "    result = {}\n",
    "    for page_xml in tqdm(page_xmls):\n",
    "        parsed_page = parse_page_xml(page_xml)\n",
    "        if parsed_page:\n",
    "            result[parsed_page['title']] = parsed_page\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437190/437190 [09:34<00:00, 761.08it/s]\n"
     ]
    }
   ],
   "source": [
    "parsed = parse_dump_xml(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_redirects(parsed):\n",
    "    for title, page in tqdm(parsed.items()):\n",
    "        if 'links' in page:\n",
    "            for token, link in page['links'].items():\n",
    "                old_target = parsed.get(link['target'])\n",
    "                new_target = old_target\n",
    "                depth = 0\n",
    "                while depth < 100 and new_target and 'redirect' in new_target:\n",
    "                    new_target = parsed.get(new_target['redirect'])\n",
    "                    depth += 1\n",
    "                if new_target and not (old_target is new_target):\n",
    "                    #print('redirecting %s -> %s' % (old_target[\"title\"], new_target[\"title\"]))\n",
    "                    link['target'] = new_target['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177277/177277 [00:03<00:00, 58134.71it/s]\n"
     ]
    }
   ],
   "source": [
    "resolve_redirects(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unresolved_links(parsed):\n",
    "    num_resolved = 0\n",
    "    num_unresolved = 0\n",
    "    for title, page in tqdm(parsed.items()):\n",
    "        if 'links' in page:\n",
    "            unresolved = {}\n",
    "            for token, link in page['links'].items():\n",
    "                target = parsed.get(link['target'])\n",
    "                if not target or 'redirect' in target:\n",
    "                    num_unresolved += 1\n",
    "                    unresolved[token] = link['text']\n",
    "                else:\n",
    "                    num_resolved += 1\n",
    "            for token, text in unresolved.items():\n",
    "                page['text'] = page['text'].replace(token, text)\n",
    "                page['links'].pop(token, None)\n",
    "    print(num_resolved, num_unresolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177277/177277 [00:01<00:00, 142776.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055666 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "remove_unresolved_links(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redirect_pages(parsed):\n",
    "    to_remove = [title for title, page in tqdm(parsed.items()) if 'redirect' in page]\n",
    "    for title in to_remove:\n",
    "        del parsed[title]\n",
    "    print(len(to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177277/177277 [00:00<00:00, 1001274.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "remove_redirect_pages(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ids(parsed):\n",
    "    counter = 0\n",
    "    for _, page in tqdm(parsed.items()):\n",
    "        page['id'] = counter\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125947/125947 [00:00<00:00, 842361.42it/s]\n"
     ]
    }
   ],
   "source": [
    "assign_ids(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125947"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/simplewiki/simplewiki-20171103.parsed.json.gz', 'wt', encoding='utf-8') as f:\n",
    "    json.dump(parsed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = list(parsed.items())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
